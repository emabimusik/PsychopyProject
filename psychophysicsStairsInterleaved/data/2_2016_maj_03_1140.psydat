ccopy_reg
_reconstructor
p1
(cpsychopy.data
ExperimentHandler
p2
c__builtin__
object
p3
NtRp4
(dp5
S'originPath'
p6
VC:\u005cUsers\u005cVlad Ilie\u005cDocuments\u005cDemosPsyschopy\u005cpsychophysicsStairsInterleaved\u005cinterleaved_SF_contrast.psyexp
p7
sS'dataFileName'
p8
VC:\u005cUsers\u005cVlad Ilie\u005cDocuments\u005cDemosPsyschopy\u005cpsychophysicsStairsInterleaved\u005cdata\u005c2_2016_maj_03_1140
p9
sS'runtimeInfo'
p10
NsS'name'
p11
S'interleaved_SF_contrast'
p12
sS'dataNames'
p13
(lp14
S'endInstructions.keys'
p15
aS'endInstructions.rt'
p16
aVtrials.maxVal
p17
aVtrials.minVal
p18
aVtrials.label
p19
aVtrials.stepSizes
p20
aVtrials.startVal
p21
aVtrials.sf
p22
aS'trials.thisIndex'
p23
aS'trials.thisRepN'
p24
aS'trials.thisN'
p25
aS'trials.direction'
p26
aS'trials.stepSize'
p27
aS'trials.stepType'
p28
aS'trials.intensity'
p29
aS'trials.response'
p30
asS'autoLog'
p31
I01
sS'extraInfo'
p32
(dp33
S'date'
p34
V2016_maj_03_1140
p35
sS'frameRate'
p36
cnumpy.core.multiarray
scalar
p37
(cnumpy
dtype
p38
(S'f8'
I0
I1
tRp39
(I3
S'<'
NNNI-1
I-1
I0
tbS'\xf6(\xec\xf2\xcf\xbcR@'
tRp40
sS'expName'
p41
g12
sVsession
p42
V001
p43
sVparticipant
p44
V2
ssS'loopsUnfinished'
p45
(lp46
g1
(cpsychopy.data
MultiStairHandler
p47
g3
NtRp48
(dp49
S'origin'
p50
V<PsychoPy2experiment version="1.78.00" encoding="utf-8">\u000a  <Settings>\u000a    <Param name="Show mouse" val="False" valType="bool" updates="None"/>\u000a    <Param name="Save csv file" val="False" valType="bool" updates="None"/>\u000a    <Param name="Monitor" val="testMonitor" valType="str" updates="None"/>\u000a    <Param name="Enable Escape" val="True" valType="bool" updates="None"/>\u000a    <Param name="color" val="$[0,0,0]" valType="str" updates="None"/>\u000a    <Param name="Window size (pixels)" val="[1920, 1080]" valType="code" updates="None"/>\u000a    <Param name="Full-screen window" val="True" valType="bool" updates="None"/>\u000a    <Param name="colorSpace" val="rgb" valType="str" updates="None"/>\u000a    <Param name="Save log file" val="True" valType="bool" updates="None"/>\u000a    <Param name="Experiment info" val="{u'session': u'001', u'participant': u''}" valType="code" updates="None"/>\u000a    <Param name="Save excel file" val="False" valType="bool" updates="None"/>\u000a    <Param name="Save wide csv file" val="True" valType="bool" updates="None"/>\u000a    <Param name="Save psydat file" val="True" valType="bool" updates="None"/>\u000a    <Param name="expName" val="interleaved_SF_contrast" valType="str" updates="None"/>\u000a    <Param name="logging level" val="exp" valType="code" updates="None"/>\u000a    <Param name="Units" val="deg" valType="str" updates="None"/>\u000a    <Param name="Show info dlg" val="True" valType="bool" updates="None"/>\u000a    <Param name="Saved data folder" val="" valType="code" updates="None"/>\u000a    <Param name="Screen" val="1" valType="num" updates="None"/>\u000a  </Settings>\u000a  <Routines>\u000a    <Routine name="trial">\u000a      <CodeComponent name="setSide">\u000a        <Param name="Begin Experiment" val="" valType="extendedCode" updates="constant"/>\u000a        <Param name="name" val="setSide" valType="code" updates="None"/>\u000a        <Param name="Each Frame" val="" valType="extendedCode" updates="constant"/>\u000a        <Param name="Begin Routine" val="if random()&gt;0.5:&#10;    pos = [-5,0] #this is deg visual angle&#10;    correctAns = 'left'&#10;else:&#10;    pos = [+5,0]&#10;    correctAns = 'right'" valType="extendedCode" updates="constant"/>\u000a        <Param name="End Routine" val="trials.addOtherData('side',correctAns)" valType="extendedCode" updates="constant"/>\u000a        <Param name="End Experiment" val="" valType="extendedCode" updates="constant"/>\u000a      </CodeComponent>\u000a      <StaticComponent name="ISI">\u000a        <Param name="code" val="" valType="code" updates="None"/>\u000a        <Param name="name" val="ISI" valType="code" updates="None"/>\u000a        <Param name="stopVal" val="0.25" valType="code" updates="constant"/>\u000a        <Param name="durationEstim" val="" valType="code" updates="None"/>\u000a        <Param name="startEstim" val="" valType="code" updates="None"/>\u000a        <Param name="startType" val="time (s)" valType="str" updates="None"/>\u000a        <Param name="stopType" val="duration (s)" valType="str" updates="None"/>\u000a        <Param name="startVal" val="0.0" valType="code" updates="None"/>\u000a      </StaticComponent>\u000a      <GratingComponent name="grating">\u000a        <Param name="opacity" val="1" valType="code" updates="constant"/>\u000a        <Param name="tex" val="sin" valType="str" updates="constant"/>\u000a        <Param name="colorSpace" val="rgb" valType="str" updates="constant"/>\u000a        <Param name="name" val="grating" valType="code" updates="constant"/>\u000a        <Param name="color" val="$level" valType="str" updates="set every repeat"/>\u000a        <Param name="stopVal" val="10" valType="code" updates="constant"/>\u000a        <Param name="durationEstim" val="0.16" valType="code" updates="None"/>\u000a        <Param name="mask" val="gauss" valType="str" updates="constant"/>\u000a        <Param name="pos" val="pos" valType="code" updates="set every repeat"/>\u000a        <Param name="interpolate" val="linear" valType="str" updates="constant"/>\u000a        <Param name="startEstim" val="" valType="code" updates="None"/>\u000a        <Param name="units" val="from exp settings" valType="str" updates="None"/>\u000a        <Param name="texture resolution" val="128" valType="code" updates="constant"/>\u000a        <Param name="phase" val="0.0" valType="code" updates="constant"/>\u000a        <Param name="startType" val="time (s)" valType="str" updates="None"/>\u000a        <Param name="ori" val="0" valType="code" updates="constant"/>\u000a        <Param name="stopType" val="duration (frames)" valType="str" updates="None"/>\u000a        <Param name="startVal" val="0.5" valType="code" updates="None"/>\u000a        <Param name="sf" val="sf" valType="code" updates="set every repeat"/>\u000a        <Param name="advancedParams"/>\u000a        <Param name="size" val="4" valType="code" updates="constant"/>\u000a      </GratingComponent>\u000a      <KeyboardComponent name="resp">\u000a        <Param name="correctAns" val="$correctAns" valType="str" updates="constant"/>\u000a        <Param name="storeCorrect" val="True" valType="bool" updates="constant"/>\u000a        <Param name="name" val="resp" valType="code" updates="None"/>\u000a        <Param name="stopVal" val="" valType="code" updates="constant"/>\u000a        <Param name="durationEstim" val="" valType="code" updates="None"/>\u000a        <Param name="forceEndRoutine" val="True" valType="bool" updates="constant"/>\u000a        <Param name="startEstim" val="" valType="code" updates="None"/>\u000a        <Param name="discard previous" val="True" valType="bool" updates="constant"/>\u000a        <Param name="startType" val="time (s)" valType="str" updates="None"/>\u000a        <Param name="allowedKeys" val="'left','right'" valType="code" updates="constant"/>\u000a        <Param name="stopType" val="duration (s)" valType="str" updates="None"/>\u000a        <Param name="startVal" val="0.5" valType="code" updates="None"/>\u000a        <Param name="store" val="last key" valType="str" updates="constant"/>\u000a      </KeyboardComponent>\u000a      <GratingComponent name="fixation">\u000a        <Param name="opacity" val="1" valType="code" updates="constant"/>\u000a        <Param name="tex" val="" valType="str" updates="constant"/>\u000a        <Param name="colorSpace" val="rgb" valType="str" updates="constant"/>\u000a        <Param name="name" val="fixation" valType="code" updates="constant"/>\u000a        <Param name="color" val="black" valType="str" updates="constant"/>\u000a        <Param name="stopVal" val="" valType="code" updates="constant"/>\u000a        <Param name="durationEstim" val="" valType="code" updates="None"/>\u000a        <Param name="mask" val="gauss" valType="str" updates="constant"/>\u000a        <Param name="pos" val="[0, 0]" valType="code" updates="constant"/>\u000a        <Param name="interpolate" val="linear" valType="str" updates="constant"/>\u000a        <Param name="startEstim" val="" valType="code" updates="None"/>\u000a        <Param name="units" val="from exp settings" valType="str" updates="None"/>\u000a        <Param name="texture resolution" val="128" valType="code" updates="constant"/>\u000a        <Param name="phase" val="0.0" valType="code" updates="constant"/>\u000a        <Param name="startType" val="time (s)" valType="str" updates="None"/>\u000a        <Param name="ori" val="0" valType="code" updates="constant"/>\u000a        <Param name="stopType" val="duration (s)" valType="str" updates="None"/>\u000a        <Param name="startVal" val="0.25" valType="code" updates="None"/>\u000a        <Param name="sf" val="None" valType="code" updates="constant"/>\u000a        <Param name="advancedParams"/>\u000a        <Param name="size" val="1" valType="code" updates="constant"/>\u000a      </GratingComponent>\u000a    </Routine>\u000a    <Routine name="thanks">\u000a      <TextComponent name="thanksMsg">\u000a        <Param name="opacity" val="1" valType="code" updates="constant"/>\u000a        <Param name="colorSpace" val="rgb" valType="str" updates="constant"/>\u000a        <Param name="name" val="thanksMsg" valType="code" updates="constant"/>\u000a        <Param name="color" val="$[1,1,1]" valType="str" updates="constant"/>\u000a        <Param name="wrapWidth" val="" valType="code" updates="constant"/>\u000a        <Param name="stopVal" val="2.0" valType="code" updates="constant"/>\u000a        <Param name="durationEstim" val="" valType="code" updates="None"/>\u000a        <Param name="pos" val="[0, 0]" valType="code" updates="constant"/>\u000a        <Param name="flip" val="" valType="str" updates="constant"/>\u000a        <Param name="startEstim" val="" valType="code" updates="None"/>\u000a        <Param name="units" val="from exp settings" valType="str" updates="None"/>\u000a        <Param name="text" val="You're done! Fun, wasn't it!? ;-)" valType="str" updates="constant"/>\u000a        <Param name="startType" val="time (s)" valType="str" updates="None"/>\u000a        <Param name="ori" val="0" valType="code" updates="constant"/>\u000a        <Param name="stopType" val="duration (s)" valType="str" updates="None"/>\u000a        <Param name="startVal" val="0.0" valType="code" updates="None"/>\u000a        <Param name="font" val="Arial" valType="str" updates="constant"/>\u000a        <Param name="letterHeight" val="0.1" valType="code" updates="constant"/>\u000a      </TextComponent>\u000a    </Routine>\u000a    <Routine name="instructions">\u000a      <TextComponent name="instrText">\u000a        <Param name="opacity" val="1" valType="code" updates="constant"/>\u000a        <Param name="colorSpace" val="rgb" valType="str" updates="constant"/>\u000a        <Param name="name" val="instrText" valType="code" updates="None"/>\u000a        <Param name="wrapWidth" val="" valType="code" updates="constant"/>\u000a        <Param name="color" val="white" valType="str" updates="constant"/>\u000a        <Param name="text" val="Press the left and right cursor keys to indicate whether the grating was on the left or right (there is always a correct answer).&#13;&#10;&#13;&#10;If you don't see anything then guess!&#13;&#10;&#13;&#10;&#13;&#10;Press any key to continue" valType="str" updates="constant"/>\u000a        <Param name="stopVal" val="" valType="code" updates="constant"/>\u000a        <Param name="durationEstim" val="" valType="code" updates="None"/>\u000a        <Param name="pos" val="[0, 0]" valType="code" updates="constant"/>\u000a        <Param name="flip" val="" valType="str" updates="constant"/>\u000a        <Param name="startEstim" val="" valType="code" updates="None"/>\u000a        <Param name="units" val="from exp settings" valType="str" updates="None"/>\u000a        <Param name="startType" val="time (s)" valType="str" updates="None"/>\u000a        <Param name="ori" val="0" valType="code" updates="constant"/>\u000a        <Param name="stopType" val="duration (s)" valType="str" updates="None"/>\u000a        <Param name="startVal" val="0.0" valType="code" updates="None"/>\u000a        <Param name="font" val="Arial" valType="str" updates="constant"/>\u000a        <Param name="letterHeight" val="1" valType="code" updates="constant"/>\u000a      </TextComponent>\u000a      <KeyboardComponent name="endInstructions">\u000a        <Param name="correctAns" val="" valType="str" updates="constant"/>\u000a        <Param name="storeCorrect" val="False" valType="bool" updates="constant"/>\u000a        <Param name="name" val="endInstructions" valType="code" updates="None"/>\u000a        <Param name="stopVal" val="" valType="code" updates="constant"/>\u000a        <Param name="durationEstim" val="" valType="code" updates="None"/>\u000a        <Param name="forceEndRoutine" val="True" valType="bool" updates="constant"/>\u000a        <Param name="startEstim" val="" valType="code" updates="None"/>\u000a        <Param name="discard previous" val="True" valType="bool" updates="constant"/>\u000a        <Param name="startType" val="time (s)" valType="str" updates="None"/>\u000a        <Param name="allowedKeys" val="" valType="code" updates="constant"/>\u000a        <Param name="stopType" val="duration (s)" valType="str" updates="None"/>\u000a        <Param name="startVal" val="0.0" valType="code" updates="None"/>\u000a        <Param name="store" val="last key" valType="str" updates="constant"/>\u000a      </KeyboardComponent>\u000a    </Routine>\u000a  </Routines>\u000a  <Flow>\u000a    <Routine name="instructions"/>\u000a    <LoopInitiator loopType="MultiStairHandler" name="trials">\u000a      <Param name="stairType" val="simple" valType="str" updates="None"/>\u000a      <Param name="switchMethod" val="random" valType="str" updates="None"/>\u000a      <Param name="name" val="trials" valType="code" updates="None"/>\u000a      <Param name="conditionsFile" val="stairDefinitions.xlsx" valType="str" updates="None"/>\u000a      <Param name="loopType" val="interleaved staircases" valType="str" updates="None"/>\u000a      <Param name="nReps" val="40" valType="code" updates="None"/>\u000a      <Param name="endPoints" val="[0, 1]" valType="num" updates="None"/>\u000a      <Param name="conditions" val="[{u'startVal': 0.001, u'sf': 2, u'label': u'low_2'}, {u'startVal': 0.1, u'sf': 2, u'label': u'high_2'}, {u'startVal': 0.001, u'sf': 8, u'label': u'low_8'}, {u'startVal': 0.1, u'sf': 8, u'label': u'high_8'}]" valType="str" updates="None"/>\u000a    </LoopInitiator>\u000a    <Routine name="trial"/>\u000a    <LoopTerminator name="trials"/>\u000a    <Routine name="thanks"/>\u000a  </Flow>\u000a</PsychoPy2experiment>\u000a
p51
sg6
g7
sS'_exp'
p52
I66623920
sg11
S'trials'
p53
sS'totalTrials'
p54
I164
sS'runningStaircases'
p55
(lp56
sS'thisPassRemaining'
p57
(lp58
sS'type'
p59
S'simple'
p60
sg31
I01
sS'currentStaircase'
p61
g1
(cpsychopy.data
StairHandler
p62
g3
NtRp63
(dp64
g50
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle, string, sys, os, time, copy\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import QuestObject    #used for QuestHandler\u000afrom contrib.psi import PsiObject   #used for PsiHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000a\u000atry:\u000a    #import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept ImportError:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False,\u000a                   encoding='utf-8',\u000a                   fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        print "saved data to %r" %f.name\u000a\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle for later use:\u000a        # We are going to set self.savePickle to False before saving,\u000a        # so PsychoPy won't try to save it again after loading from\u000a        # disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle is restored.\u000a        #\u000a        # See https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        # for details.\u000a        savePickle = self.savePickle\u000a        self.savePickle = False\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self,fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .tsv appended and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in Excel (xlsx) format, but was not found.')\u000a            #return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList): #user has hopefully specified a filename\u000a            self.trialList = importConditions(trialList) #import conditions from that file\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry)==dict:\u000a                self.trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try:\u000a            data = self.data\u000a        except:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum':\u000a                    heading ='n'\u000a                elif heading=='order_raw':\u000a                    heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str:\u000a            dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list:\u000a            dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go through standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. This should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   encoding='utf-8',\u000a                   fileCollisionMethod='rename'\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a        Also, return a pandas DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a             encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns = header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        if parameterName == "TrialNumber":\u000a                            nextEntry[parameterName] = trialCount\u000a                        else:\u000a                            nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a        df= df.convert_objects() # Converts numbers to numeric, such as float64, boolean to bool. Otherwise they all are "object" type, i.e. strings\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val)==0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            #nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except:\u000a        pass\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a        "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        "2:5"       # 2,3,4 (doesn't include last whole value)\u000a        "-10:2:"    #tenth from last to the last in steps of 2\u000a        slice(-10,2,None) #the same as above\u000a        random(5)*8 #5 random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError('Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name))\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError('Conditions file not found: %s' %os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        trialsArr = read_csv(fileName) # use pandas reader, which can handle commas in fields, etc\u000a        trialsArr = trialsArr.to_records(index=False) # convert the resulting dataframe to a numpy recarry\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    #if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection)>0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except:\u000a                    raise TypeError, "importConditions() was given some `indices` but could not parse them"\u000a    #the selection might now be a slice or a series of indices\u000a    if isinstance(selection,slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection)>0:\u000a        allConds = trialList\u000a        trialList=[]\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size\u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                   fileCollisionMethod='rename'\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in Excel (xlsx) format, but was not found.')\u000a            #return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """\u000a    Handler to implement the "Psi" adaptive psychophysical method (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function to be a cumulative Gaussian.\u000a    Psi estimates the two free parameters of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution. It chooses stimuli to present by\u000a    minimizing the entropy of this grid. Because this grid is represented internally as a 4-D array, one\u000a    must choose the intensity, alpha, and beta ranges carefully so as to avoid a Memory Error. Maximum likelihood\u000a    is used to estimate Lambda, the most likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of the Psi procedure. If the\u000a    estimated alpha or beta values equal your specified search bounds, then the search range most likely did\u000a    not contain the true value. In this situation the procedure should be repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior from existing research. A function\u000a    to save the posterior over Lambda as a Numpy binary file is included.\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 extraInfo=None,\u000a                 stepType='lin',\u000a                 TwoAFC=False,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 name=''):\u000a\u000a\u000a        """\u000a        Initializes the handler and creates an internal Psi Object for grid approximation.\u000a\u000a        Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the stimuli intensity range.\u000a                If stepType == 'log', this specifies the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in logging system.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli intensity range. If 'lin' then evenly spaced steps are used. If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            TwoAFC  (bool)\u000a                If True then the d' based psychometric function from Kontsevich & Tyler (1999) will be used. If False then a Yes/No task is assumed.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the Psi Object. This can either be a numpy.ndarray object or the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in logging system.\u000a        """\u000a        # Initialize parent class first\u000a        StairHandler.__init__(self, startVal=None, nTrials=nTrials, extraInfo=extraInfo, method=None, stepType=stepType, minVal=intensRange[0], maxVal=intensRange[1], name=name)\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be read. Using a uniform prior instead.")\u000a                prior = None\u000a        self._psi = PsiObject(intensRange, alphaRange, betaRange, intensPrecision, alphaPrecision, betaPrecision, delta, stepType, TwoAFC, prior)\u000a        self._psi.update(None)\u000a\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        #add the current data to experiment if possible\u000a        if self.getExp() is not None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it."""\u000a        self._checkFinished()\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)"""\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability. The optional argument 'lamb' allows thresholds to be estimated without having to recompute the maximum likelihood lambda."""\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    warnings.warn("Invalid user-specified lambda pair. A new estimate of lambda will be computed.", SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                warnings.warn("Invalid user-specified lambda pair. A new estimate of lambda will be computed.", SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """\u000a        Saves the posterior array over probLambda as a pickle file with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest','QUEST']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type in ['QUEST','quest']:\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple', 'QUEST' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type in ['QUEST','quest']:\u000a            # fp added alternatives since the builder creates 'QUEST' but\u000a            # the API spec wants 'quest'?\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys():\u000a                    val=condition[paramName]\u000a                else:\u000a                    val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type in ['QUEST','quest']:\u000a                # see above\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError("MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append=appendFile\u000a        for thisStair in self.staircases:\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True #never print info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" % label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead")\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params is None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax-rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin) / (rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError("name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name)))\u000a        else:\u000a            raise AttributeError("name %s (type %s) could not be converted to a string" % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p65
sS'nDown'
p66
I3
sg52
NsS'reversalIntensities'
p67
(lp68
F0.0006309573444801932
aF0.01258925411794168
aF0.010000000000000005
aF0.019952623149688795
asS'stepSizes'
p69
(lp70
I4
aI2
aI2
aI1
asS'nUp'
p71
I1
sS'startVal'
p72
F0.001
sS'_nextIntensity'
p73
F0.017782794100389229
sS'_warnUseOfNext'
p74
I01
sS'method'
p75
S'2AFC'
p76
sS'maxVal'
p77
I1
sS'stepSizeCurrent'
p78
I1
sS'correctCounter'
p79
I0
sS'nReversals'
p80
I4
sS'minVal'
p81
I0
sS'otherData'
p82
(dp83
S'resp.rt'
p84
(lp85
F1.6284960324992426
aF0.89437758071653661
aF1.1079980596423411
aF1.2281296948713134
aF1.9355329086556594
aF0.46726521534219501
aF0.53407172381230339
aF0.64081132797036844
aF0.61410424019959464
aF0.38725684777637071
aF0.38725382917255047
aF0.34705781318552908
aF0.50734833558817627
aF0.73421444334962871
aF0.73420508568233345
aF0.2404428773206746
aF0.88108667283813702
aF0.33382305131817702
aF0.4673035515970696
aF0.53399957920737506
aF0.49395177661244816
aF0.40052270125124778
aF0.22703243277283036
aF0.17365327302468359
aF0.52061388720176183
aF0.29373811991172261
aF0.17366746045809123
aF0.13346540726706735
aF0.32048173277507885
aF0.4672763841736014
aF0.14698512523136742
aF0.48067988593356858
aF0.44062453683181957
aF0.29371155620719946
aF0.62744736990680394
aF0.33380524156200408
aF0.3738542515966401
aF0.24036258248816011
aF0.32055478296206275
aF0.17356573354663851
aF0.2536655647745647
aF0.17363999117333151
aF0.22702911231135658
aF0.17366172511356126
asS'side'
p86
(lp87
S'left'
p88
ag88
aS'right'
p89
ag89
ag88
ag89
ag88
ag89
ag88
ag88
ag89
ag88
ag89
ag89
ag89
ag89
ag89
ag88
ag88
ag89
ag89
ag88
ag89
ag89
ag89
ag89
ag88
ag89
ag88
ag88
ag88
ag89
ag89
ag89
ag89
ag89
ag89
ag89
ag89
ag89
ag88
ag89
ag88
ag88
assS'finished'
p90
I01
sS'stepType'
p91
S'db'
p92
sS'data'
p93
(lp94
I1
aI0
aI1
aI1
aI0
aI0
aI0
aI1
aI1
aI0
aI1
aI1
aI0
aI0
aI1
aI1
aI0
aI1
aI1
aI0
aI1
aI0
aI1
aI1
aI0
aI0
aI0
aI1
aI1
aI1
aI1
aI1
aI0
aI0
aI1
aI0
aI1
aI0
aI1
aI0
aI0
aI1
aI1
aI1
asS'condition'
p95
(dp96
VmaxVal
p97
I1
sVminVal
p98
I0
sVlabel
p99
Vlow_8
p100
sVstepSizes
p101
(lp102
I4
aI2
aI2
aI1
asVstartVal
p103
F0.001
sVsf
p104
I8
ssS'reversalPoints'
p105
(lp106
I1
aI29
aI32
aI43
asg6
S'C:\\Program Files (x86)\\PsychoPy2\\lib\\site-packages\\psychopy-1.82.01-py2.7.egg\\psychopy\\data.py'
p107
sg11
S''
sg32
NsS'currentDirection'
p108
S'down'
p109
sS'_variableStep'
p110
I01
sS'intensities'
p111
(lp112
F0.001
aF0.0006309573444801932
aF0.00079432823472428153
aF0.00079432823472428153
aF0.00079432823472428153
aF0.001
aF0.0012589254117941673
aF0.0015848931924611136
aF0.0015848931924611136
aF0.0015848931924611136
aF0.0019952623149688798
aF0.0019952623149688798
aF0.0019952623149688798
aF0.0025118864315095803
aF0.0031622776601683798
aF0.0031622776601683798
aF0.0031622776601683798
aF0.0039810717055349734
aF0.0039810717055349734
aF0.0039810717055349734
aF0.0050118723362727246
aF0.0050118723362727246
aF0.0063095734448019355
aF0.0063095734448019355
aF0.0063095734448019355
aF0.007943282347242819
aF0.010000000000000005
aF0.01258925411794168
aF0.01258925411794168
aF0.01258925411794168
aF0.010000000000000005
aF0.010000000000000005
aF0.010000000000000005
aF0.011220184543019639
aF0.012589254117941677
aF0.012589254117941677
aF0.014125375446227547
aF0.014125375446227547
aF0.015848931924611138
aF0.015848931924611138
aF0.017782794100389229
aF0.019952623149688795
aF0.019952623149688795
aF0.019952623149688795
asS'initialRule'
p113
I0
sS'nTrials'
p114
I40
sS'thisTrialN'
p115
I43
sg31
I01
sbsg90
I01
sS'staircases'
p116
(lp117
g1
(g62
g3
NtRp118
(dp119
g50
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle, string, sys, os, time, copy\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import QuestObject    #used for QuestHandler\u000afrom contrib.psi import PsiObject   #used for PsiHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000a\u000atry:\u000a    #import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept ImportError:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False,\u000a                   encoding='utf-8',\u000a                   fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        print "saved data to %r" %f.name\u000a\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle for later use:\u000a        # We are going to set self.savePickle to False before saving,\u000a        # so PsychoPy won't try to save it again after loading from\u000a        # disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle is restored.\u000a        #\u000a        # See https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        # for details.\u000a        savePickle = self.savePickle\u000a        self.savePickle = False\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self,fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .tsv appended and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in Excel (xlsx) format, but was not found.')\u000a            #return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList): #user has hopefully specified a filename\u000a            self.trialList = importConditions(trialList) #import conditions from that file\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry)==dict:\u000a                self.trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try:\u000a            data = self.data\u000a        except:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum':\u000a                    heading ='n'\u000a                elif heading=='order_raw':\u000a                    heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str:\u000a            dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list:\u000a            dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go through standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. This should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   encoding='utf-8',\u000a                   fileCollisionMethod='rename'\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a        Also, return a pandas DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a             encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns = header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        if parameterName == "TrialNumber":\u000a                            nextEntry[parameterName] = trialCount\u000a                        else:\u000a                            nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a        df= df.convert_objects() # Converts numbers to numeric, such as float64, boolean to bool. Otherwise they all are "object" type, i.e. strings\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val)==0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            #nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except:\u000a        pass\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a        "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        "2:5"       # 2,3,4 (doesn't include last whole value)\u000a        "-10:2:"    #tenth from last to the last in steps of 2\u000a        slice(-10,2,None) #the same as above\u000a        random(5)*8 #5 random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError('Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name))\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError('Conditions file not found: %s' %os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        trialsArr = read_csv(fileName) # use pandas reader, which can handle commas in fields, etc\u000a        trialsArr = trialsArr.to_records(index=False) # convert the resulting dataframe to a numpy recarry\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    #if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection)>0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except:\u000a                    raise TypeError, "importConditions() was given some `indices` but could not parse them"\u000a    #the selection might now be a slice or a series of indices\u000a    if isinstance(selection,slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection)>0:\u000a        allConds = trialList\u000a        trialList=[]\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size\u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                   fileCollisionMethod='rename'\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in Excel (xlsx) format, but was not found.')\u000a            #return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """\u000a    Handler to implement the "Psi" adaptive psychophysical method (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function to be a cumulative Gaussian.\u000a    Psi estimates the two free parameters of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution. It chooses stimuli to present by\u000a    minimizing the entropy of this grid. Because this grid is represented internally as a 4-D array, one\u000a    must choose the intensity, alpha, and beta ranges carefully so as to avoid a Memory Error. Maximum likelihood\u000a    is used to estimate Lambda, the most likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of the Psi procedure. If the\u000a    estimated alpha or beta values equal your specified search bounds, then the search range most likely did\u000a    not contain the true value. In this situation the procedure should be repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior from existing research. A function\u000a    to save the posterior over Lambda as a Numpy binary file is included.\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 extraInfo=None,\u000a                 stepType='lin',\u000a                 TwoAFC=False,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 name=''):\u000a\u000a\u000a        """\u000a        Initializes the handler and creates an internal Psi Object for grid approximation.\u000a\u000a        Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the stimuli intensity range.\u000a                If stepType == 'log', this specifies the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in logging system.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli intensity range. If 'lin' then evenly spaced steps are used. If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            TwoAFC  (bool)\u000a                If True then the d' based psychometric function from Kontsevich & Tyler (1999) will be used. If False then a Yes/No task is assumed.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the Psi Object. This can either be a numpy.ndarray object or the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in logging system.\u000a        """\u000a        # Initialize parent class first\u000a        StairHandler.__init__(self, startVal=None, nTrials=nTrials, extraInfo=extraInfo, method=None, stepType=stepType, minVal=intensRange[0], maxVal=intensRange[1], name=name)\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be read. Using a uniform prior instead.")\u000a                prior = None\u000a        self._psi = PsiObject(intensRange, alphaRange, betaRange, intensPrecision, alphaPrecision, betaPrecision, delta, stepType, TwoAFC, prior)\u000a        self._psi.update(None)\u000a\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        #add the current data to experiment if possible\u000a        if self.getExp() is not None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it."""\u000a        self._checkFinished()\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)"""\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability. The optional argument 'lamb' allows thresholds to be estimated without having to recompute the maximum likelihood lambda."""\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    warnings.warn("Invalid user-specified lambda pair. A new estimate of lambda will be computed.", SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                warnings.warn("Invalid user-specified lambda pair. A new estimate of lambda will be computed.", SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """\u000a        Saves the posterior array over probLambda as a pickle file with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest','QUEST']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type in ['QUEST','quest']:\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple', 'QUEST' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type in ['QUEST','quest']:\u000a            # fp added alternatives since the builder creates 'QUEST' but\u000a            # the API spec wants 'quest'?\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys():\u000a                    val=condition[paramName]\u000a                else:\u000a                    val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type in ['QUEST','quest']:\u000a                # see above\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError("MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append=appendFile\u000a        for thisStair in self.staircases:\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True #never print info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" % label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead")\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params is None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax-rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin) / (rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError("name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name)))\u000a        else:\u000a            raise AttributeError("name %s (type %s) could not be converted to a string" % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p120
sg66
I3
sg52
Nsg67
(lp121
F0.0039810717055349734
aF0.0031622776601683798
aF0.0063095734448019355
aF0.0056234132519034936
aF0.0063095734448019355
aF0.0056234132519034936
aF0.017782794100389226
asg69
(lp122
I4
aI2
aI2
aI1
asg71
I1
sg72
F0.001
sg73
F0.015848931924611134
sg74
I01
sg75
g76
sg77
I1
sg78
I1
sg79
I1
sg80
I4
sg81
I0
sg82
(dp123
g84
(lp124
F1.2146543503658904
aF1.8821410707769246
aF0.88102841380532482
aF1.0011995927306998
aF0.97441915291346959
aF0.37387175949152152
aF0.64077268985602132
aF0.34723259028396569
aF0.49397320869320538
aF0.60072066121756507
aF0.42725423970296106
aF0.52064226206857711
aF0.77428035755838209
aF0.62749838429408555
aF0.34716889776609605
aF0.94775855162515654
aF0.40057914912358683
aF0.17360950328475155
aF0.53398780665520462
aF0.42716820952591661
aF1.3215376400148671
aF0.37382768789211696
aF0.20031538361581624
aF0.25370571219355043
aF0.16034183864940132
aF0.066844241004218929
aF0.26708446141128661
aF0.26705970886723662
aF0.34713569313680637
aF0.29373238456537365
aF0.69419471376386355
aF0.26704612515459303
aF0.30711868028993194
aF0.34710852571151918
aF0.22704541276470991
aF0.13355566348764114
aF0.90770773043186637
aF0.96113850828442082
aF0.70756470903324953
aF0.36054251536006632
asg86
(lp125
g88
ag88
ag88
ag88
ag88
ag88
ag89
ag88
ag88
ag88
ag89
ag88
ag89
ag89
ag88
ag89
ag89
ag89
ag88
ag88
ag88
ag88
ag89
ag89
ag89
ag88
ag89
ag88
ag88
ag88
ag88
ag89
ag88
ag88
ag88
ag88
ag89
ag88
ag89
ag89
assg90
I01
sg91
g92
sg93
(lp126
I0
aI0
aI0
aI1
aI1
aI0
aI1
aI1
aI0
aI0
aI1
aI1
aI1
aI0
aI1
aI1
aI1
aI0
aI1
aI1
aI0
aI0
aI1
aI1
aI0
aI0
aI1
aI0
aI1
aI1
aI0
aI0
aI1
aI1
aI0
aI0
aI1
aI1
aI1
aI1
asg95
(dp127
g97
I1
sg98
I0
sg99
Vlow_2
p128
sg101
(lp129
I4
aI2
aI2
aI1
asg103
F0.001
sg104
I2
ssg105
(lp130
I3
aI5
aI12
aI13
aI16
aI17
aI38
asg6
g107
sg11
S''
sg32
Nsg108
g109
sg110
I01
sg111
(lp131
F0.001
aF0.0015848931924611136
aF0.0025118864315095807
aF0.0039810717055349734
aF0.0031622776601683798
aF0.0031622776601683798
aF0.0039810717055349734
aF0.0039810717055349734
aF0.0039810717055349734
aF0.0050118723362727246
aF0.0063095734448019355
aF0.0063095734448019355
aF0.0063095734448019355
aF0.0056234132519034936
aF0.0063095734448019355
aF0.0063095734448019355
aF0.0063095734448019355
aF0.0056234132519034936
aF0.0063095734448019355
aF0.0063095734448019355
aF0.0063095734448019355
aF0.0070794578438413821
aF0.0079432823472428173
aF0.0079432823472428173
aF0.0079432823472428173
aF0.0089125093813374572
aF0.010000000000000002
aF0.010000000000000002
aF0.011220184543019636
aF0.011220184543019636
aF0.011220184543019636
aF0.012589254117941673
aF0.014125375446227544
aF0.014125375446227544
aF0.014125375446227544
aF0.015848931924611134
aF0.017782794100389226
aF0.017782794100389226
aF0.017782794100389226
aF0.015848931924611134
asg113
I0
sg114
I40
sg115
I39
sg31
I01
sbag1
(g62
g3
NtRp132
(dp133
g50
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle, string, sys, os, time, copy\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import QuestObject    #used for QuestHandler\u000afrom contrib.psi import PsiObject   #used for PsiHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000a\u000atry:\u000a    #import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept ImportError:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False,\u000a                   encoding='utf-8',\u000a                   fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        print "saved data to %r" %f.name\u000a\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle for later use:\u000a        # We are going to set self.savePickle to False before saving,\u000a        # so PsychoPy won't try to save it again after loading from\u000a        # disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle is restored.\u000a        #\u000a        # See https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        # for details.\u000a        savePickle = self.savePickle\u000a        self.savePickle = False\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self,fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .tsv appended and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in Excel (xlsx) format, but was not found.')\u000a            #return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList): #user has hopefully specified a filename\u000a            self.trialList = importConditions(trialList) #import conditions from that file\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry)==dict:\u000a                self.trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try:\u000a            data = self.data\u000a        except:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum':\u000a                    heading ='n'\u000a                elif heading=='order_raw':\u000a                    heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str:\u000a            dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list:\u000a            dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go through standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. This should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   encoding='utf-8',\u000a                   fileCollisionMethod='rename'\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a        Also, return a pandas DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a             encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns = header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        if parameterName == "TrialNumber":\u000a                            nextEntry[parameterName] = trialCount\u000a                        else:\u000a                            nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a        df= df.convert_objects() # Converts numbers to numeric, such as float64, boolean to bool. Otherwise they all are "object" type, i.e. strings\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val)==0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            #nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except:\u000a        pass\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a        "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        "2:5"       # 2,3,4 (doesn't include last whole value)\u000a        "-10:2:"    #tenth from last to the last in steps of 2\u000a        slice(-10,2,None) #the same as above\u000a        random(5)*8 #5 random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError('Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name))\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError('Conditions file not found: %s' %os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        trialsArr = read_csv(fileName) # use pandas reader, which can handle commas in fields, etc\u000a        trialsArr = trialsArr.to_records(index=False) # convert the resulting dataframe to a numpy recarry\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    #if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection)>0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except:\u000a                    raise TypeError, "importConditions() was given some `indices` but could not parse them"\u000a    #the selection might now be a slice or a series of indices\u000a    if isinstance(selection,slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection)>0:\u000a        allConds = trialList\u000a        trialList=[]\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size\u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                   fileCollisionMethod='rename'\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in Excel (xlsx) format, but was not found.')\u000a            #return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """\u000a    Handler to implement the "Psi" adaptive psychophysical method (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function to be a cumulative Gaussian.\u000a    Psi estimates the two free parameters of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution. It chooses stimuli to present by\u000a    minimizing the entropy of this grid. Because this grid is represented internally as a 4-D array, one\u000a    must choose the intensity, alpha, and beta ranges carefully so as to avoid a Memory Error. Maximum likelihood\u000a    is used to estimate Lambda, the most likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of the Psi procedure. If the\u000a    estimated alpha or beta values equal your specified search bounds, then the search range most likely did\u000a    not contain the true value. In this situation the procedure should be repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior from existing research. A function\u000a    to save the posterior over Lambda as a Numpy binary file is included.\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 extraInfo=None,\u000a                 stepType='lin',\u000a                 TwoAFC=False,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 name=''):\u000a\u000a\u000a        """\u000a        Initializes the handler and creates an internal Psi Object for grid approximation.\u000a\u000a        Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the stimuli intensity range.\u000a                If stepType == 'log', this specifies the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in logging system.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli intensity range. If 'lin' then evenly spaced steps are used. If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            TwoAFC  (bool)\u000a                If True then the d' based psychometric function from Kontsevich & Tyler (1999) will be used. If False then a Yes/No task is assumed.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the Psi Object. This can either be a numpy.ndarray object or the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in logging system.\u000a        """\u000a        # Initialize parent class first\u000a        StairHandler.__init__(self, startVal=None, nTrials=nTrials, extraInfo=extraInfo, method=None, stepType=stepType, minVal=intensRange[0], maxVal=intensRange[1], name=name)\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be read. Using a uniform prior instead.")\u000a                prior = None\u000a        self._psi = PsiObject(intensRange, alphaRange, betaRange, intensPrecision, alphaPrecision, betaPrecision, delta, stepType, TwoAFC, prior)\u000a        self._psi.update(None)\u000a\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        #add the current data to experiment if possible\u000a        if self.getExp() is not None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it."""\u000a        self._checkFinished()\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)"""\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability. The optional argument 'lamb' allows thresholds to be estimated without having to recompute the maximum likelihood lambda."""\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    warnings.warn("Invalid user-specified lambda pair. A new estimate of lambda will be computed.", SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                warnings.warn("Invalid user-specified lambda pair. A new estimate of lambda will be computed.", SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """\u000a        Saves the posterior array over probLambda as a pickle file with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest','QUEST']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type in ['QUEST','quest']:\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple', 'QUEST' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type in ['QUEST','quest']:\u000a            # fp added alternatives since the builder creates 'QUEST' but\u000a            # the API spec wants 'quest'?\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys():\u000a                    val=condition[paramName]\u000a                else:\u000a                    val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type in ['QUEST','quest']:\u000a                # see above\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError("MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append=appendFile\u000a        for thisStair in self.staircases:\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True #never print info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" % label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead")\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params is None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax-rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin) / (rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError("name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name)))\u000a        else:\u000a            raise AttributeError("name %s (type %s) could not be converted to a string" % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p134
sg66
I3
sg52
Nsg67
(lp135
F0.0063095734448019311
aF0.015848931924611134
aF0.012589254117941671
aF0.014125375446227542
aF0.012589254117941671
aF0.014125375446227542
aF0.012589254117941671
aF0.014125375446227542
aF0.012589254117941671
aF0.015848931924611131
aF0.01412537544622754
asg69
(lp136
I4
aI2
aI2
aI1
asg71
I1
sg72
F0.10000000000000001
sg73
F0.015848931924611131
sg74
I01
sg75
g76
sg77
I1
sg78
I1
sg79
I1
sg80
I4
sg81
I0
sg82
(dp137
g84
(lp138
F1.1213103995996789
aF1.0278396675184922
aF1.107909916441713
aF1.3749080458146636
aF0.77425107711314922
aF0.65420215159974759
aF0.26711072325451823
aF0.25379898701794446
aF0.53396275225350109
aF0.52066158112575067
aF0.29370853760519822
aF0.30712079331351561
aF0.3471695014868601
aF0.41391624162315566
aF0.62742261736457294
aF0.56070847813680302
aF0.18698855436377926
aF0.52071591597450606
aF0.5206630904267513
aF1.4281785358634806
aF0.52066037368422258
aF0.10692675752761716
aF0.36051927211883594
aF0.29380966079770587
aF0.36053255397018802
aF1.0679161468378879
aF0.1602844851968257
aF0.20038269845645118
aF0.24037375131774752
aF0.42723250576273131
aF0.080202463723253459
aF0.29377826732888934
aF0.4539643460757361
aF0.17361614421133709
aF0.18694176602002699
aF0.16031648238458729
aF0.56073987160743854
aF0.24040242804403533
aF0.22703756439841527
aF0.25371597544290125
asg86
(lp139
g89
ag88
ag88
ag88
ag89
ag89
ag89
ag88
ag89
ag89
ag89
ag89
ag88
ag88
ag89
ag88
ag89
ag88
ag88
ag88
ag88
ag88
ag89
ag89
ag89
ag88
ag89
ag88
ag89
ag89
ag88
ag88
ag89
ag88
ag89
ag89
ag89
ag88
ag89
ag88
assg90
I01
sg91
g92
sg93
(lp140
I1
aI1
aI1
aI1
aI1
aI1
aI0
aI0
aI1
aI0
aI1
aI1
aI0
aI1
aI1
aI1
aI0
aI1
aI1
aI1
aI1
aI0
aI1
aI1
aI1
aI1
aI1
aI0
aI1
aI1
aI1
aI0
aI1
aI1
aI0
aI1
aI1
aI1
aI0
aI1
asg95
(dp141
g97
I1
sg98
I0
sg99
Vhigh_2
p142
sg101
(lp143
I4
aI2
aI2
aI1
asg103
F0.10000000000000001
sg104
I2
ssg105
(lp144
I6
aI15
aI16
aI19
aI21
aI24
aI27
aI30
aI31
aI37
aI38
asg6
g107
sg11
S''
sg32
Nsg108
S'up'
p145
sg110
I01
sg111
(lp146
F0.10000000000000001
aF0.063095734448019331
aF0.039810717055349727
aF0.025118864315095801
aF0.015848931924611134
aF0.0099999999999999985
aF0.0063095734448019311
aF0.0079432823472428138
aF0.0099999999999999985
aF0.0099999999999999985
aF0.012589254117941671
aF0.012589254117941671
aF0.012589254117941671
aF0.015848931924611134
aF0.015848931924611134
aF0.015848931924611134
aF0.012589254117941671
aF0.014125375446227542
aF0.014125375446227542
aF0.014125375446227542
aF0.012589254117941671
aF0.012589254117941671
aF0.014125375446227542
aF0.014125375446227542
aF0.014125375446227542
aF0.012589254117941671
aF0.012589254117941671
aF0.012589254117941671
aF0.014125375446227542
aF0.014125375446227542
aF0.014125375446227542
aF0.012589254117941671
aF0.014125375446227542
aF0.014125375446227542
aF0.014125375446227542
aF0.015848931924611131
aF0.015848931924611131
aF0.015848931924611131
aF0.01412537544622754
aF0.015848931924611131
asg113
I0
sg114
I40
sg115
I39
sg31
I01
sbag63
ag1
(g62
g3
NtRp147
(dp148
g50
V# -*- coding: utf-8 -*-\u000a"""Routines for handling data structures and analysis"""\u000a# Part of the PsychoPy library\u000a# Copyright (C) 2015 Jonathan Peirce\u000a# Distributed under the terms of the GNU General Public License (GPL).\u000a\u000afrom psychopy import logging\u000afrom psychopy.tools.arraytools import extendArr, shuffleArray\u000afrom psychopy.tools.fileerrortools import handleFileCollision\u000afrom psychopy.tools.filetools import openOutputFile, genDelimiter\u000aimport psychopy\u000afrom pandas import DataFrame, read_csv\u000aimport cPickle, string, sys, os, time, copy\u000aimport numpy\u000afrom scipy import optimize, special\u000afrom contrib.quest import QuestObject    #used for QuestHandler\u000afrom contrib.psi import PsiObject   #used for PsiHandler\u000aimport inspect #so that Handlers can find the script that called them\u000aimport codecs\u000aimport weakref\u000aimport re\u000aimport warnings\u000a\u000atry:\u000a    #import openpyxl\u000a    from openpyxl.cell import get_column_letter\u000a    from openpyxl.reader.excel import load_workbook\u000a    haveOpenpyxl=True\u000aexcept ImportError:\u000a    haveOpenpyxl=False\u000a\u000a_experiments=weakref.WeakValueDictionary()\u000a_nonalphanumeric_re = re.compile(r'\u005cW') # will match all bad var name chars\u000a\u000a\u000aclass ExperimentHandler(object):\u000a    """A container class for keeping track of multiple loops/handlers\u000a\u000a    Useful for generating a single data file from an experiment with many\u000a    different loops (e.g. interleaved staircases or loops within loops\u000a\u000a    :usage:\u000a\u000a        exp = data.ExperimentHandler(name="Face Preference",version='0.1.0')\u000a\u000a    """\u000a    def __init__(self,\u000a                name='',\u000a                version='',\u000a                extraInfo=None,\u000a                runtimeInfo=None,\u000a                originPath=None,\u000a                savePickle=True,\u000a                saveWideText=True,\u000a                dataFileName='',\u000a                autoLog=True):\u000a        """\u000a        :parameters:\u000a\u000a            name : a string or unicode\u000a                As a useful identifier later\u000a\u000a            version : usually a string (e.g. '1.1.0')\u000a                To keep track of which version of the experiment was run\u000a\u000a            extraInfo : a dictionary\u000a                Containing useful information about this run\u000a                (e.g. {'participant':'jwp','gender':'m','orientation':90} )\u000a\u000a            runtimeInfo : :class:`psychopy.info.RunTimeInfo`\u000a                Containining information about the system as detected at runtime\u000a\u000a            originPath : string or unicode\u000a                The path and filename of the originating script/experiment\u000a                If not provided this will be determined as the path of the\u000a                calling script.\u000a\u000a            dataFileName : string\u000a                This is defined in advance and the file will be saved at any\u000a                point that the handler is removed or discarded (unless .abort()\u000a                had been called in advance).\u000a                The handler will attempt to populate the file even in the\u000a                event of a (not too serious) crash!\u000a\u000a            savePickle : True (default) or False\u000a\u000a            saveWideText : True (default) or False\u000a\u000a            autoLog : True (default) or False\u000a        """\u000a        self.loops=[]\u000a        self.loopsUnfinished=[]\u000a        self.name=name\u000a        self.version=version\u000a        self.runtimeInfo=runtimeInfo\u000a        if extraInfo is None:\u000a            self.extraInfo = {}\u000a        else:\u000a            self.extraInfo=extraInfo\u000a        self.originPath=originPath\u000a        self.savePickle=savePickle\u000a        self.saveWideText=saveWideText\u000a        self.dataFileName=dataFileName\u000a        self.thisEntry = {}\u000a        self.entries=[]#chronological list of entries\u000a        self._paramNamesSoFar=[]\u000a        self.dataNames=[]#names of all the data (eg. resp.keys)\u000a        self.autoLog = autoLog\u000a        if dataFileName in ['', None]:\u000a            logging.warning('ExperimentHandler created with no dataFileName parameter. No data will be saved in the event of a crash')\u000a        else:\u000a            checkValidFilePath(dataFileName, makeValid=True) #fail now if we fail at all!\u000a    def __del__(self):\u000a        if self.dataFileName not in ['', None]:\u000a            if self.autoLog:\u000a                logging.debug('Saving data for %s ExperimentHandler' %self.name)\u000a            if self.savePickle==True:\u000a                self.saveAsPickle(self.dataFileName)\u000a            if self.saveWideText==True:\u000a                self.saveAsWideText(self.dataFileName+'.csv', delim=',')\u000a    def addLoop(self, loopHandler):\u000a        """Add a loop such as a :class:`~psychopy.data.TrialHandler` or :class:`~psychopy.data.StairHandler`\u000a        Data from this loop will be included in the resulting data files.\u000a        """\u000a        self.loops.append(loopHandler)\u000a        self.loopsUnfinished.append(loopHandler)\u000a        #keep the loop updated that is now owned\u000a        loopHandler.setExp(self)\u000a    def loopEnded(self, loopHandler):\u000a        """Informs the experiment handler that the loop is finished and not to\u000a        include its values in further entries of the experiment.\u000a\u000a        This method is called by the loop itself if it ends its iterations,\u000a        so is not typically needed by the user.\u000a        """\u000a        if loopHandler in self.loopsUnfinished:\u000a            self.loopsUnfinished.remove(loopHandler)\u000a    def _getAllParamNames(self):\u000a        """Returns the attribute names of loop parameters (trialN etc)\u000a        that the current set of loops contain, ready to build a wide-format\u000a        data file.\u000a        """\u000a        names=copy.deepcopy(self._paramNamesSoFar)\u000a        #get names (or identifiers) for all contained loops\u000a        for thisLoop in self.loops:\u000a            theseNames, vals = self._getLoopInfo(thisLoop)\u000a            for name in theseNames:\u000a                if name not in names:\u000a                    names.append(name)\u000a        return names\u000a    def _getExtraInfo(self):\u000a        """\u000a        Get the names and vals from the extraInfo dict (if it exists)\u000a        """\u000a        if type(self.extraInfo) != dict:\u000a            names=[]\u000a            vals=[]\u000a        else:\u000a            names=self.extraInfo.keys()\u000a            vals= self.extraInfo.values()\u000a        return names, vals\u000a    def _getLoopInfo(self, loop):\u000a        """Returns the attribute names and values for the current trial of a particular loop.\u000a        Does not return data inputs from the subject, only info relating to the trial\u000a        execution.\u000a        """\u000a        names=[]\u000a        vals=[]\u000a        name = loop.name\u000a        #standard attributes\u000a        for attr in ['thisRepN', 'thisTrialN', 'thisN','thisIndex', 'stepSizeCurrent']:\u000a            if hasattr(loop, attr):\u000a                if attr=='stepSizeCurrent':\u000a                    attrName=name+'.stepSize'\u000a                else:\u000a                    attrName = name+'.'+attr\u000a                #append the attribute name and the current value\u000a                names.append(attrName)\u000a                vals.append(getattr(loop,attr))\u000a        #method of constants\u000a        if hasattr(loop, 'thisTrial'):\u000a            trial = loop.thisTrial\u000a            if hasattr(trial,'items'):#is a TrialList object or a simple dict\u000a                for attr,val in trial.items():\u000a                    if attr not in self._paramNamesSoFar:\u000a                        self._paramNamesSoFar.append(attr)\u000a                    names.append(attr)\u000a                    vals.append(val)\u000a            elif trial==[]:#we haven't had 1st trial yet? Not actually sure why this occasionally happens (JWP)\u000a                pass\u000a            else:\u000a                names.append(name+'.thisTrial')\u000a                vals.append(trial)\u000a        #single StairHandler\u000a        elif hasattr(loop, 'intensities'):\u000a            names.append(name+'.intensity')\u000a            if len(loop.intensities)>0:\u000a                vals.append(loop.intensities[-1])\u000a            else:\u000a                vals.append(None)\u000a\u000a        return names, vals\u000a    def addData(self, name, value):\u000a        """Add the data with a given name to the current experiment.\u000a\u000a        Typically the user does not need to use this function; if you added\u000a        your data to the loop and had already added the loop to the\u000a        experiment then the loop will automatically inform the experiment\u000a        that it has received data.\u000a\u000a        Multiple data name/value pairs can be added to any given entry of\u000a        the data file and is considered part of the same entry until the\u000a        nextEntry() call is made.\u000a\u000a        e.g.::\u000a\u000a            #add some data for this trial\u000a            exp.addData('resp.rt', 0.8)\u000a            exp.addData('resp.key', 'k')\u000a            #end of trial - move to next line in data output\u000a            exp.nextEntry()\u000a        """\u000a        if name not in self.dataNames:\u000a            self.dataNames.append(name)\u000a        self.thisEntry[name]=value\u000a\u000a    def nextEntry(self):\u000a        """Calling nextEntry indicates to the ExperimentHandler that the\u000a        current trial has ended and so further\u000a        addData() calls correspond to the next trial.\u000a        """\u000a        this=self.thisEntry\u000a        #fetch data from each (potentially-nested) loop\u000a        for thisLoop in self.loopsUnfinished:\u000a            names, vals = self._getLoopInfo(thisLoop)\u000a            for n, name in enumerate(names):\u000a                this[name]=vals[n]\u000a        #add the extraInfo dict to the data\u000a        if type(self.extraInfo)==dict:\u000a            this.update(self.extraInfo)#NB update() really means mergeFrom()\u000a        self.entries.append(this)\u000a        #then create new empty entry for n\u000a        self.thisEntry = {}\u000a    def saveAsWideText(self, fileName, delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=False,\u000a                   encoding='utf-8',\u000a                   fileCollisionMethod='rename'):\u000a        """Saves a long, wide-format text file, with one line representing the attributes and data\u000a        for a single trial. Suitable for analysis in R and SPSS.\u000a\u000a        If `appendFile=True` then the data will be added to the bottom of an existing file. Otherwise, if the file exists\u000a        already it will be overwritten\u000a\u000a        If `matrixOnly=True` then the file will not contain a header row, which can be handy if you want to append data\u000a        to an existing file of the same format.\u000a\u000a        encoding:\u000a            The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        fileCollisionMethod:\u000a            Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        names = self._getAllParamNames()\u000a        names.extend(self.dataNames)\u000a        names.extend(self._getExtraInfo()[0]) #names from the extraInfo dictionary\u000a        #write a header line\u000a        if not matrixOnly:\u000a            for heading in names:\u000a                f.write(u'%s%s' %(heading,delim))\u000a            f.write('\u005cn')\u000a        #write the data for each entry\u000a\u000a        for entry in self.entries:\u000a            for name in names:\u000a                entry.keys()\u000a                if name in entry.keys():\u000a                    if ',' in unicode(entry[name]) or '\u005cn' in unicode(entry[name]):\u000a                        f.write(u'"%s"%s' %(entry[name],delim))\u000a                    else:\u000a                        f.write(u'%s%s' %(entry[name],delim))\u000a                else:\u000a                    f.write(delim)\u000a            f.write('\u005cn')\u000a        f.close()\u000a        print "saved data to %r" %f.name\u000a\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        # Store the current state of self.savePickle for later use:\u000a        # We are going to set self.savePickle to False before saving,\u000a        # so PsychoPy won't try to save it again after loading from\u000a        # disk.\u000a        #\u000a        # After saving, the initial state of self.savePickle is restored.\u000a        #\u000a        # See https://groups.google.com/d/msg/psychopy-dev/Z4m_UX88q8U/UGuh1eeyjMEJ\u000a        # for details.\u000a        savePickle = self.savePickle\u000a        self.savePickle = False\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a        self.savePickle = savePickle\u000a\u000a    def abort(self):\u000a        """Inform the ExperimentHandler that the run was aborted.\u000a\u000a        Experiment handler will attempt automatically to save data (even in the event of a crash if possible).\u000a        So if you quit your script early you may want to tell the Handler not to save out the data files for this run.\u000a        This is the method that allows you to do that.\u000a        """\u000a        self.savePickle=False\u000a        self.saveWideText=False\u000a\u000aclass TrialType(dict):\u000a    """This is just like a dict, except that you can access keys with obj.key\u000a    """\u000a    def __getattribute__(self, name):\u000a        try:#to get attr from dict in normal way (passing self)\u000a            return dict.__getattribute__(self, name)\u000a        except AttributeError:\u000a            try:\u000a                return self[name]\u000a            except KeyError:\u000a                raise AttributeError('TrialType has no attribute (or key) \u005c'%s\u005c'' %(name))\u000a\u000aclass _BaseTrialHandler(object):\u000a    def setExp(self, exp):\u000a        """Sets the ExperimentHandler that this handler is attached to\u000a\u000a        Do NOT attempt to set the experiment using::\u000a\u000a            trials._exp = myExperiment\u000a\u000a        because it needs to be performed using the `weakref` module.\u000a        """\u000a        #need to use a weakref to avoid creating a circular reference that\u000a        #prevents effective object deletion\u000a        expId=id(exp)\u000a        _experiments[expId] = exp\u000a        self._exp = expId\u000a    def getExp(self):\u000a        """Return the ExperimentHandler that this handler is attached to, if any.\u000a        Returns None if not attached\u000a        """\u000a        if self._exp is None or self._exp not in _experiments:\u000a            return None\u000a        else:\u000a            return _experiments[self._exp]\u000a    def _terminate(self):\u000a        """Remove references to ourself in experiments and terminate the loop\u000a        """\u000a        #remove ourself from the list of unfinished loops in the experiment\u000a        exp=self.getExp()\u000a        if exp!=None:\u000a            exp.loopEnded(self)\u000a        #and halt the loop\u000a        raise StopIteration\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of the handler (with data) to a pickle file.\u000a\u000a        This can be reloaded if necessary and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('.saveAsPickle() called but no trials completed. Nothing saved')\u000a            return -1\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsText(self,fileName,\u000a                   stimOut=None,\u000a                   dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   summarised=True,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'\u000a                   ):\u000a        """\u000a        Write a text file with the data and various chosen stimulus attributes\u000a\u000a         :Parameters:\u000a\u000a            fileName:\u000a                will have .tsv appended and can include path info.\u000a\u000a            stimOut:\u000a                the stimulus attributes to be output. To use this you need to\u000a                use a list of dictionaries and give here the names of dictionary keys\u000a                that you want as strings\u000a\u000a            dataOut:\u000a                a list of strings specifying the dataType and the analysis to\u000a                be performed,in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including;\u000a                'mean','std','median','max','min'...\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row or extraInfo attached\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        #loop through lines in the data matrix\u000a        for line in dataArray:\u000a            for cellN, entry in enumerate(line):\u000a                if delim in unicode(entry):#surround in quotes to prevent effect of delimiter\u000a                    f.write(u'"%s"' %unicode(entry))\u000a                else:\u000a                    f.write(unicode(entry))\u000a                if cellN<(len(line)-1):\u000a                    f.write(delim)\u000a            f.write("\u005cn")#add an EOL at end of each line\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a    def printAsText(self, stimOut=None,\u000a                    dataOut=('all_mean', 'all_std', 'all_raw'),\u000a                    delim='\u005ct',\u000a                    matrixOnly=False,\u000a                  ):\u000a        """Exactly like saveAsText() except that the output goes\u000a        to the screen instead of a file"""\u000a        if stimOut is None:\u000a            stimOut = []\u000a        self.saveAsText('stdout', stimOut, dataOut, delim, matrixOnly)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='rawData',\u000a                    stimOut=None,\u000a                    dataOut=('n','all_mean','all_std', 'all_raw'),\u000a                    matrixOnly=False,\u000a                    appendFile=True,\u000a                    fileCollisionMethod='rename'\u000a                    ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            stimOut: list of strings\u000a                the attributes of the trial characteristics to be output. To use this you need to have provided\u000a                a list of dictionaries specifying to trialList parameter of the TrialHandler\u000a                and give here the names of strings specifying entries in that dictionary\u000a\u000a            dataOut: list of strings\u000a                specifying the dataType and the analysis to\u000a                be performed, in the form `dataType_analysis`. The data can be any of the types that\u000a                you added using trialHandler.data.add() and the analysis can be either\u000a                'raw' or most things in the numpy library, including\u000a                'mean','std','median','max','min'. e.g. `rt_max` will give a column of max reaction\u000a                times across the trials assuming that `rt` values have been stored.\u000a                The default values will output the raw, mean and std of all datatypes found\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if stimOut is None:\u000a            stimOut = []\u000a\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            if self.autoLog:\u000a                logging.info('TrialHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in Excel (xlsx) format, but was not found.')\u000a            #return -1\u000a\u000a        #create the data array to be sent to the Excel file\u000a        dataArray = self._createOutputArray(stimOut=stimOut,\u000a            dataOut=dataOut,\u000a            matrixOnly=matrixOnly)\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #loop through lines in the data matrix\u000a        for lineN, line in enumerate(dataArray):\u000a            if line is None:\u000a                continue\u000a            for colN, entry in enumerate(line):\u000a                if entry in [None]:\u000a                    entry=''\u000a                try:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = float(entry)#if it can conver to a number (from numpy) then do it\u000a                except:\u000a                    ws.cell(_getExcelCellName(col=colN,row=lineN)).value = unicode(entry)#else treat as unicode\u000a\u000a        ew.save(filename = fileName)\u000a\u000a    def nextTrial(self):\u000a        """DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """\u000a        if self._warnUseOfNext:\u000a            logging.warning("""DEPRECATION WARNING: nextTrial() will be deprecated\u000a        please use next() instead.\u000a        jwp: 19/6/06\u000a        """)\u000a            self._warnUseOfNext=False\u000a        return self.next()\u000a    def getOriginPathAndFile(self, originPath=None):\u000a        """Attempts to determine the path of the script that created this data file\u000a        and returns both the path to that script and its contents.\u000a        Useful to store the entire experiment with the data.\u000a\u000a        If originPath is provided (e.g. from Builder) then this is used otherwise\u000a        the calling script is the originPath (fine from a standard python script).\u000a        """\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        if originPath is None or not os.path.isfile(originPath):\u000a            try:\u000a                originPath = inspect.getouterframes(inspect.currentframe())[2][1]\u000a                if self.autoLog:\u000a                    logging.debug("Using %s as origin file" %originPath)\u000a            except:\u000a                if self.autoLog:\u000a                    logging.debug("Failed to find origin file using inspect.getouterframes")\u000a                return '',''\u000a        if os.path.isfile(originPath):#do we NOW have a path?\u000a            origin = codecs.open(originPath, "r", encoding="utf-8").read()\u000a        else:\u000a            origin=None\u000a        return originPath, origin\u000a\u000aclass TrialHandler(_BaseTrialHandler):\u000a    """Class to handle trial sequencing and data storage.\u000a\u000a    Calls to .next() will fetch the next trial object given to this handler,\u000a    according to the method specified (random, sequential, fullRandom). Calls\u000a    will raise a StopIteration error if trials have finished.\u000a\u000a    See demo_trialHandler.py\u000a\u000a    The psydat file format is literally just a pickled copy of the TrialHandler object that\u000a    saved it. You can open it with::\u000a\u000a            from psychopy.tools.filetools import fromFile\u000a            dat = fromFile(path)\u000a\u000a    Then you'll find that `dat` has the following attributes that\u000a    """\u000a    def __init__(self,\u000a                 trialList,\u000a                 nReps,\u000a                 method='random',\u000a                 dataTypes=None,\u000a                 extraInfo=None,\u000a                 seed=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a\u000a        :Parameters:\u000a\u000a            trialList: a simple list (or flat array) of dictionaries specifying conditions\u000a                This can be imported from an excel/csv file using :func:`~psychopy.data.importConditions`\u000a\u000a            nReps: number of repeats for all conditions\u000a\u000a            method: *'random',* 'sequential', or 'fullRandom'\u000a                'sequential' obviously presents the conditions in the order they appear in the list.\u000a                'random' will result in a shuffle of the conditions on each repeat, but all conditions\u000a                occur once before the second repeat etc. 'fullRandom' fully randomises the\u000a                trials across repeats as well, which means you could potentially run all trials of\u000a                one condition before any trial of another.\u000a\u000a            dataTypes: (optional) list of names for data storage. e.g. ['corr','rt','resp']\u000a                If not provided then these will be created as needed during calls to\u000a                :func:`~psychopy.data.TrialHandler.addData`\u000a\u000a            extraInfo: A dictionary\u000a                This will be stored alongside the data and usually describes the experiment and\u000a                subject ID, date etc.\u000a\u000a            seed: an integer\u000a                If provided then this fixes the random number generator to use the same pattern\u000a                of trials, by seeding its startpoint\u000a\u000a            originPath: a string describing the location of the script/experiment file path\u000a                The psydat file format will store a copy of the experiment if possible. If no file path\u000a                is provided here then the TrialHandler will still store a copy of the script where it was\u000a                created\u000a\u000a        :Attributes (after creation):\u000a\u000a            .data - a dictionary of numpy arrays, one for each data type stored\u000a\u000a            .trialList - the original list of dicts, specifying the conditions\u000a\u000a            .thisIndex - the index of the current trial in the original conditions list\u000a\u000a            .nTotal - the total number of trials that will be run\u000a\u000a            .nRemaining - the total number of trials remaining\u000a\u000a            .thisN - total trials completed so far\u000a\u000a            .thisRepN - which repeat you are currently on\u000a\u000a            .thisTrialN - which trial number *within* that repeat\u000a\u000a            .thisTrial - a dictionary giving the parameters of the current trial\u000a\u000a            .finished - True/False for have we finished yet\u000a\u000a            .extraInfo - the dictionary of extra info as given at beginning\u000a\u000a            .origin - the contents of the script or builder experiment that created the handler\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a\u000a        if trialList in [None, []]:#user wants an empty trialList\u000a            self.trialList = [None]#which corresponds to a list with a single empty entry\u000a        elif isinstance(trialList, basestring) and os.path.isfile(trialList): #user has hopefully specified a filename\u000a            self.trialList = importConditions(trialList) #import conditions from that file\u000a        else:\u000a            self.trialList =trialList\u000a        #convert any entry in the TrialList into a TrialType object (with obj.key or obj[key] access)\u000a        for n, entry in enumerate(self.trialList):\u000a            if type(entry)==dict:\u000a                self.trialList[n]=TrialType(entry)\u000a        self.nReps = int(nReps)\u000a        self.nTotal = self.nReps*len(self.trialList)\u000a        self.nRemaining =self.nTotal #subtract 1 each trial\u000a        self.method = method\u000a        self.thisRepN = 0        #records which repetition or pass we are on\u000a        self.thisTrialN = -1    #records which trial number within this repetition\u000a        self.thisN = -1\u000a        self.thisIndex = 0        #the index of the current trial in the conditions list\u000a        self.thisTrial = []\u000a        self.finished=False\u000a        self.extraInfo=extraInfo\u000a        self._warnUseOfNext=True\u000a        self.seed=seed\u000a        #create dataHandler\u000a        self.data = DataHandler(trials=self)\u000a        if dataTypes!=None:\u000a            self.data.addDataType(dataTypes)\u000a        self.data.addDataType('ran')\u000a        self.data['ran'].mask=False#this is a bool - all entries are valid\u000a        self.data.addDataType('order')\u000a        #generate stimulus sequence\u000a        if self.method in ['random','sequential', 'fullRandom']:\u000a            self.sequenceIndices = self._createSequence()\u000a        else: self.sequenceIndices=[]\u000a\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a\u000a    def __iter__(self):\u000a        return self\u000a    def __repr__(self):\u000a        """prints a more verbose version of self as string"""\u000a        return self.__str__(verbose=True)\u000a\u000a    def __str__(self, verbose=False):\u000a        """string representation of the object"""\u000a        strRepres = 'psychopy.data.TrialHandler(\u005cn'\u000a        attribs = dir(self)\u000a\u000a        #print data first, then all others\u000a        try:\u000a            data = self.data\u000a        except:\u000a            data = None\u000a        if data:\u000a            strRepres += str('\u005ctdata=')\u000a            strRepres +=str(data)+'\u005cn'\u000a\u000a        for thisAttrib in attribs:\u000a            #can handle each attribute differently\u000a            if 'instancemethod' in str(type(getattr(self,thisAttrib))):\u000a                #this is a method\u000a                continue\u000a            elif thisAttrib[0]=='_':\u000a                #the attrib is private\u000a                continue\u000a            elif thisAttrib=='data':\u000a                #we handled this first\u000a                continue\u000a            elif len(str(getattr(self,thisAttrib)))>20 and \u005c\u000a                 not verbose:\u000a                #just give type of LONG public attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(type(getattr(self,thisAttrib)))+'\u005cn'\u000a            else:\u000a                #give the complete contents of attribute\u000a                strRepres += str('\u005ct'+thisAttrib+'=')\u000a                strRepres += str(getattr(self,thisAttrib))+'\u005cn'\u000a\u000a        strRepres+=')'\u000a        return strRepres\u000a\u000a    def _createSequence(self):\u000a        """\u000a        Pre-generates the sequence of trial presentations (for non-adaptive methods).\u000a        This is called automatically when the TrialHandler is initialised so doesn't\u000a        need an explicit call from the user.\u000a\u000a        The returned sequence has form indices[stimN][repN]\u000a        Example: sequential with 6 trialtypes (rows), 5 reps (cols), returns:\u000a            [[0 0 0 0 0]\u000a             [1 1 1 1 1]\u000a             [2 2 2 2 2]\u000a             [3 3 3 3 3]\u000a             [4 4 4 4 4]\u000a             [5 5 5 5 5]]\u000a        These 30 trials will be returned by .next() in the order:\u000a            0, 1, 2, 3, 4, 5,   0, 1, 2, ...  ... 3, 4, 5\u000a\u000a        To add a new type of sequence (as of v1.65.02):\u000a        - add the sequence generation code here\u000a        - adjust "if self.method in [ ...]:" in both __init__ and .next()\u000a        - adjust allowedVals in experiment.py -> shows up in DlgLoopProperties\u000a        Note that users can make any sequence whatsoever outside of PsychoPy, and\u000a        specify sequential order; any order is possible this way.\u000a        """\u000a        # create indices for a single rep\u000a        indices = numpy.asarray(self._makeIndices(self.trialList), dtype=int)\u000a\u000a        if self.method == 'random':\u000a            sequenceIndices = []\u000a            seed=self.seed\u000a            for thisRep in range(self.nReps):\u000a                thisRepSeq = shuffleArray(indices.flat, seed=seed).tolist()\u000a                seed=None#so that we only seed the first pass through!\u000a                sequenceIndices.append(thisRepSeq)\u000a            sequenceIndices = numpy.transpose(sequenceIndices)\u000a        elif self.method == 'sequential':\u000a            sequenceIndices = numpy.repeat(indices,self.nReps,1)\u000a        elif self.method == 'fullRandom':\u000a            # indices*nReps, flatten, shuffle, unflatten; only use seed once\u000a            sequential = numpy.repeat(indices, self.nReps,1) # = sequential\u000a            randomFlat = shuffleArray(sequential.flat, seed=self.seed)\u000a            sequenceIndices = numpy.reshape(randomFlat, (len(indices), self.nReps))\u000a        if self.autoLog:\u000a            logging.exp('Created sequence: %s, trialTypes=%d, nReps=%i, seed=%s' %\u000a                (self.method, len(indices), self.nReps, str(self.seed) )  )\u000a        return sequenceIndices\u000a\u000a    def _makeIndices(self,inputArray):\u000a        """\u000a        Creates an array of tuples the same shape as the input array\u000a        where each tuple contains the indices to itself in the array.\u000a\u000a        Useful for shuffling and then using as a reference.\u000a        """\u000a        inputArray  = numpy.asarray(inputArray, 'O')#make sure its an array of objects (can be strings etc)\u000a        #get some simple variables for later\u000a        dims=inputArray.shape\u000a        dimsProd=numpy.product(dims)\u000a        dimsN = len(dims)\u000a        dimsList = range(dimsN)\u000a        listOfLists = []\u000a        arrayOfTuples = numpy.ones(dimsProd, 'O')#this creates space for an array of any objects\u000a\u000a        #for each dimension create list of its indices (using modulo)\u000a        for thisDim in dimsList:\u000a            prevDimsProd = numpy.product(dims[:thisDim])\u000a            thisDimVals = numpy.arange(dimsProd)/prevDimsProd % dims[thisDim] #NB this means modulus in python\u000a            listOfLists.append(thisDimVals)\u000a\u000a        #convert to array\u000a        indexArr = numpy.asarray(listOfLists)\u000a        for n in range(dimsProd):\u000a            arrayOfTuples[n] = tuple((indexArr[:,n]))\u000a        return (numpy.reshape(arrayOfTuples,dims)).tolist()\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; thisTrial, thisTrialN and thisIndex\u000a        If the trials have ended this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            for eachTrial in trials:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            trials = data.TrialHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = trials.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        #update pointer for next trials\u000a        self.thisTrialN+=1#number of trial this pass\u000a        self.thisN+=1 #number of trial in total\u000a        self.nRemaining-=1\u000a        if self.thisTrialN==len(self.trialList):\u000a            #start a new repetition\u000a            self.thisTrialN=0\u000a            self.thisRepN+=1\u000a        if self.thisRepN>=self.nReps:\u000a            #all reps complete\u000a            self.thisTrial=[]\u000a            self.finished=True\u000a\u000a        if self.finished==True:\u000a            self._terminate()\u000a\u000a        #fetch the trial info\u000a        if self.method in ['random','sequential','fullRandom']:\u000a            self.thisIndex = self.sequenceIndices[self.thisTrialN][self.thisRepN]\u000a            self.thisTrial = self.trialList[self.thisIndex]\u000a            self.data.add('ran',1)\u000a            self.data.add('order',self.thisN)\u000a        if self.autoLog:\u000a            logging.exp('New trial (rep=%i, index=%i): %s' %(self.thisRepN, self.thisTrialN, self.thisTrial), obj=self.thisTrial)\u000a        return self.thisTrial\u000a\u000a    def getFutureTrial(self, n=1):\u000a        """Returns the condition for n trials into the future, without advancing\u000a        the trials. Returns 'None' if attempting to go beyond the last trial.\u000a        """\u000a        # check that we don't go out of bounds for either positive or negative offsets:\u000a        if n>self.nRemaining or self.thisN+n < 0:\u000a            return None\u000a        seqs = numpy.array(self.sequenceIndices).transpose().flat\u000a        condIndex=seqs[self.thisN+n]\u000a        return self.trialList[condIndex]\u000a\u000a    def getEarlierTrial(self, n=-1):\u000a        """Returns the condition information from n trials previously. Useful\u000a        for comparisons in n-back tasks. Returns 'None' if trying to access a trial\u000a        prior to the first.\u000a        """\u000a        # treat positive offset values as equivalent to negative ones:\u000a        if n > 0:\u000a            n = n * -1\u000a        return self.getFutureTrial(n)\u000a\u000a    def _createOutputArray(self,stimOut,dataOut,delim=None,\u000a                          matrixOnly=False):\u000a        """\u000a        Does the leg-work for saveAsText and saveAsExcel.\u000a        Combines stimOut with ._parseDataOutput()\u000a        """\u000a        if stimOut==[] and len(self.trialList) and hasattr(self.trialList[0],'keys'):\u000a            stimOut=self.trialList[0].keys()\u000a            #these get added somewhere (by DataHandler?)\u000a            if 'n' in stimOut:\u000a                stimOut.remove('n')\u000a            if 'float' in stimOut:\u000a                stimOut.remove('float')\u000a\u000a        lines=[]\u000a        #parse the dataout section of the output\u000a        dataOut, dataAnal, dataHead = self._createOutputArrayData(dataOut=dataOut)\u000a        if not matrixOnly:\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #write a header line\u000a            for heading in stimOut+dataHead:\u000a                if heading=='ran_sum':\u000a                    heading ='n'\u000a                elif heading=='order_raw':\u000a                    heading ='order'\u000a                thisLine.append(heading)\u000a\u000a        #loop through stimuli, writing data\u000a        for stimN in range(len(self.trialList)):\u000a            thisLine=[]\u000a            lines.append(thisLine)\u000a            #first the params for this stim (from self.trialList)\u000a            for heading in stimOut:\u000a                thisLine.append(self.trialList[stimN][heading])\u000a\u000a            #then the data for this stim (from self.data)\u000a            for thisDataOut in dataOut:\u000a                #make a string version of the data and then format it\u000a                tmpData = dataAnal[thisDataOut][stimN]\u000a                if hasattr(tmpData,'tolist'): #is a numpy array\u000a                    strVersion = unicode(tmpData.tolist())\u000a                    #for numeric data replace None with a blank cell\u000a                    if tmpData.dtype.kind not in ['SaUV']:\u000a                        strVersion=strVersion.replace('None','')\u000a                elif tmpData in [None,'None']:\u000a                    strVersion=''\u000a                else:\u000a                    strVersion = unicode(tmpData)\u000a\u000a                if strVersion=='()':\u000a                    strVersion="--"# 'no data' in masked array should show as "--"\u000a                #handle list of values (e.g. rt_raw )\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    strVersion=strVersion[1:-1]#skip first and last chars\u000a                #handle lists of lists (e.g. raw of multiple key presses)\u000a                if len(strVersion) and strVersion[0] in ["[", "("] and strVersion[-1] in ["]", ")"]:\u000a                    tup = eval(strVersion) #convert back to a tuple\u000a                    for entry in tup:\u000a                        #contents of each entry is a list or tuple so keep in quotes to avoid probs with delim\u000a                        thisLine.append(unicode(entry))\u000a                else:\u000a                    thisLine.extend(strVersion.split(','))\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            lines.append([])\u000a            lines.append(['extraInfo'])#give a single line of space and then a heading\u000a            for key, value in self.extraInfo.items():\u000a                lines.append([key,value])\u000a        return lines\u000a\u000a    def _createOutputArrayData(self, dataOut):\u000a        """This just creates the dataOut part of the output matrix.\u000a        It is called by _createOutputArray() which creates the header line and adds the stimOut columns\u000a        """\u000a        dataHead=[]#will store list of data headers\u000a        dataAnal=dict([])    #will store data that has been analyzed\u000a        if type(dataOut)==str:\u000a            dataOut=[dataOut]#don't do list convert or we get a list of letters\u000a        elif type(dataOut)!=list:\u000a            dataOut = list(dataOut)\u000a\u000a        #expand any 'all' dataTypes to be the full list of available dataTypes\u000a        allDataTypes=self.data.keys()\u000a        #treat these separately later\u000a        allDataTypes.remove('ran')\u000a        #ready to go through standard data types\u000a        dataOutNew=[]\u000a        for thisDataOut in dataOut:\u000a            if thisDataOut == 'n':\u000a                #n is really just the sum of the ran trials\u000a                dataOutNew.append('ran_sum')\u000a                continue#no need to do more with this one\u000a            #then break into dataType and analysis\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if dataType == 'all':\u000a                dataOutNew.extend([key+"_"+analType for key in allDataTypes])\u000a                if 'order_mean' in dataOutNew:\u000a                    dataOutNew.remove('order_mean')\u000a                if 'order_std' in dataOutNew:\u000a                    dataOutNew.remove('order_std')\u000a            else:\u000a                dataOutNew.append(thisDataOut)\u000a        dataOut=dataOutNew\u000a        dataOut.sort()#so that all datatypes come together, rather than all analtypes\u000a\u000a        #do the various analyses, keeping track of fails (e.g. mean of a string)\u000a        dataOutInvalid=[]\u000a        #add back special data types (n and order)\u000a        if 'ran_sum' in dataOut:#move n to the first column\u000a            dataOut.remove('ran_sum')\u000a            dataOut.insert(0,'ran_sum')\u000a        if 'order_raw' in dataOut:#move order_raw to the second column\u000a            dataOut.remove('order_raw')\u000a            dataOut.append('order_raw')\u000a        #do the necessary analysis on the data\u000a        for thisDataOutN,thisDataOut in enumerate(dataOut):\u000a            dataType, analType = string.rsplit(thisDataOut, '_', 1)\u000a            if not dataType in self.data:\u000a                dataOutInvalid.append(thisDataOut)#that analysis can't be done\u000a                continue\u000a            thisData = self.data[dataType]\u000a\u000a            #set the header\u000a            dataHead.append(dataType+'_'+analType)\u000a            #analyse thisData using numpy module\u000a            if analType in dir(numpy):\u000a                try:#this will fail if we try to take mean of a string for example\u000a                    if analType=='std':\u000a                        thisAnal = numpy.std(thisData,axis=1,ddof=0)\u000a                        #normalise by N-1 instead. This should work by setting ddof=1\u000a                        #but doesn't as of 08/2010 (because of using a masked array?)\u000a                        N=thisData.shape[1]\u000a                        if N == 1:\u000a                            thisAnal*=0 #prevent a divide-by-zero error\u000a                        else:\u000a                            thisAnal = thisAnal*numpy.sqrt(N)/numpy.sqrt(N-1)\u000a                    else:\u000a                        exec("thisAnal = numpy.%s(thisData,1)" %analType)\u000a                except:\u000a                    dataHead.remove(dataType+'_'+analType)#that analysis doesn't work\u000a                    dataOutInvalid.append(thisDataOut)\u000a                    continue#to next analysis\u000a            elif analType=='raw':\u000a                thisAnal=thisData\u000a            else:\u000a                raise AttributeError('You can only use analyses from numpy')\u000a            #add extra cols to header if necess\u000a            if len(thisAnal.shape)>1:\u000a                for n in range(thisAnal.shape[1]-1):\u000a                    dataHead.append("")\u000a            dataAnal[thisDataOut]=thisAnal\u000a\u000a        #remove invalid analyses (e.g. average of a string)\u000a        for invalidAnal in dataOutInvalid:\u000a            dataOut.remove(invalidAnal)\u000a        return dataOut, dataAnal, dataHead\u000a\u000a    def saveAsWideText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   appendFile=True,\u000a                   encoding='utf-8',\u000a                   fileCollisionMethod='rename'\u000a                  ):\u000a        """\u000a        Write a text file with the session, stimulus, and data values from each trial in chronological order.\u000a        Also, return a pandas DataFrame containing same information as the file.\u000a\u000a        That is, unlike 'saveAsText' and 'saveAsExcel':\u000a         - each row comprises information from only a single trial.\u000a         - no summarising is done (such as collapsing to produce mean and standard deviation values across trials).\u000a\u000a        This 'wide' format, as expected by R for creating dataframes, and various other analysis programs, means that some\u000a        information must be repeated on every row.\u000a\u000a        In particular, if the trialHandler's 'extraInfo' exists, then each entry in there occurs in every row.\u000a        In builder, this will include any entries in the 'Experiment info' field of the 'Experiment settings' dialog.\u000a        In Coder, this information can be set using something like::\u000a\u000a            myTrialHandler.extraInfo = {'SubjID':'Joan Smith', 'DOB':1970 Nov 16, 'Group':'Control'}\u000a\u000a        :Parameters:\u000a\u000a            fileName:\u000a                if extension is not specified, '.csv' will be appended if the delimiter is ',', else '.tsv' will be appended.\u000a                Can include path info.\u000a\u000a            delim:\u000a                allows the user to use a delimiter other than the default tab ("," is popular with file extension ".csv")\u000a\u000a            matrixOnly:\u000a                outputs the data with no header row.\u000a\u000a            appendFile:\u000a                will add this output to the end of the specified file if it already exists.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a             encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.thisTrialN<1 and self.thisRepN<1:#if both are <1 we haven't started\u000a            logging.info('TrialHandler.saveAsWideText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=appendFile, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        # collect parameter names related to the stimuli:\u000a        if self.trialList[0]:\u000a            header = self.trialList[0].keys()\u000a        else:\u000a            header = []\u000a        # and then add parameter names related to data (e.g. RT)\u000a        header.extend(self.data.dataTypes)\u000a        # get the extra 'wide' parameter names into the header line:\u000a        header.insert(0,"TrialNumber")\u000a        if (self.extraInfo != None):\u000a            for key in self.extraInfo:\u000a                header.insert(0, key)\u000a        df = DataFrame(columns = header)\u000a\u000a        # loop through each trial, gathering the actual values:\u000a        dataOut = []\u000a        trialCount = 0\u000a        # total number of trials = number of trialtypes * number of repetitions:\u000a\u000a        repsPerType={}\u000a        for rep in range(self.nReps):\u000a            for trialN in range(len(self.trialList)):\u000a                #find out what trial type was on this trial\u000a                trialTypeIndex = self.sequenceIndices[trialN, rep]\u000a                #determine which repeat it is for this trial\u000a                if trialTypeIndex not in repsPerType.keys():\u000a                    repsPerType[trialTypeIndex]=0\u000a                else:\u000a                    repsPerType[trialTypeIndex]+=1\u000a                repThisType=repsPerType[trialTypeIndex]#what repeat are we on for this trial type?\u000a\u000a                # create a dictionary representing each trial:\u000a                # this is wide format, so we want fixed information (e.g. subject ID, date, etc) repeated every line if it exists:\u000a                if (self.extraInfo != None):\u000a                    nextEntry = self.extraInfo.copy()\u000a                else:\u000a                    nextEntry = {}\u000a\u000a                # add a trial number so the original order of the data can always be recovered if sorted during analysis:\u000a                trialCount += 1\u000a\u000a                # now collect the value from each trial of the variables named in the header:\u000a                for parameterName in header:\u000a                    # the header includes both trial and data variables, so need to check before accessing:\u000a                    if self.trialList[trialTypeIndex] and parameterName in self.trialList[trialTypeIndex]:\u000a                        nextEntry[parameterName] = self.trialList[trialTypeIndex][parameterName]\u000a                    elif parameterName in self.data:\u000a                        nextEntry[parameterName] = self.data[parameterName][trialTypeIndex][repThisType]\u000a                    else: # allow a null value if this parameter wasn't explicitly stored on this trial:\u000a                        if parameterName == "TrialNumber":\u000a                            nextEntry[parameterName] = trialCount\u000a                        else:\u000a                            nextEntry[parameterName] = ''\u000a\u000a                #store this trial's data\u000a                dataOut.append(nextEntry)\u000a                df = df.append(nextEntry, ignore_index=True)\u000a\u000a        if not matrixOnly:\u000a        # write the header row:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + parameterName + delim\u000a            f.write(nextLine[:-1] + '\u005cn') # remove the final orphaned tab character\u000a\u000a        # write the data matrix:\u000a        for trial in dataOut:\u000a            nextLine = ''\u000a            for parameterName in header:\u000a                nextLine = nextLine + unicode(trial[parameterName]) + delim\u000a            nextLine = nextLine[:-1] # remove the final orphaned tab character\u000a            f.write(nextLine + '\u005cn')\u000a\u000a        if f != sys.stdout:\u000a            f.close()\u000a            logging.info('saved wide-format data to %s' %f.name)\u000a\u000a        df= df.convert_objects() # Converts numbers to numeric, such as float64, boolean to bool. Otherwise they all are "object" type, i.e. strings\u000a        return df\u000a\u000a    def addData(self, thisType, value, position=None):\u000a        """Add data for the current trial\u000a        """\u000a        self.data.add(thisType, value, position=None)\u000a        if self.getExp()!=None:#update the experiment handler too\u000a            self.getExp().addData(thisType, value)\u000a\u000a\u000adef importTrialTypes(fileName, returnFieldNames=False):\u000a    """importTrialTypes is DEPRECATED (as of v1.70.00)\u000a    Please use `importConditions` for identical functionality.\u000a    """\u000a    logging.warning("importTrialTypes is DEPRECATED (as of v1.70.00). Please use `importConditions` for identical functionality.")\u000a    return importConditions(fileName, returnFieldNames)\u000a\u000adef sliceFromString(sliceString):\u000a    """Convert a text string into a valid slice object\u000a    which can be used as indices for a list or array.\u000a\u000a    >>> sliceFromString("0:10")\u000a    slice(0,10,None)\u000a    >>> sliceFromString("0::3")\u000a    slice(0,None,3)\u000a    >>> sliceFromString("-8:")\u000a    slice(-8,None,None)\u000a    """\u000a    sliceArgs = []\u000a    for val in sliceString.split(':'):\u000a        if len(val)==0:\u000a            sliceArgs.append(None)\u000a        else:\u000a            sliceArgs.append(int(round(float(val))))\u000a            #nb int(round(float(x))) is needed for x='4.3'\u000a    return apply(slice, sliceArgs)\u000a\u000adef indicesFromString(indsString):\u000a    """Convert a text string into a valid list of indices\u000a    """\u000a    # "6"\u000a    try:\u000a        inds = int(round(float(indsString)))\u000a        return [inds]\u000a    except:\u000a        pass\u000a    # "-6::2"\u000a    try:\u000a        inds = sliceFromString(indsString)\u000a        return inds\u000a    except:\u000a        pass\u000a    # "1,4,8"\u000a    try:\u000a        inds = list(eval(indsString))\u000a        return inds\u000a    except:\u000a        pass\u000a\u000adef importConditions(fileName, returnFieldNames=False, selection=""):\u000a    """Imports a list of conditions from an .xlsx, .csv, or .pkl file\u000a\u000a    The output is suitable as an input to :class:`TrialHandler` `trialTypes` or to\u000a    :class:`MultiStairHandler` as a `conditions` list.\u000a\u000a    If `fileName` ends with:\u000a        - .csv:  import as a comma-separated-value file (header + row x col)\u000a        - .xlsx: import as Excel 2007 (xlsx) files. Sorry no support for older (.xls) is planned.\u000a        - .pkl:  import from a pickle file as list of lists (header + row x col)\u000a\u000a    The file should contain one row per type of trial needed and one column\u000a    for each parameter that defines the trial type. The first row should give\u000a    parameter names, which should:\u000a\u000a        - be unique\u000a        - begin with a letter (upper or lower case)\u000a        - contain no spaces or other punctuation (underscores are permitted)\u000a\u000a\u000a    `selection` is used to select a subset of condition indices to be used\u000a    It can be a list/array of indices, a python `slice` object or a string to\u000a    be parsed as either option.\u000a    e.g.:\u000a        "1,2,4" or [1,2,4] or (1,2,4) are the same\u000a        "2:5"       # 2,3,4 (doesn't include last whole value)\u000a        "-10:2:"    #tenth from last to the last in steps of 2\u000a        slice(-10,2,None) #the same as above\u000a        random(5)*8 #5 random vals 0-8\u000a\u000a    """\u000a    def _assertValidVarNames(fieldNames, fileName):\u000a        """screens a list of names as candidate variable names. if all names are\u000a        OK, return silently; else raise ImportError with msg\u000a        """\u000a        if not all(fieldNames):\u000a            raise ImportError('Conditions file %s: Missing parameter name(s); empty cell(s) in the first row?' % fileName)\u000a        for name in fieldNames:\u000a            OK, msg = isValidVariableName(name)\u000a            if not OK: #tailor message to importConditions\u000a                msg = msg.replace('Variables', 'Parameters (column headers)')\u000a                raise ImportError('Conditions file %s: %s%s"%s"' %(fileName, msg, os.linesep*2, name))\u000a\u000a    if fileName in ['None','none',None]:\u000a        if returnFieldNames:\u000a            return [], []\u000a        return []\u000a    if not os.path.isfile(fileName):\u000a        raise ImportError('Conditions file not found: %s' %os.path.abspath(fileName))\u000a\u000a    if fileName.endswith('.csv'):\u000a        trialsArr = read_csv(fileName) # use pandas reader, which can handle commas in fields, etc\u000a        trialsArr = trialsArr.to_records(index=False) # convert the resulting dataframe to a numpy recarry\u000a        if trialsArr.shape == ():  # convert 0-D to 1-D with one element:\u000a            trialsArr = trialsArr[numpy.newaxis]\u000a        fieldNames = trialsArr.dtype.names\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        #convert the record array into a list of dicts\u000a        trialList = []\u000a        for trialN, trialType in enumerate(trialsArr):\u000a            thisTrial ={}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                val = trialsArr[trialN][fieldN]\u000a                if type(val)==numpy.string_:\u000a                    val = unicode(val.decode('utf-8'))\u000a                    #if it looks like a list, convert it:\u000a                    if val.startswith('[') and val.endswith(']'):\u000a                        #exec('val=%s' %unicode(val.decode('utf8')))\u000a                        val = eval(val)\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    elif fileName.endswith('.pkl'):\u000a        f = open(fileName, 'rU') # is U needed?\u000a        try:\u000a            trialsArr = cPickle.load(f)\u000a        except:\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        f.close()\u000a        trialList = []\u000a        fieldNames = trialsArr[0] # header line first\u000a        _assertValidVarNames(fieldNames, fileName)\u000a        for row in trialsArr[1:]:\u000a            thisTrial = {}\u000a            for fieldN, fieldName in enumerate(fieldNames):\u000a                thisTrial[fieldName] = row[fieldN] # type is correct, being .pkl\u000a            trialList.append(thisTrial)\u000a    else:\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for loading excel format files, but it was not found.')\u000a        try:\u000a            wb = load_workbook(filename=fileName)\u000a        except: # InvalidFileException(unicode(e)): # this fails\u000a            raise ImportError('Could not open %s as conditions' % fileName)\u000a        ws = wb.worksheets[0]\u000a        nCols = ws.get_highest_column()\u000a        nRows = ws.get_highest_row()\u000a\u000a        #get parameter names from the first row header\u000a        fieldNames = []\u000a        for colN in range(nCols):\u000a            fieldName = ws.cell(_getExcelCellName(col=colN, row=0)).value\u000a            fieldNames.append(fieldName)\u000a        _assertValidVarNames(fieldNames, fileName)\u000a\u000a        #loop trialTypes\u000a        trialList = []\u000a        for rowN in range(1, nRows):#skip header first row\u000a            thisTrial={}\u000a            for colN in range(nCols):\u000a                val = ws.cell(_getExcelCellName(col=colN, row=rowN)).value\u000a                #if it looks like a list, convert it\u000a                if type(val) in [unicode, str] and (\u000a                        val.startswith('[') and val.endswith(']') or\u000a                        val.startswith('(') and val.endswith(')') ):\u000a                    val = eval(val)\u000a                fieldName = fieldNames[colN]\u000a                thisTrial[fieldName] = val\u000a            trialList.append(thisTrial)\u000a    #if we have a selection then try to parse it\u000a    if isinstance(selection, basestring) and len(selection)>0:\u000a        selection = indicesFromString(selection)\u000a        if not isinstance(selection, slice):\u000a            for n in selection:\u000a                try:\u000a                    assert n == int(n)\u000a                except:\u000a                    raise TypeError, "importConditions() was given some `indices` but could not parse them"\u000a    #the selection might now be a slice or a series of indices\u000a    if isinstance(selection,slice):\u000a        trialList = trialList[selection]\u000a    elif len(selection)>0:\u000a        allConds = trialList\u000a        trialList=[]\u000a        for ii in selection:\u000a            trialList.append(allConds[int(round(ii))])\u000a\u000a    logging.exp('Imported %s as conditions, %d conditions, %d params' %\u000a                 (fileName, len(trialList), len(fieldNames)))\u000a    if returnFieldNames:\u000a        return (trialList,fieldNames)\u000a    else:\u000a        return trialList\u000a\u000adef createFactorialTrialList(factors):\u000a    """Create a trialList by entering a list of factors with names (keys) and levels (values)\u000a    it will return a trialList in which all factors have been factorially combined (so for example\u000a    if there are two factors with 3 and 5 levels the trialList will be a list of 3*5 = 15, each specifying\u000a    the values for a given trial\u000a\u000a    Usage::\u000a\u000a        trialList = createFactorialTrialList(factors)\u000a\u000a    :Parameters:\u000a\u000a        factors : a dictionary with names (keys) and levels (values) of the factors\u000a\u000a    Example::\u000a\u000a        mytrials = createFactorialTrialList( factors={"text": ["red", "green", "blue"],\u000a            "letterColor": ["red", "green"], "size": [0,1]})\u000a    """\u000a\u000a    # the first step is to place all the factorial combinations in a list of lists\u000a    tempListOfLists=[[]]\u000a    for key in factors:\u000a        alist = factors[key]   # this takes the levels of each factor as a set of values (a list) at a time\u000a        tempList = []\u000a        for value in alist:     # now we loop over the values in a given list, and add each value of the other lists\u000a            for iterList in tempListOfLists:\u000a                tempList.append(iterList + [key,value])\u000a        tempListOfLists = tempList\u000a\u000a    # this second step is so we can return a list in the format of trialList\u000a    trialList = []\u000a    for atrial in tempListOfLists:\u000a        keys = atrial[0::2]          #the even elements are keys\u000a        values = atrial[1::2]       #the odd elements are values\u000a        atrialDict = {}\u000a        for i in range(len(keys)):\u000a            atrialDict[keys[i]] = values[i]     #this combines the key with the value\u000a        trialList.append(atrialDict)             #append one trial at a time to the final trialList\u000a\u000a    return trialList\u000a\u000aclass StairHandler(_BaseTrialHandler):\u000a    """Class to handle smoothly the selection of the next trial\u000a    and report current values etc.\u000a    Calls to nextTrial() will fetch the next object given to this\u000a    handler, according to the method specified.\u000a\u000a    See ``Demos >> ExperimentalControl >> JND_staircase_exp.py``\u000a\u000a    The staircase will terminate when *nTrials* AND *nReversals* have been exceeded. If *stepSizes* was an array\u000a    and has been exceeded before nTrials is exceeded then the staircase will continue\u000a    to reverse.\u000a\u000a    *nUp* and *nDown* are always considered as 1 until the first reversal is reached. The values entered as arguments\u000a    are then used.\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 nReversals=None,\u000a                 stepSizes=4,  #dB stepsize\u000a                 nTrials=0,\u000a                 nUp=1,\u000a                 nDown=3, #correct responses before stim goes down\u000a                 extraInfo=None,\u000a                 method = '2AFC',\u000a                 stepType='db',\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        :Parameters:\u000a\u000a            startVal:\u000a                The initial value for the staircase.\u000a\u000a            nReversals:\u000a                The minimum number of reversals permitted. If stepSizes is a list then there must\u000a                also be enough reversals to satisfy this list.\u000a\u000a            stepSizes:\u000a                The size of steps as a single value or a list (or array). For a single value the step\u000a                size is fixed. For an array or list the step size will progress to the next entry\u000a                at each reversal.\u000a\u000a            nTrials:\u000a                The minimum number of trials to be conducted. If the staircase has not reached the\u000a                required number of reversals then it will continue.\u000a\u000a            nUp:\u000a                The number of 'incorrect' (or 0) responses before the staircase level increases.\u000a\u000a            nDown:\u000a                The number of 'correct' (or 1) responses before the staircase level decreases.\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            stepType:\u000a                specifies whether each step will be a jump of the given size in\u000a                'db', 'log' or 'lin' units ('lin' means this intensity will be added/subtracted)\u000a\u000a            method:\u000a                Not used and may be deprecated in future releases.\u000a\u000a            stepType: *'db'*, 'lin', 'log'\u000a                The type of steps that should be taken each time. 'lin' will simply add or subtract that\u000a                amount each step, 'db' and 'log' will step by a certain number of decibels or log units\u000a                (note that this will prevent your value ever reaching zero or less)\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a        """\u000a\u000a        """\u000a        trialList: a simple list (or flat array) of trials.\u000a\u000a            """\u000a        self.name=name\u000a        self.startVal=startVal\u000a        self.nReversals=nReversals\u000a        self.nUp=nUp\u000a        self.nDown=nDown\u000a        self.extraInfo=extraInfo\u000a        self.method=method\u000a        self.stepType=stepType\u000a\u000a        self.stepSizes=stepSizes\u000a        if type(stepSizes) in [int, float]:\u000a            self.stepSizeCurrent=stepSizes\u000a            self._variableStep=False\u000a        else:#list, tuple or array\u000a            self.stepSizeCurrent=stepSizes[0]\u000a            self.nReversals= max(len(stepSizes),self.nReversals)\u000a            self._variableStep=True\u000a\u000a        self.nTrials = nTrials#to terminate the nTrials must be exceeded and either\u000a        self.finished=False\u000a        self.thisTrialN = -1\u000a        self.otherData={} #a dict of lists where each should have the same length as the main data\u000a        self.data = []\u000a        self.intensities=[]\u000a        self.reversalPoints = []\u000a        self.reversalIntensities=[]\u000a        self.currentDirection='start' #initially it goes down but on every step\u000a        self.correctCounter=0  #correct since last stim change (minus are incorrect)\u000a        self._nextIntensity=self.startVal\u000a        self._warnUseOfNext=True\u000a        self.minVal = minVal\u000a        self.maxVal = maxVal\u000a        self.autoLog = autoLog\u000a        self.initialRule = 0  #a flag for the 1-up 1-down initial rule\u000a\u000a        #self.originPath and self.origin (the contents of the origin file)\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def __iter__(self):\u000a        return self\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity!=None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a\u000a        #increment the counter of correct scores\u000a        if result==1:\u000a            if len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter+=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = 1\u000a        else:\u000a            if  len(self.data)>1 and self.data[-2]==result:\u000a                #increment if on a run\u000a                self.correctCounter-=1\u000a            else:\u000a                #or reset\u000a                self.correctCounter = -1\u000a\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a\u000a    def addOtherData(self, dataName, value):\u000a        """Add additional data to the handler, to be tracked alongside the result\u000a        data but not affecting the value of the staircase\u000a        """\u000a        if not dataName in self.otherData: #init the list\u000a            if self.thisTrialN>0:\u000a                self.otherData[dataName]=[None]*(self.thisTrialN-1) #might have run trals already\u000a            else:\u000a                self.otherData[dataName]=[]\u000a        #then add current value\u000a        self.otherData[dataName].append(value)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(dataName, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated since 1.79.00: This function name was ambiguous. Please use one of\u000a        these instead:\u000a            .addResponse(result, intensity)\u000a            .addOtherData('dataName', value')\u000a        """\u000a        self.addResponse(result, intensity)\u000a\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity, counter of correct responses and current direction"""\u000a\u000a        if len(self.reversalIntensities)<1:\u000a            #always using a 1-down, 1-up rule initially\u000a            if self.data[-1]==1:    #last answer correct\u000a                #got it right\u000a                if self.currentDirection=='up':\u000a                    reversal=True\u000a                else:#direction is 'down' or 'start'\u000a                    reversal=False\u000a                self.currentDirection='down'\u000a            else:\u000a                #got it wrong\u000a                if self.currentDirection=='down':\u000a                    reversal=True\u000a                else:#direction is 'up' or 'start'\u000a                    reversal=False\u000a                #now:\u000a                self.currentDirection='up'\u000a\u000a        elif self.correctCounter >= self.nDown: #n right, time to go down!\u000a            if self.currentDirection!='down':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='down'\u000a\u000a        elif self.correctCounter <= -self.nUp: #n wrong, time to go up!\u000a            #note current direction\u000a            if self.currentDirection!='up':\u000a                reversal=True\u000a            else:\u000a                reversal=False\u000a            self.currentDirection='up'\u000a\u000a        else:\u000a            #same as previous trial\u000a            reversal=False\u000a\u000a\u000a        #add reversal info\u000a        if reversal:\u000a            self.reversalPoints.append(self.thisTrialN)\u000a            if len(self.reversalIntensities)<1:\u000a                self.initialRule=1\u000a            self.reversalIntensities.append(self.intensities[-1])\u000a        #test if we're done\u000a        if len(self.reversalIntensities)>=self.nReversals and \u005c\u000a            len(self.intensities)>=self.nTrials:\u000a                self.finished=True\u000a        #new step size if necessary\u000a        if reversal and self._variableStep:\u000a            if len(self.reversalIntensities) >= len(self.stepSizes):\u000a                #we've gone beyond the list of step sizes so just use the last one\u000a                self.stepSizeCurrent = self.stepSizes[-1]\u000a            else:\u000a                self.stepSizeCurrent = self.stepSizes[len(self.reversalIntensities)]\u000a\u000a        #apply new step size\u000a        if len(self.reversalIntensities)<1 or self.initialRule==1:\u000a            self.initialRule=0 #reset the flag\u000a            if self.data[-1]==1:\u000a                self._intensityDec()\u000a            else:\u000a                self._intensityInc()\u000a        elif self.correctCounter >= self.nDown: #n right, so going down\u000a            self._intensityDec()\u000a        elif self.correctCounter <= -self.nUp:  #n wrong, so going up\u000a            self._intensityInc()\u000a\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN` and `thisIndex`.\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.StairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        if self.finished==False:\u000a            #check that all 'otherData' is aligned with current trialN\u000a            for key in self.otherData.keys():\u000a                while len(self.otherData[key])<self.thisTrialN:\u000a                    self.otherData[key].append(None)\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a    def _intensityInc(self):\u000a        """increment the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity *= 10.0**(self.stepSizeCurrent/20.0)\u000a        elif self.stepType=='log':\u000a            self._nextIntensity *= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity += self.stepSizeCurrent\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        self.correctCounter =0\u000a\u000a    def _intensityDec(self):\u000a        """decrement the current intensity and reset counter"""\u000a        if self.stepType=='db':\u000a            self._nextIntensity /= 10.0**(self.stepSizeCurrent/20.0)\u000a        if self.stepType=='log':\u000a            self._nextIntensity /= 10.0**self.stepSizeCurrent\u000a        elif self.stepType=='lin':\u000a            self._nextIntensity -= self.stepSizeCurrent\u000a        self.correctCounter =0\u000a        #check we haven't gone out of the legal range\u000a        if (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'\u000a                  ):\u000a        """\u000a        Write a text file with the data\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #set default delimiter if none given\u000a        if delim is None:\u000a            delim = genDelimiter(fileName)\u000a\u000a        #create the file or print to stdout\u000a        f = openOutputFile(\u000a            fileName, append=False, delim=delim,\u000a            fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a        )\u000a\u000a        #write the data\u000a        reversalStr = str(self.reversalIntensities)\u000a        reversalStr = string.replace( reversalStr, ',', delim)\u000a        reversalStr = string.replace( reversalStr, '[', '')\u000a        reversalStr = string.replace( reversalStr, ']', '')\u000a        f.write('\u005cnreversalIntensities=\u005ct%s\u005cn' %reversalStr)\u000a\u000a        reversalPts = str(self.reversalPoints)\u000a        reversalPts = string.replace( reversalPts, ',', delim)\u000a        reversalPts = string.replace( reversalPts, '[', '')\u000a        reversalPts = string.replace( reversalPts, ']', '')\u000a        f.write('reversalIndices=\u005ct%s\u005cn' %reversalPts)\u000a\u000a        rawIntens = str(self.intensities)\u000a        rawIntens = string.replace( rawIntens, ',', delim)\u000a        rawIntens = string.replace( rawIntens, '[', '')\u000a        rawIntens = string.replace( rawIntens, ']', '')\u000a        f.write('\u005cnintensities=\u005ct%s\u005cn' %rawIntens)\u000a\u000a        responses = str(self.data)\u000a        responses = string.replace( responses, ',', delim)\u000a        responses = string.replace( responses, '[', '')\u000a        responses = string.replace( responses, ']', '')\u000a        f.write('responses=\u005ct%s\u005cn' %responses)\u000a\u000a        #add self.extraInfo\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            strInfo = str(self.extraInfo)\u000a            #dict begins and ends with {} - remove\u000a            strInfo = strInfo[1:-1] #string.replace(strInfo, '{','');strInfo = string.replace(strInfo, '}','');\u000a            strInfo = string.replace(strInfo, ': ', ':\u005cn')#separate value from keyname\u000a            strInfo = string.replace(strInfo, ',', '\u005cn')#separate values from each other\u000a            strInfo = string.replace(strInfo, 'array([ ', '')\u000a            strInfo = string.replace(strInfo, '])', '')\u000a\u000a            f.write('\u005cn%s\u005cn' %strInfo)\u000a\u000a        f.write("\u005cn")\u000a        if f != sys.stdout:\u000a            f.close()\u000a            if self.autoLog:\u000a                logging.info('saved data to %s' %f.name)\u000a\u000a    def saveAsExcel(self,fileName, sheetName='data',\u000a                   matrixOnly=False, appendFile=True,\u000a                   fileCollisionMethod='rename'\u000a                  ):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that data can be stored in multiple named sheets within the file. So you could have a single file\u000a        named after your experiment and then have one worksheet for each participant. Or you could have\u000a        one file for each participant and then multiple sheets for repeated sessions etc.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            sheetName: string\u000a                the name of the worksheet within the file\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a        #NB this was based on the limited documentation (1 page wiki) for openpyxl v1.0\u000a        if not haveOpenpyxl:\u000a            raise ImportError('openpyxl is required for saving files in Excel (xlsx) format, but was not found.')\u000a            #return -1\u000a\u000a        #import necessary subpackages - they are small so won't matter to do it here\u000a        from openpyxl.workbook import Workbook\u000a        from openpyxl.writer.excel import ExcelWriter\u000a        from openpyxl.reader.excel import load_workbook\u000a\u000a        if not fileName.endswith('.xlsx'):\u000a            fileName+='.xlsx'\u000a        #create or load the file\u000a        if appendFile and os.path.isfile(fileName):\u000a            wb = load_workbook(fileName)\u000a            newWorkbook=False\u000a        else:\u000a            if not appendFile: #the file exists but we're not appending, so will be overwritten\u000a                fileName = handleFileCollision(fileName,\u000a                                               fileCollisionMethod)\u000a            wb = Workbook()#create new workbook\u000a            wb.properties.creator='PsychoPy'+psychopy.__version__\u000a            newWorkbook=True\u000a\u000a        ew = ExcelWriter(workbook = wb)\u000a\u000a        if newWorkbook:\u000a            ws = wb.worksheets[0]\u000a            ws.title=sheetName\u000a        else:\u000a            ws=wb.create_sheet()\u000a            ws.title=sheetName\u000a\u000a        #write the data\u000a        #reversals data\u000a        ws.cell('A1').value = 'Reversal Intensities'\u000a        ws.cell('B1').value = 'Reversal Indices'\u000a        for revN, revIntens in enumerate(self.reversalIntensities):\u000a            ws.cell(_getExcelCellName(col=0,row=revN+1)).value = unicode(revIntens)\u000a            ws.cell(_getExcelCellName(col=1,row=revN+1)).value = unicode(self.reversalPoints[revN])\u000a\u000a        #trials data\u000a        ws.cell('C1').value = 'All Intensities'\u000a        ws.cell('D1').value = 'All Responses'\u000a        for intenN, intensity in enumerate(self.intensities):\u000a            ws.cell(_getExcelCellName(col=2,row=intenN+1)).value = unicode(intensity)\u000a            ws.cell(_getExcelCellName(col=3,row=intenN+1)).value = unicode(self.data[intenN])\u000a\u000a        #add self.extraInfo\u000a        rowN = 0\u000a        if (self.extraInfo != None) and not matrixOnly:\u000a            ws.cell(_getExcelCellName(col=6,row=rowN)).value = 'extraInfo'\u000a            rowN += 1\u000a            for key,val in self.extraInfo.items():\u000a                ws.cell(_getExcelCellName(col=6,row=rowN)).value = unicode(key)+u':'\u000a                ws.cell(_getExcelCellName(col=7,row=rowN)).value = unicode(val)\u000a                rowN+=1\u000a\u000a        ew.save(filename = fileName)\u000a        if self.autoLog:\u000a            logging.info('saved data to %s' %fileName)\u000a\u000a    def saveAsPickle(self,fileName, fileCollisionMethod='rename'):\u000a        """Basically just saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded if necess and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.thisTrialN<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a\u000aclass QuestHandler(StairHandler):\u000a    """Class that implements the Quest algorithm for quick measurement of\u000a    psychophysical thresholds.\u000a\u000a    Uses Andrew Straw's `QUEST <http://www.visionegg.org/Quest>`_, which is a\u000a    Python port of Denis Pelli's Matlab code.\u000a\u000a    Measures threshold using a Weibull psychometric function. Currently, it is\u000a    not possible to use a different psychometric function.\u000a\u000a    Threshold 't' is measured on an abstract 'intensity' scale, which\u000a    usually corresponds to log10 contrast.\u000a\u000a    The Weibull psychometric function:\u000a\u000a    p2=delta*gamma+(1-delta)*(1-(1-gamma)*exp(-10**(beta*(x2+xThreshold))))\u000a\u000a    **Example**::\u000a\u000a        # setup display/window\u000a        ...\u000a        # create stimulus\u000a        stimulus = visual.RadialStim(win=win, tex='sinXsin', size=1, pos=[0,0], units='deg')\u000a        ...\u000a        # create staircase object\u000a        # trying to find out the point where subject's response is 50/50\u000a        # if wanted to do a 2AFC then the defaults for pThreshold and gamma are good\u000a        staircase = data.QuestHandler(staircase._nextIntensity, 0.2, pThreshold=0.63, gamma=0.01,\u000a                                  nTrials=20, minVal=0, maxVal=1)\u000a        ...\u000a        while thisContrast in staircase:\u000a            # setup stimulus\u000a            stimulus.setContrast(thisContrast)\u000a            stimulus.draw()\u000a            win.flip()\u000a            core.wait(0.5)\u000a            # get response\u000a            ...\u000a            # inform QUEST of the response, needed to calculate next level\u000a            staircase.addResponse(thisResp)\u000a        ...\u000a        # can now access 1 of 3 suggested threshold levels\u000a        staircase.mean()\u000a        staircase.mode()\u000a        staircase.quantile() #gets the median\u000a\u000a    """\u000a    def __init__(self,\u000a                 startVal,\u000a                 startValSd,\u000a                 pThreshold=0.82,\u000a                 nTrials=None,\u000a                 stopInterval=None,\u000a                 method='quantile',\u000a                 stepType='log',\u000a                 beta=3.5,\u000a                 delta=0.01,\u000a                 gamma=0.5,\u000a                 grain=0.01,\u000a                 range=None,\u000a                 extraInfo=None,\u000a                 minVal=None,\u000a                 maxVal=None,\u000a                 staircase=None,\u000a                 originPath=None,\u000a                 name='',\u000a                 autoLog=True):\u000a        """\u000a        Typical values for pThreshold are:\u000a            * 0.82 which is equivalent to a 3 up 1 down standard staircase\u000a            * 0.63 which is equivalent to a 1 up 1 down standard staircase (and might want gamma=0.01)\u000a\u000a        The variable(s) nTrials and/or stopSd must be specified.\u000a\u000a        `beta`, `delta`, and `gamma` are the parameters of the Weibull psychometric function.\u000a\u000a        :Parameters:\u000a\u000a            startVal:\u000a                Prior threshold estimate or your initial guess threshold.\u000a\u000a            startValSd:\u000a                Standard deviation of your starting guess threshold. Be generous with the sd\u000a                as QUEST will have trouble finding the true threshold if it's more than one sd\u000a                from your initial guess.\u000a\u000a            pThreshold\u000a                Your threshold criterion expressed as probability of response==1. An intensity\u000a                offset is introduced into the psychometric function so that the threshold (i.e.,\u000a                the midpoint of the table) yields pThreshold.\u000a\u000a            nTrials: *None* or a number\u000a                The maximum number of trials to be conducted.\u000a\u000a            stopInterval: *None* or a number\u000a                The minimum 5-95% confidence interval required in the threshold estimate before stopping.\u000a                If both this and nTrials is specified, whichever happens first will determine when\u000a                Quest will stop.\u000a\u000a            method: *'quantile'*, 'mean', 'mode'\u000a                The method used to determine the next threshold to test. If you want to get a specific threshold\u000a                level at the end of your staircasing, please use the quantile, mean, and mode methods directly.\u000a\u000a            stepType: *'log'*, 'db', 'lin'\u000a                The type of steps that should be taken each time. 'db' and 'log' will transform your intensity levels\u000a                into decibels or log units and will move along the psychometric function with these values.\u000a\u000a            beta: *3.5* or a number\u000a                Controls the steepness of the psychometric function.\u000a\u000a            delta: *0.01* or a number\u000a                The fraction of trials on which the observer presses blindly.\u000a\u000a            gamma: *0.5* or a number\u000a                The fraction of trials that will generate response 1 when intensity=-Inf.\u000a\u000a            grain: *0.01* or a number\u000a                The quantization of the internal table.\u000a\u000a            range: *None*, or a number\u000a                The intensity difference between the largest and smallest intensity that the\u000a                internal table can store. This interval will be centered on the initial guess\u000a                tGuess. QUEST assumes that intensities outside of this range have zero prior\u000a                probability (i.e., they are impossible).\u000a\u000a            extraInfo:\u000a                A dictionary (typically) that will be stored along with collected data using\u000a                :func:`~psychopy.data.StairHandler.saveAsPickle` or\u000a                :func:`~psychopy.data.StairHandler.saveAsText` methods.\u000a\u000a            minVal: *None*, or a number\u000a                The smallest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            maxVal: *None*, or a number\u000a                The largest legal value for the staircase, which can be used to prevent it\u000a                reaching impossible contrast values, for instance.\u000a\u000a            staircase: *None* or StairHandler\u000a                Can supply a staircase object with intensities and results. Might be useful to\u000a                give the quest algorithm more information if you have it. You can also call the\u000a                importData function directly.\u000a\u000a        """\u000a\u000a        # Initialize using parent class first\u000a        StairHandler.__init__(self, startVal, nTrials=nTrials, extraInfo=extraInfo, method=method,\u000a                                stepType=stepType, minVal=minVal, maxVal=maxVal, name=name, autoLog=autoLog)\u000a\u000a        # Setup additional values\u000a        self.stopInterval = stopInterval\u000a\u000a        # Transform startVal and startValSd based on stepType\u000a        startVal = self._intensity2scale(startVal)\u000a        startValSd = self._intensity2scale(startValSd)\u000a        self._questNextIntensity = startVal\u000a\u000a        # Create Quest object\u000a        self._quest = QuestObject(startVal, startValSd, pThreshold, beta, delta, gamma, grain, range)\u000a\u000a        # Import any old staircase data\u000a        if staircase is not None:\u000a            self.importData(staircase.intensities, staircase.data)\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp=None\u000a        self.autoLog = autoLog\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        # Process user supplied intensity\u000a        if intensity is None:\u000a            intensity = self._questNextIntensity\u000a        else:\u000a            intensity = self._intensity2scale(intensity)\u000a            # Update the intensity.\u000a            #\u000a            # During the first trial, self.intensities will be of length 0,\u000a            # so pop() would not work.\u000a            if len(self.intensities) != 0:\u000a                self.intensities.pop()  #remove the one that had been auto-generated\u000a            self.intensities.append(intensity)\u000a        # Update quest\u000a        self._quest.update(intensity, result)\u000a        # Update other things\u000a        self.data.append(result)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.calculateNextIntensity()\u000a    def importData(self, intensities, results):\u000a        """import some data which wasn't previously given to the quest algorithm"""\u000a        # NOT SURE ABOUT CLASS TO USE FOR RAISING ERROR\u000a        if len(intensities) != len(results):\u000a            raise AttributeError("length of intensities and results input must be the same")\u000a        self.incTrials(len(intensities))\u000a        for intensity, result in zip(intensities,results):\u000a            try:\u000a                self.next()\u000a                self.addResponse(result, intensity)\u000a            except StopIteration:   # would get a stop iteration if stopInterval set\u000a                pass    # TODO: might want to check if nTrials is still good\u000a    def calculateNextIntensity(self):\u000a        """based on current intensity and counter of correct responses"""\u000a        self._intensity()\u000a        # Check we haven't gone out of the legal range\u000a        if (self._nextIntensity > self.maxVal) and self.maxVal is not None:\u000a            self._nextIntensity = self.maxVal\u000a        elif (self._nextIntensity < self.minVal) and self.minVal is not None:\u000a            self._nextIntensity = self.minVal\u000a        self._questNextIntensity = self._intensity2scale(self._nextIntensity)\u000a    def _intensity(self):\u000a        """assigns the next intensity level"""\u000a        if self.method == 'mean':\u000a            self._questNextIntensity = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            self._questNextIntensity = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            self._questNextIntensity = self._quest.quantile()\u000a        # else: maybe raise an error\u000a        self._nextIntensity = self._scale2intensity(self._questNextIntensity)\u000a\u000a    def _intensity2scale(self, intensity):\u000a        """returns the scaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            scaled_intensity = numpy.log10(intensity) * 20.0\u000a        elif self.stepType=='log':\u000a            scaled_intensity = numpy.log10(intensity)\u000a        else:\u000a            scaled_intensity = intensity\u000a        return scaled_intensity\u000a\u000a    def _scale2intensity(self, scaled_intensity):\u000a        """returns the unscaled intensity level based on value of self.stepType"""\u000a        if self.stepType=='db':\u000a            intensity = 10.0**(scaled_intensity/20.0)\u000a        elif self.stepType=='log':\u000a            intensity = 10.0**scaled_intensity\u000a        else:\u000a            intensity = scaled_intensity\u000a        return intensity\u000a\u000a    def mean(self):\u000a        """mean of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mean())\u000a\u000a    def sd(self):\u000a        """standard deviation of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.sd())\u000a\u000a    def mode(self):\u000a        """mode of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.mode()[0])\u000a\u000a    def quantile(self, p=None):\u000a        """quantile of Quest posterior pdf"""\u000a        return self._scale2intensity(self._quest.quantile(p))\u000a\u000a    def confInterval(self, getDifference=False):\u000a        """give the range of the 5-95% confidence interval"""\u000a        interval = [self.quantile(0.05), self.quantile(0.95)]\u000a        if getDifference:\u000a            return abs(interval[0] - interval[1])\u000a        else:\u000a            return interval\u000a\u000a    def incTrials(self, nNewTrials):\u000a        """increase maximum number of trials\u000a        Updates attribute: `nTrials`\u000a        """\u000a        self.nTrials += nNewTrials\u000a\u000a    def simulate(self, tActual):\u000a        """ returns a simulated user response to the next intensity level presented by Quest,\u000a            need to supply the actual threshold level\u000a        """\u000a        # Current estimated intensity level\u000a        if self.method == 'mean':\u000a            tTest = self._quest.mean()\u000a        elif self.method == 'mode':\u000a            tTest = self._quest.mode()\u000a        elif self.method == 'quantile':\u000a            tTest = self._quest.quantile()\u000a        return self._quest.simulate(tTest, tActual)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a        Updates attributes; `thisTrial`, `thisTrialN`, `thisIndex`, `finished`, `intensities`\u000a\u000a        If the trials have ended, calling this method will raise a StopIteration error.\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff\u000a\u000a        or::\u000a\u000a            staircase = data.QuestHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a        """\u000a        self._checkFinished()\u000a\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._nextIntensity)\u000a            return self._nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        elif self.stopInterval is not None and self.confInterval(True) < self.stopInterval:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a\u000aclass PsiHandler(StairHandler):\u000a    """\u000a    Handler to implement the "Psi" adaptive psychophysical method (Kontsevich & Tyler, 1999).\u000a\u000a    This implementation assumes the form of the psychometric function to be a cumulative Gaussian.\u000a    Psi estimates the two free parameters of the psychometric function, the location (alpha) and slope (beta),\u000a    using Bayes' rule and grid approximation of the posterior distribution. It chooses stimuli to present by\u000a    minimizing the entropy of this grid. Because this grid is represented internally as a 4-D array, one\u000a    must choose the intensity, alpha, and beta ranges carefully so as to avoid a Memory Error. Maximum likelihood\u000a    is used to estimate Lambda, the most likely location/slope pair. Because Psi estimates the entire\u000a    psychometric function, any threshold defined on the function may be estimated once Lambda is determined.\u000a\u000a    It is advised that Lambda estimates are examined after completion of the Psi procedure. If the\u000a    estimated alpha or beta values equal your specified search bounds, then the search range most likely did\u000a    not contain the true value. In this situation the procedure should be repeated with appropriately adjusted bounds.\u000a\u000a    Because Psi is a Bayesian method, it can be initialized with a prior from existing research. A function\u000a    to save the posterior over Lambda as a Numpy binary file is included.\u000a    """\u000a\u000a    def __init__(self,\u000a                 nTrials,\u000a                 intensRange, alphaRange, betaRange,\u000a                 intensPrecision, alphaPrecision, betaPrecision,\u000a                 delta,\u000a                 extraInfo=None,\u000a                 stepType='lin',\u000a                 TwoAFC=False,\u000a                 prior=None,\u000a                 fromFile=False,\u000a                 name=''):\u000a\u000a\u000a        """\u000a        Initializes the handler and creates an internal Psi Object for grid approximation.\u000a\u000a        Parameters:\u000a\u000a            nTrials (int)\u000a                The number of trials to run.\u000a\u000a            intensRange (list)\u000a                Two element list containing the (inclusive) endpoints of the stimuli intensity range.\u000a\u000a            alphaRange  (list)\u000a                Two element list containing the (inclusive) endpoints of the alpha (location parameter) range.\u000a\u000a            betaRange   (list)\u000a                Two element list containing the (inclusive) endpoints of the beta (slope parameter) range.\u000a\u000a            intensPrecision (float or int)\u000a                If stepType == 'lin', this specifies the step size of the stimuli intensity range.\u000a                If stepType == 'log', this specifies the number of steps in the stimuli intensity range.\u000a\u000a            alphaPrecision  (float)\u000a                The step size of the alpha (location parameter) range.\u000a\u000a            betaPrecision   (float)\u000a                The step size of the beta (slope parameter) range.\u000a\u000a            delta   (float)\u000a                The guess rate.\u000a\u000a            extraInfo   (dict)\u000a                Optional dictionary object used in PsychoPy's built-in logging system.\u000a\u000a            stepType    (str)\u000a                The type of steps to be used when constructing the stimuli intensity range. If 'lin' then evenly spaced steps are used. If 'log' then logarithmically spaced steps are used.\u000a                Defaults to 'lin'.\u000a\u000a            TwoAFC  (bool)\u000a                If True then the d' based psychometric function from Kontsevich & Tyler (1999) will be used. If False then a Yes/No task is assumed.\u000a\u000a            prior   (numpy.ndarray or str)\u000a                Optional prior distribution with which to initialize the Psi Object. This can either be a numpy.ndarray object or the path to a numpy binary file (.npy) containing the ndarray.\u000a\u000a            fromFile    (str)\u000a                Flag specifying whether prior is a file pathname or not.\u000a\u000a            name    (str)\u000a                Optional name for the PsiHandler used in PsychoPy's built-in logging system.\u000a        """\u000a        # Initialize parent class first\u000a        StairHandler.__init__(self, startVal=None, nTrials=nTrials, extraInfo=extraInfo, method=None, stepType=stepType, minVal=intensRange[0], maxVal=intensRange[1], name=name)\u000a\u000a        # Create Psi object\u000a        if prior is not None and fromFile:\u000a            try:\u000a                prior = numpy.load(prior)\u000a            except IOError:\u000a                logging.warning("The specified pickle file could not be read. Using a uniform prior instead.")\u000a                prior = None\u000a        self._psi = PsiObject(intensRange, alphaRange, betaRange, intensPrecision, alphaPrecision, betaPrecision, delta, stepType, TwoAFC, prior)\u000a        self._psi.update(None)\u000a\u000a\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a        Supplying an `intensity` value here indicates that you did not use the\u000a        recommended intensity in your last trial and the staircase will\u000a        replace its recorded value with the one you supplied here.\u000a        """\u000a        self.data.append(result)\u000a\u000a        #if needed replace the existing intensity with this custom one\u000a        if intensity is not None:\u000a            self.intensities.pop()\u000a            self.intensities.append(intensity)\u000a        #add the current data to experiment if possible\u000a        if self.getExp() is not None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self._psi.update(result)\u000a\u000a    def next(self):\u000a        """Advances to next trial and returns it."""\u000a        self._checkFinished()\u000a        if self.finished==False:\u000a            #update pointer for next trial\u000a            self.thisTrialN+=1\u000a            self.intensities.append(self._psi.nextIntensity)\u000a            return self._psi.nextIntensity\u000a        else:\u000a            self._terminate()\u000a\u000a    def _checkFinished(self):\u000a        """checks if we are finished\u000a        Updates attribute: `finished`\u000a        """\u000a        if self.nTrials is not None and len(self.intensities) >= self.nTrials:\u000a            self.finished = True\u000a        else:\u000a            self.finished = False\u000a\u000a    def estimateLambda(self):\u000a        """Returns a tuple of (location, slope)"""\u000a        return self._psi.estimateLambda()\u000a\u000a    def estimateThreshold(self, thresh, lamb=None):\u000a        """Returns an intensity estimate for the provided probability. The optional argument 'lamb' allows thresholds to be estimated without having to recompute the maximum likelihood lambda."""\u000a        if lamb is not None:\u000a            try:\u000a                if len(lamb) != 2:\u000a                    warnings.warn("Invalid user-specified lambda pair. A new estimate of lambda will be computed.", SyntaxWarning)\u000a                    lamb = None\u000a            except TypeError:\u000a                warnings.warn("Invalid user-specified lambda pair. A new estimate of lambda will be computed.", SyntaxWarning)\u000a                lamb = None\u000a        return self._psi.estimateThreshold(thresh, lamb)\u000a\u000a    def savePosterior(self, fileName, fileCollisionMethod='rename'):\u000a        """\u000a        Saves the posterior array over probLambda as a pickle file with the specified name.\u000a\u000a        :Parameters:\u000a        fileCollisionMethod : string\u000a            Collision method passed to\u000a            :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        try:\u000a            if os.path.exists(fileName):\u000a                fileName = handleFileCollision(\u000a                    fileName,\u000a                    fileCollisionMethod=fileCollisionMethod\u000a                )\u000a            self._psi.savePosterior(fileName)\u000a        except IOError:\u000a            warnings.warn("An error occurred while trying to save the posterior array. Continuing without saving...")\u000a\u000a\u000aclass MultiStairHandler(_BaseTrialHandler):\u000a    def __init__(self, stairType='simple', method='random',\u000a            conditions=None, nTrials=50, originPath=None, name='', autoLog=True):\u000a        """A Handler to allow easy interleaved staircase procedures (simple or\u000a        QUEST).\u000a\u000a        Parameters for the staircases, as used by the relevant :class:`StairHandler` or\u000a        :class:`QuestHandler` (e.g. the `startVal`, `minVal`, `maxVal`...)\u000a        should be specified in the `conditions` list and may vary between\u000a        each staircase. In particular, the conditions /must/ include the\u000a        a `startVal` (because this is a required argument to the above handlers)\u000a        a `label` to tag the staircase and a `startValSd` (only for QUEST\u000a        staircases). Any parameters not specified in the conditions file\u000a        will revert to the default for that individual handler.\u000a\u000a        If you need to custom the behaviour further you may want to look at the\u000a        recipe on :ref:`interleavedStairs`.\u000a\u000a        :params:\u000a\u000a            stairType: 'simple' or 'quest'\u000a                Use a :class:`StairHandler` or :class:`QuestHandler`\u000a\u000a            method: 'random' or 'sequential'\u000a                The stairs are shuffled in each repeat but not randomised more than\u000a                that (so you can't have 3 repeats of the same staircase in a row\u000a                unless it's the only one still running)\u000a\u000a            conditions: a list of dictionaries specifying conditions\u000a                Can be used to control parameters for the different staicases.\u000a                Can be imported from an Excel file using `psychopy.data.importConditions`\u000a                MUST include keys providing, 'startVal', 'label' and 'startValSd' (QUEST only).\u000a                The 'label' will be used in data file saving so should be unique.\u000a                See Example Usage below.\u000a\u000a            nTrials=50\u000a                Minimum trials to run (but may take more if the staircase hasn't\u000a                also met its minimal reversals. See :class:`~psychopy.data.StairHandler`\u000a\u000a        Example usage::\u000a\u000a            conditions=[\u000a                {'label':'low', 'startVal': 0.1, 'ori':45},\u000a                {'label':'high','startVal': 0.8, 'ori':45},\u000a                {'label':'low', 'startVal': 0.1, 'ori':90},\u000a                {'label':'high','startVal': 0.8, 'ori':90},\u000a                ]\u000a            stairs = data.MultiStairHandler(conditions=conditions, nTrials=50)\u000a\u000a            for thisIntensity, thisCondition in stairs:\u000a                thisOri = thisCondition['ori']\u000a\u000a                #do something with thisIntensity and thisOri\u000a\u000a                stairs.addResponse(correctIncorrect)#this is ESSENTIAL\u000a\u000a            #save data as multiple formats\u000a            stairs.saveDataAsExcel(fileName)#easy to browse\u000a            stairs.saveAsPickle(fileName)#contains more info\u000a\u000a        """\u000a        self.name=name\u000a        self.autoLog = autoLog\u000a        self.type=stairType\u000a        self.method=method #'random' or 'sequential'\u000a        self.conditions=conditions\u000a        self.nTrials=nTrials\u000a        self.finished=False\u000a        self.totalTrials=0\u000a        self._checkArguments()\u000a        #create staircases\u000a        self.staircases=[]#all staircases\u000a        self.runningStaircases=[]#staircases that haven't finished yet\u000a        self.thisPassRemaining=[]#staircases to run this pass\u000a        self._createStairs()\u000a\u000a        #fetch first staircase/value (without altering/advancing it)\u000a        self._startNewPass()\u000a        self.currentStaircase = self.thisPassRemaining[0]#take the first and remove it\u000a        self._nextIntensity = self.currentStaircase._nextIntensity#gets updated by self.addData()\u000a        #store the origin file and its path\u000a        self.originPath, self.origin = self.getOriginPathAndFile(originPath)\u000a        self._exp = None#the experiment handler that owns me!\u000a    def _checkArguments(self):\u000a        #did we get a conditions parameter, correctly formatted\u000a        if type(self.conditions) not in [list]:\u000a            logging.error('conditions parameter to MultiStairHandler should be a list, not a %s' %type(self.conditions))\u000a            return\u000a        c0=self.conditions[0]\u000a        if type(c0)!=dict:\u000a            logging.error('conditions to MultiStairHandler should be a list of python dictionaries' + \u005c\u000a                ', not a list of %ss' %type(c0))\u000a        #did conditions contain the things we need?\u000a        params = c0.keys()\u000a        if self.type in ['simple','quest','QUEST']:\u000a            if 'startVal' not in params:\u000a                logging.error('MultiStairHandler needs a param called `startVal` in conditions')\u000a            if 'label' not in params:\u000a                logging.error('MultiStairHandler needs a param called `label` in conditions')\u000a            if 'startValSd' not in params and self.type in ['QUEST','quest']:\u000a                logging.error("MultiStairHandler('quest') needs a param called `startValSd` in conditions")\u000a        else:\u000a            logging.error("MultiStairHandler `stairType` should be 'simple', 'QUEST' or 'quest', not '%s'" %self.type)\u000a    def _createStairs(self):\u000a        if self.type=='simple':\u000a            defaults = {'nReversals':None, 'stepSizes':4, 'nTrials':self.nTrials,\u000a                'nUp':1, 'nDown':3, 'extraInfo':None,\u000a                'stepType':'db', 'minVal':None, 'maxVal':None}\u000a        elif self.type in ['QUEST','quest']:\u000a            # fp added alternatives since the builder creates 'QUEST' but\u000a            # the API spec wants 'quest'?\u000a            defaults = {'pThreshold':0.82, 'nTrials':self.nTrials, 'stopInterval':None,\u000a                'method':'quantile', 'stepType':'log', 'beta':3.5, 'delta':0.01,\u000a                'gamma':0.5, 'grain':0.01, 'range':None, 'extraInfo':None,\u000a                'minVal':None, 'maxVal':None, 'staircase':None}\u000a\u000a        for condition in self.conditions:\u000a            startVal=condition['startVal']\u000a            #fetch each params from conditions if possible\u000a            for paramName in defaults:\u000a                #get value for the parameter\u000a                if paramName in condition.keys():\u000a                    val=condition[paramName]\u000a                else:\u000a                    val = defaults[paramName]\u000a                #assign value to variable name\u000a                exec('%s=%s' %(paramName, repr(val)))\u000a            #then create actual staircase\u000a            if self.type=='simple':\u000a                thisStair = StairHandler(startVal, nReversals=nReversals,\u000a                    stepSizes=stepSizes, nTrials=nTrials, nUp=nUp, nDown=nDown,\u000a                    extraInfo=extraInfo,\u000a                    stepType=stepType, minVal=minVal, maxVal=maxVal)\u000a            elif self.type in ['QUEST','quest']:\u000a                # see above\u000a                thisStair = QuestHandler(startVal, startValSd=condition['startValSd'],\u000a                    pThreshold=pThreshold, nTrials=nTrials, stopInterval=stopInterval,\u000a                    method=method, stepType=stepType, beta=beta, delta=delta,\u000a                    gamma=gamma, grain=grain, range=range, extraInfo=extraInfo,\u000a                    minVal=minVal, maxVal=maxVal, staircase=staircase)\u000a            thisStair.condition = condition#this isn't normally part of handler\u000a            #and finally, add it to the list\u000a            self.staircases.append(thisStair)\u000a            self.runningStaircases.append(thisStair)\u000a    def __iter__(self):\u000a        return self\u000a    def next(self):\u000a        """Advances to next trial and returns it.\u000a\u000a        This can be handled with code such as::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            for eachTrial in staircase:#automatically stops when done\u000a                #do stuff here for the trial\u000a\u000a        or::\u000a\u000a            staircase = data.MultiStairHandler(.......)\u000a            while True: #ie forever\u000a                try:\u000a                    thisTrial = staircase.next()\u000a                except StopIteration:#we got a StopIteration error\u000a                    break #break out of the forever loop\u000a                #do stuff here for the trial\u000a\u000a        """\u000a        #create a new set for this pass if needed\u000a        if not hasattr(self, 'thisPassRemaining') or self.thisPassRemaining==[]:\u000a            if len(self.runningStaircases)>0:\u000a                self._startNewPass()\u000a            else:\u000a                self.finished=True\u000a                raise StopIteration\u000a        #fetch next staircase/value\u000a        self.currentStaircase = self.thisPassRemaining.pop(0)#take the first and remove it\u000a        #if staircase.next() not called, staircaseHandler would not save the first intensity,\u000a        #Error: miss align intensities and responses\u000a        self._nextIntensity =self.currentStaircase.next()#gets updated by self.addData()\u000a        #return value\u000a        if not self.finished:\u000a            #inform experiment of the condition (but not intensity, that might be overridden by user)\u000a            if self.getExp() != None:\u000a                exp = self.getExp()\u000a                stair = self.currentStaircase\u000a                for key, value in stair.condition.items():\u000a                    exp.addData("%s.%s" %(self.name, key), value)\u000a                exp.addData(self.name+'.thisIndex', self.conditions.index(stair.condition))\u000a                exp.addData(self.name+'.thisRepN', stair.thisTrialN+1)\u000a                exp.addData(self.name+'.thisN', self.totalTrials)\u000a                exp.addData(self.name+'.direction', stair.currentDirection)\u000a                exp.addData(self.name+'.stepSize', stair.stepSizeCurrent)\u000a                exp.addData(self.name+'.stepType', stair.stepType)\u000a                exp.addData(self.name+'.intensity', self._nextIntensity)\u000a            return self._nextIntensity, self.currentStaircase.condition\u000a        else:\u000a            raise StopIteration\u000a\u000a    def _startNewPass(self):\u000a        """Create a new iteration of the running staircases for this pass.\u000a\u000a        This is not normally needed by the user - it gets called at __init__\u000a        and every time that next() runs out of trials for this pass.\u000a        """\u000a        self.thisPassRemaining = copy.copy(self.runningStaircases)\u000a        if self.method=='random':\u000a            numpy.random.shuffle(self.thisPassRemaining)\u000a    def addResponse(self, result, intensity=None):\u000a        """Add a 1 or 0 to signify a correct/detected or incorrect/missed trial\u000a\u000a        This is essential to advance the staircase to a new intensity level!\u000a        """\u000a        self.currentStaircase.addResponse(result, intensity)\u000a        if self.currentStaircase.finished:\u000a            self.runningStaircases.remove(self.currentStaircase)\u000a        #add the current data to experiment if poss\u000a        if self.getExp() != None:#update the experiment handler too\u000a            self.getExp().addData(self.name+".response", result)\u000a        self.totalTrials+=1\u000a    def addOtherData(self, name, value):\u000a        """Add some data about the current trial that will not be used to control the\u000a        staircase(s) such as reaction time data\u000a        """\u000a        self.currentStaircase.addOtherData(name, value)\u000a    def addData(self, result, intensity=None):\u000a        """Deprecated 1.79.00: It was ambiguous whether you were adding the response\u000a        (0 or 1) or some other data concerning the trial so there is now a pair\u000a        of explicit methods:\u000a            addResponse(corr,intensity) #some data that alters the next trial value\u000a            addOtherData('RT', reactionTime) #some other data that won't control staircase\u000a        """\u000a        self.addResponse(result, intensity)\u000a        if type(result) in [str, unicode]:\u000a            raise TypeError("MultiStairHandler.addData should only receive corr/incorr. Use .addOtherData('datName',val)")\u000a\u000a    def saveAsPickle(self, fileName, fileCollisionMethod='rename'):\u000a        """Saves a copy of self (with data) to a pickle file.\u000a\u000a        This can be reloaded later and further analyses carried out.\u000a\u000a        :Parameters:\u000a\u000a            fileCollisionMethod: Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsPickle called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        #otherwise use default location\u000a        if not fileName.endswith('.psydat'):\u000a            fileName+='.psydat'\u000a\u000a        f = openOutputFile(fileName, append=False,\u000a                           fileCollisionMethod=fileCollisionMethod)\u000a        cPickle.dump(self, f)\u000a        f.close()\u000a        logging.info('saved data to %s' % f.name)\u000a\u000a    def saveAsExcel(self, fileName, matrixOnly=False, appendFile=False,\u000a                    fileCollisionMethod='rename'):\u000a        """\u000a        Save a summary data file in Excel OpenXML format workbook (:term:`xlsx`) for processing\u000a        in most spreadsheet packages. This format is compatible with\u000a        versions of Excel (2007 or greater) and and with OpenOffice (>=3.0).\u000a\u000a        It has the advantage over the simpler text files (see :func:`TrialHandler.saveAsText()` )\u000a        that the data from each staircase will be save in the same file, with\u000a        the sheet name coming from the 'label' given in the dictionary of\u000a        conditions during initialisation of the Handler.\u000a\u000a        The file extension `.xlsx` will be added if not given already.\u000a\u000a        The file will contain a set of values specifying the staircase level ('intensity') at each\u000a        reversal, a list of reversal indices (trial numbers), the raw staircase/intensity\u000a        level on *every* trial and the corresponding responses of the participant on every trial.\u000a\u000a        :Parameters:\u000a\u000a            fileName: string\u000a                the name of the file to create or append. Can include relative or absolute path\u000a\u000a            matrixOnly: True or False\u000a                If set to True then only the data itself will be output (no additional info)\u000a\u000a            appendFile: True or False\u000a                If False any existing file with this name will be overwritten. If True then a new worksheet will be appended.\u000a                If a worksheet already exists with that name a number will be added to make it unique.\u000a\u000a            fileCollisionMethod: string\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a                This is ignored if ``append`` is ``True``.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsExcel called but no trials completed. Nothing saved')\u000a            return -1\u000a\u000a        append=appendFile\u000a        for thisStair in self.staircases:\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisStair.saveAsExcel(\u000a                fileName, sheetName=label, matrixOnly=matrixOnly,\u000a                appendFile=append, fileCollisionMethod='rename'\u000a            )\u000a            append = True\u000a\u000a    def saveAsText(self,fileName,\u000a                   delim=None,\u000a                   matrixOnly=False,\u000a                   fileCollisionMethod='rename',\u000a                   encoding='utf-8'):\u000a        """\u000a        Write out text files with the data.\u000a\u000a        For MultiStairHandler this will output one file for each staircase\u000a        that was run, with _label added to the fileName that you specify above\u000a        (label comes from the condition dictionary you specified when you\u000a        created the Handler).\u000a\u000a        :Parameters:\u000a\u000a            fileName: a string\u000a                The name of the file, including path if needed. The extension\u000a                `.tsv` will be added if not included.\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a\u000a            fileCollisionMethod:\u000a                Collision method passed to :func:`~psychopy.tools.fileerrortools.handleFileCollision`\u000a\u000a            encoding:\u000a                The encoding to use when saving a the file. Defaults to `utf-8`.\u000a\u000a        """\u000a        if self.totalTrials<1:\u000a            if self.autoLog:\u000a                logging.debug('StairHandler.saveAsText called but no trials completed. Nothing saved')\u000a            return -1\u000a        for thisStair in self.staircases:\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            thisFileName = fileName+"_"+label\u000a            thisStair.saveAsText(\u000a                fileName=thisFileName, delim=delim, matrixOnly=matrixOnly,\u000a                fileCollisionMethod=fileCollisionMethod, encoding=encoding\u000a            )\u000a\u000a    def printAsText(self,\u000a                   delim='\u005ct',\u000a                   matrixOnly=False):\u000a        """\u000a        Write the data to the standard output stream\u000a\u000a        :Parameters:\u000a\u000a            delim: a string\u000a                the delimitter to be used (e.g. '\u005ct' for tab-delimitted, ',' for csv files)\u000a\u000a            matrixOnly: True/False\u000a                If True, prevents the output of the `extraInfo` provided at initialisation.\u000a        """\u000a        nStairs = len(self.staircases)\u000a        for stairN, thisStair in enumerate(self.staircases):\u000a            if stairN < nStairs - 1:\u000a                thisMatrixOnly = True #never print info for first files\u000a            else:\u000a                thisMatrixOnly = matrixOnly\u000a            #make a filename\u000a            label = thisStair.condition['label']\u000a            print "\u005cn%s:" % label\u000a            thisStair.saveAsText(fileName='stdout', delim=delim,\u000a                matrixOnly=thisMatrixOnly)\u000a\u000aclass DataHandler(dict):\u000a    """For handling data (used by TrialHandler, principally, rather than\u000a    by users directly)\u000a\u000a    Numeric data are stored as numpy masked arrays where the mask is set True for missing entries.\u000a    When any non-numeric data (string, list or array) get inserted using DataHandler.add(val) the array\u000a    is converted to a standard (not masked) numpy array with dtype='O' and where missing entries have\u000a    value="--"\u000a\u000a    Attributes:\u000a        - ['key']=data arrays containing values for that key\u000a            (e.g. data['accuracy']=...)\u000a        - dataShape=shape of data (x,y,...z,nReps)\u000a        - dataTypes=list of keys as strings\u000a\u000a    """\u000a    def __init__(self, dataTypes=None, trials=None, dataShape=None):\u000a        self.trials=trials\u000a        self.dataTypes=[]#names will be added during addDataType\u000a        self.isNumeric={}\u000a        #if given dataShape use it - otherwise guess!\u000a        if dataShape:\u000a            self.dataShape=dataShape\u000a        elif self.trials:\u000a            self.dataShape=list(numpy.asarray(trials.trialList,'O').shape)\u000a            self.dataShape.append(trials.nReps)\u000a\u000a        #initialise arrays now if poss\u000a        if dataTypes and self.dataShape:\u000a            for thisType in dataTypes:\u000a                self.addDataType(thisType)\u000a\u000a    def addDataType(self, names, shape=None):\u000a        """Add a new key to the data dictionary of\u000a        particular shape if specified (otherwise the\u000a        shape of the trial matrix in the trial handler.\u000a        Data are initialised to be zero everywhere.\u000a        Not needed by user: appropriate types will be added\u000a        during initialisation and as each xtra type is needed.\u000a        """\u000a        if not shape:\u000a            shape = self.dataShape\u000a        if not isinstance(names,basestring):\u000a            #recursively call this function until we have a string\u000a            for thisName in names:\u000a                self.addDataType(thisName)\u000a        else:\u000a            #create the appropriate array in the dict\u000a            #initially use numpy masked array of floats with mask=True for missing vals\u000a            #convert to a numpy array with dtype='O' if non-numeric data given\u000a            #NB don't use masked array with dytpe='O' together -they don't unpickle\u000a            self[names]=numpy.ma.zeros(shape,'f')#masked array of floats\u000a            self[names].mask=True\u000a            #add the name to the list\u000a            self.dataTypes.append(names)\u000a            self.isNumeric[names]=True#until we need otherwise\u000a    def add(self, thisType, value, position=None):\u000a        """Add data to an existing data type\u000a        (and add a new one if necess)\u000a        """\u000a        if not thisType in self:\u000a            self.addDataType(thisType)\u000a        if position is None:\u000a            #'ran' is always the first thing to update\u000a            if thisType=='ran':\u000a                repN = sum(self['ran'][self.trials.thisIndex])\u000a            else:\u000a                repN = sum(self['ran'][self.trials.thisIndex])-1#because it has already been updated\u000a            #make a list where 1st digit is trial number\u000a            position= [self.trials.thisIndex]\u000a            position.append(repN)\u000a\u000a        #check whether data falls within bounds\u000a        posArr = numpy.asarray(position)\u000a        shapeArr = numpy.asarray(self.dataShape)\u000a        if not numpy.alltrue(posArr<shapeArr):\u000a            #array isn't big enough\u000a            logging.warning('need a bigger array for:'+thisType)\u000a            self[thisType]=extendArr(self[thisType],posArr)#not implemented yet!\u000a        #check for ndarrays with more than one value and for non-numeric data\u000a        if self.isNumeric[thisType] and \u005c\u000a            ((type(value)==numpy.ndarray and len(value)>1) or (type(value) not in [float, int])):\u000a                self._convertToObjectArray(thisType)\u000a        #insert the value\u000a        self[thisType][position[0],position[1]]=value\u000a    def _convertToObjectArray(self, thisType):\u000a        """Convert this datatype from masked numeric array to unmasked object array\u000a        """\u000a        dat = self[thisType]\u000a        self[thisType] = numpy.array(dat.data, dtype='O')#create an array of Object type\u000a        #masked vals should be "--", others keep data\u000a        self[thisType] = numpy.where(dat.mask, '--',dat).astype('O')#we have to repeat forcing to 'O' or text gets truncated to 4chars\u000a        self.isNumeric[thisType]=False\u000a\u000aclass FitFunction:\u000a    """Deprecated: - use the specific functions; FitWeibull, FitLogistic...\u000a    """\u000a    def __init__(self, *args, **kwargs):\u000a        raise DeprecationWarning("FitFunction is now fully DEPRECATED: use FitLogistic, FitWeibull etc instead")\u000a\u000aclass _baseFunctionFit:\u000a    """Not needed by most users except as a superclass for developping your own functions\u000a\u000a    Derived classes must have _eval and _inverse methods with @staticmethods\u000a    """\u000a\u000a    def __init__(self, xx, yy, sems=1.0, guess=None, display=1,\u000a                 expectedMin=0.5):\u000a        self.xx = numpy.asarray(xx)\u000a        self.yy = numpy.asarray(yy)\u000a        self.sems = numpy.asarray(sems)\u000a        self.expectedMin = expectedMin\u000a        self.guess = guess\u000a        # for holding error calculations:\u000a        self.ssq=0\u000a        self.rms=0\u000a        self.chi=0\u000a        #do the calculations:\u000a        self._doFit()\u000a\u000a    def _doFit(self):\u000a        """The Fit class that derives this needs to specify its _evalFunction\u000a        """\u000a        #get some useful variables to help choose starting fit vals\u000a        #self.params = optimize.fmin_powell(self._getErr, self.params, (self.xx,self.yy,self.sems),disp=self.display)\u000a        #self.params = optimize.fmin_bfgs(self._getErr, self.params, None, (self.xx,self.yy,self.sems),disp=self.display)\u000a        global _chance\u000a        _chance = self.expectedMin\u000a        self.params, self.covar = optimize.curve_fit(self._eval, self.xx, self.yy, p0=self.guess, sigma=self.sems)\u000a        self.ssq = self._getErr(self.params, self.xx, self.yy, 1.0)\u000a        self.chi = self._getErr(self.params, self.xx, self.yy, self.sems)\u000a        self.rms = self.ssq/len(self.xx)\u000a    def _getErr(self, params, xx,yy,sems):\u000a        mod = self.eval(xx, params)\u000a        err = sum((yy-mod)**2/sems)\u000a        return err\u000a    def eval(self, xx, params=None):\u000a        """Evaluate xx for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params is None:\u000a            params = self.params\u000a        global _chance\u000a        _chance=self.expectedMin\u000a        #_eval is a static method - must be done this way because the curve_fit\u000a        #function doesn't want to have any `self` object as first arg\u000a        yy = self._eval(xx, *params)\u000a        return yy\u000a    def inverse(self, yy, params=None):\u000a        """Evaluate yy for the current parameters of the model, or for arbitrary params\u000a        if these are given.\u000a        """\u000a        if params is None:\u000a            params=self.params #so the user can set params for this particular inv\u000a        xx = self._inverse(yy, *params)\u000a        return xx\u000a\u000aclass FitWeibull(_baseFunctionFit):\u000a    """Fit a Weibull function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1.0-chance)*(1-exp( -(xx/alpha)**(beta) ))\u000a\u000a    and with inverse::\u000a\u000a        x = alpha * (-log((1.0-y)/(1-chance)))**(1.0/beta)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[alpha, beta]``)"""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, alpha, beta):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy =  _chance + (1.0-_chance)*(1-numpy.exp( -(xx/alpha)**(beta) ))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, alpha, beta):\u000a        global _chance\u000a        xx = alpha * (-numpy.log((1.0-yy)/(1-_chance))) **(1.0/beta)\u000a        return xx\u000a\u000aclass FitNakaRushton(_baseFunctionFit):\u000a    """Fit a Naka-Rushton function\u000a    of the form::\u000a\u000a        yy = rMin + (rMax-rMin) * xx**n/(xx**n+c50**n)\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[rMin, rMax, c50, n]``)\u000a\u000a    Note that this differs from most of the other functions in\u000a    not using a value for the expected minimum. Rather, it fits this\u000a    as one of the parameters of the model."""\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, c50, n, rMin, rMax):\u000a        xx = numpy.asarray(xx)\u000a        if c50 <= 0:\u000a            c50 = 0.001\u000a        if n <= 0:\u000a            n = 0.001\u000a        if rMax <= 0:\u000a            n = 0.001\u000a        if rMin <= 0:\u000a            n = 0.001\u000a        yy = rMin + (rMax-rMin) * (xx**n / (xx**n + c50**n))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, c50, n, rMin, rMax):\u000a        yScaled = (yy-rMin) / (rMax-rMin) #remove baseline and scale\u000a        #do we need to shift while fitting?\u000a        yScaled[yScaled < 0] = 0\u000a        xx = (yScaled * c50**n / (1-yScaled))**(1/n)\u000a        return xx\u000a\u000aclass FitLogistic(_baseFunctionFit):\u000a    """Fit a Logistic function (either 2AFC or YN)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)/(1+exp((PSE-xx)*JND))\u000a\u000a    and with inverse::\u000a\u000a        x = PSE - log((1-chance)/(yy-chance) - 1)/JND\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with ``fit.eval(x)``, retrieve the inverse of the function with\u000a    ``fit.inverse(y)`` or retrieve the parameters from ``fit.params``\u000a    (a list with ``[PSE, JND]``)\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, PSE, JND):\u000a        global _chance\u000a        chance = _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = chance + (1-chance)/(1+numpy.exp((PSE-xx)*JND))\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, PSE, JND):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        xx = PSE - numpy.log((1-_chance)/(yy-_chance) - 1)/JND\u000a        return xx\u000a\u000aclass FitCumNormal(_baseFunctionFit):\u000a    """Fit a Cumulative Normal function (aka error function or erf)\u000a    of the form::\u000a\u000a        y = chance + (1-chance)*((special.erf((xx-xShift)/(sqrt(2)*sd))+1)*0.5)\u000a\u000a    and with inverse::\u000a\u000a        x = xShift+sqrt(2)*sd*(erfinv(((yy-chance)/(1-chance)-.5)*2))\u000a\u000a    After fitting the function you can evaluate an array of x-values\u000a    with fit.eval(x), retrieve the inverse of the function with\u000a    fit.inverse(y) or retrieve the parameters from fit.params\u000a    (a list with [centre, sd] for the Gaussian distribution forming the cumulative)\u000a\u000a    NB: Prior to version 1.74 the parameters had different meaning, relating\u000a    to xShift and slope of the function (similar to 1/sd). Although that is more in\u000a    with the parameters for the Weibull fit, for instance, it is less in keeping\u000a    with standard expectations of normal (Gaussian distributions) so in version\u000a    1.74.00 the parameters became the [centre,sd] of the normal distribution.\u000a\u000a    """\u000a    #static methods have no `self` and this is important for optimise.curve_fit\u000a    @staticmethod\u000a    def _eval(xx, xShift, sd):\u000a        global _chance\u000a        xx = numpy.asarray(xx)\u000a        yy = _chance + (1-_chance)*((special.erf((xx-xShift)/(numpy.sqrt(2)*sd))+1)*0.5)#NB numpy.special.erf() goes from -1:1\u000a        return yy\u000a    @staticmethod\u000a    def _inverse(yy, xShift, sd):\u000a        global _chance\u000a        yy = numpy.asarray(yy)\u000a        #xx = (special.erfinv((yy-chance)/(1-chance)*2.0-1)+xShift)/xScale#NB numpy.special.erfinv() goes from -1:1\u000a        xx = xShift+numpy.sqrt(2)*sd*special.erfinv(( (yy-_chance)/(1-_chance) - 0.5 )*2)\u000a        return xx\u000a\u000a########################## End psychopy.data classes ##########################\u000a\u000adef bootStraps(dat, n=1):\u000a    """Create a list of n bootstrapped resamples of the data\u000a\u000a    SLOW IMPLEMENTATION (Python for-loop)\u000a\u000a    Usage:\u000a        ``out = bootStraps(dat, n=1)``\u000a\u000a    Where:\u000a        dat\u000a            an NxM or 1xN array (each row is a different condition, each column is a different trial)\u000a        n\u000a            number of bootstrapped resamples to create\u000a\u000a        out\u000a            - dim[0]=conditions\u000a            - dim[1]=trials\u000a            - dim[2]=resamples\u000a    """\u000a    dat = numpy.asarray(dat)\u000a    if len(dat.shape)==1: #have presumably been given a series of data for one stimulus\u000a        dat=numpy.array([dat])#adds a dimension (arraynow has shape (1,Ntrials))\u000a\u000a    nTrials = dat.shape[1]\u000a    #initialise a matrix to store output\u000a    resamples = numpy.zeros(dat.shape+(n,), dat.dtype)\u000a    for stimulusN in range(dat.shape[0]):\u000a        thisStim = dat[stimulusN,:]#fetch data for this stimulus\u000a        for sampleN in range(n):\u000a            indices = numpy.floor(nTrials*numpy.random.rand(nTrials)).astype('i')\u000a            resamples[stimulusN,:,sampleN] = numpy.take(thisStim, indices)\u000a    return resamples\u000a\u000adef functionFromStaircase(intensities, responses, bins = 10):\u000a    """Create a psychometric function by binning data from a staircase procedure.\u000a    Although the default is 10 bins Jon now always uses 'unique' bins\u000a    (fewer bins looks pretty but leads to errors in slope estimation)\u000a\u000a    usage::\u000a\u000a        intensity, meanCorrect, n = functionFromStaircase(intensities, responses, bins)\u000a\u000a    where:\u000a            intensities\u000a                are a list (or array) of intensities to be binned\u000a\u000a            responses\u000a                are a list of 0,1 each corresponding to the equivalent intensity value\u000a\u000a            bins\u000a                can be an integer (giving that number of bins) or 'unique' (each bin is made from aa data for exactly one intensity value)\u000a\u000a            intensity\u000a                a numpy array of intensity values (where each is the center of an intensity bin)\u000a\u000a            meanCorrect\u000a                a numpy array of mean % correct in each bin\u000a\u000a            n\u000a                a numpy array of number of responses contributing to each mean\u000a    """\u000a    #convert to arrays\u000a    try:#concatenate if multidimensional\u000a        intensities = numpy.concatenate(intensities)\u000a        responses = numpy.concatenate(responses)\u000a    except:\u000a        intensities = numpy.array(intensities)\u000a        responses = numpy.array(responses)\u000a\u000a    #sort the responses\u000a    sort_ii = numpy.argsort(intensities)\u000a    sortedInten = numpy.take(intensities, sort_ii)\u000a    sortedResp = numpy.take(responses, sort_ii)\u000a\u000a    binnedResp = []\u000a    binnedInten = []\u000a    nPoints = []\u000a    if bins == 'unique':\u000a        intensities = numpy.round(intensities, decimals=8)\u000a        uniqueIntens=numpy.unique(intensities)\u000a        for thisInten in uniqueIntens:\u000a            theseResps = responses[intensities==thisInten]\u000a            binnedInten.append(thisInten)\u000a            binnedResp.append(numpy.mean(theseResps))\u000a            nPoints.append(len(theseResps))\u000a    else:\u000a        pointsPerBin = len(intensities)/float(bins)\u000a        for binN in range(bins):\u000a            thisResp = sortedResp[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            thisInten = sortedInten[int(round(binN*pointsPerBin)) : int(round((binN+1)*pointsPerBin))]\u000a            binnedResp.append( numpy.mean(thisResp))\u000a            binnedInten.append( numpy.mean(thisInten))\u000a            nPoints.append( len(thisInten) )\u000a\u000a    return binnedInten, binnedResp, nPoints\u000a\u000adef getDateStr(format="%Y_%b_%d_%H%M"):\u000a    """Uses ``time.strftime()``_ to generate a string of the form\u000a    2012_Apr_19_1531 for 19th April 3.31pm, 2012.\u000a    This is often useful appended to data filenames to provide unique names.\u000a    To include the year: getDateStr(format="%Y_%b_%d_%H%M") returns '2011_Mar_16_1307'\u000a    depending on locale, can have unicode chars in month names, so utf_8_decode them\u000a    For date in the format of the current localization, do:\u000a        data.getDateStr(format=locale.nl_langinfo(locale.D_T_FMT))\u000a    """\u000a    now = time.strftime(format, time.localtime())\u000a    try:\u000a        now_dec = codecs.utf_8_decode(now)[0]\u000a    except UnicodeDecodeError:\u000a        now_dec = time.strftime("%Y_%m_%d_%H%M", time.localtime())  # '2011_03_16_1307'\u000a\u000a    return now_dec\u000a\u000adef checkValidFilePath(filepath, makeValid=True):\u000a    """Checks whether file path location (e.g. is a valid folder)\u000a\u000a    This should also check whether we have write-permissions to the folder\u000a    but doesn't currently do that!\u000a\u000a    added in: 1.90.00\u000a    """\u000a    folder = os.path.split(os.path.abspath(filepath))[0]\u000a    if not os.path.isdir(folder):\u000a        os.makedirs(folder) #spit an error if we fail\u000a    return True\u000a\u000adef isValidVariableName(name):\u000a    """Checks whether a certain string could be used as a valid variable.\u000a\u000a    Usage::\u000a\u000a        OK, msg = isValidVariableName(name)\u000a\u000a    >>> isValidVariableName('name')\u000a    (True, '')\u000a    >>> isValidVariableName('0name')\u000a    (False, 'Variables cannot begin with numeric character')\u000a    >>> isValidVariableName('first second')\u000a    (False, 'Variables cannot contain punctuation or spaces')\u000a    >>> isValidVariableName('')\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(None)\u000a    (False, "Variables cannot be missing, None, or ''")\u000a    >>> isValidVariableName(23)\u000a    (False, "Variables must be string-like")\u000a    >>> isValidVariableName('a_b_c')\u000a    (True, '')\u000a    """\u000a    if not name:\u000a        return False, "Variables cannot be missing, None, or ''"\u000a    if not type(name) in [str, unicode, numpy.string_, numpy.unicode_]:\u000a        return False, "Variables must be string-like"\u000a    try:\u000a        name=str(name)#convert from unicode if possible\u000a    except:\u000a        if type(name) in [unicode, numpy.unicode_]:\u000a            raise AttributeError("name %s (type %s) contains non-ASCII characters (e.g. accents)" % (name, type(name)))\u000a        else:\u000a            raise AttributeError("name %s (type %s) could not be converted to a string" % (name, type(name)))\u000a\u000a    if name[0].isdigit():\u000a        return False, "Variables cannot begin with numeric character"\u000a    if _nonalphanumeric_re.search(name):\u000a        return False, "Variables cannot contain punctuation or spaces"\u000a    return True, ""\u000a\u000adef _getExcelCellName(col, row):\u000a    """Returns the excel cell name for a row and column (zero-indexed)\u000a\u000a    >>> _getExcelCellName(0,0)\u000a    'A1'\u000a    >>> _getExcelCellName(2,1)\u000a    'C2'\u000a    """\u000a    return "%s%i" %(get_column_letter(col+1), row+1)#BEWARE - openpyxl uses indexing at 1, to fit with Excel\u000a
p149
sg66
I3
sg52
Nsg67
(lp150
F0.015848931924611134
aF0.12589254117941678
aF0.10000000000000005
aF0.12589254117941676
aF0.11220184543019639
aF0.12589254117941676
aF0.10000000000000005
aF0.11220184543019639
asg69
(lp151
I4
aI2
aI2
aI1
asg71
I1
sg72
F0.10000000000000001
sg73
F0.10000000000000005
sg74
I01
sg75
g76
sg77
I1
sg78
I1
sg79
I1
sg80
I4
sg81
I0
sg82
(dp152
g84
(lp153
F0.94779930276308733
aF1.1746962002725923
aF1.1479471539241786
aF0.81426990111867781
aF0.76096379155751492
aF0.4272560508652532
aF0.78757186915754573
aF0.49399705565338081
aF0.34713961731904419
aF0.20036941660328011
aF0.70751429836673196
aF0.60073907469632104
aF0.26705125678017794
aF0.25367039454067708
aF0.52067878716115956
aF0.62746367036197626
aF0.16031316192311351
aF0.28042577995438478
aF0.56075647392208339
aF1.4015891736016783
aF0.56068614047762821
aF0.5607256841740309
aF0.5473405958910007
aF0.10690411800715083
aF0.21370982956614171
aF0.52064950671592669
aF0.17360135305898439
aF0.20036096451440244
aF0.14695886338631681
aF0.2670434084138833
aF1.3081465145260154
aF0.20036971846457163
aF0.37384881811158266
aF0.26708929117376101
aF0.25368910987890558
aF0.29380452917212097
aF1.0412117758096429
aF0.33384357781687868
aF0.86772694081810187
aF0.1869568590354902
asg86
(lp154
g89
ag89
ag88
ag88
ag89
ag88
ag88
ag88
ag89
ag89
ag88
ag88
ag88
ag88
ag89
ag89
ag88
ag88
ag89
ag89
ag89
ag88
ag88
ag88
ag89
ag89
ag89
ag89
ag88
ag88
ag89
ag89
ag88
ag88
ag88
ag89
ag88
ag88
ag88
ag89
assg90
I01
sg91
g92
sg93
(lp155
I1
aI1
aI1
aI1
aI0
aI1
aI1
aI0
aI1
aI0
aI1
aI0
aI1
aI0
aI0
aI1
aI0
aI0
aI0
aI1
aI1
aI1
aI1
aI0
aI0
aI1
aI1
aI1
aI0
aI1
aI1
aI1
aI1
aI1
aI1
aI0
aI1
aI1
aI1
aI1
asg95
(dp156
g97
I1
sg98
I0
sg99
Vhigh_8
p157
sg101
(lp158
I4
aI2
aI2
aI1
asg103
F0.10000000000000001
sg104
I8
ssg105
(lp159
I4
aI21
aI23
aI27
aI28
aI31
aI35
aI38
asg6
g107
sg11
S''
sg32
Nsg108
g109
sg110
I01
sg111
(lp160
F0.10000000000000001
aF0.063095734448019331
aF0.039810717055349727
aF0.025118864315095801
aF0.015848931924611134
aF0.019952623149688795
aF0.019952623149688795
aF0.019952623149688795
aF0.025118864315095801
aF0.025118864315095801
aF0.031622776601683798
aF0.031622776601683798
aF0.039810717055349734
aF0.039810717055349734
aF0.050118723362727241
aF0.063095734448019344
aF0.063095734448019344
aF0.07943282347242818
aF0.10000000000000005
aF0.12589254117941678
aF0.12589254117941678
aF0.12589254117941678
aF0.10000000000000005
aF0.10000000000000005
aF0.11220184543019639
aF0.12589254117941676
aF0.12589254117941676
aF0.12589254117941676
aF0.11220184543019639
aF0.12589254117941676
aF0.12589254117941676
aF0.12589254117941676
aF0.11220184543019639
aF0.11220184543019639
aF0.11220184543019639
aF0.10000000000000005
aF0.11220184543019639
aF0.11220184543019639
aF0.11220184543019639
aF0.10000000000000005
asg113
I0
sg114
I40
sg115
I39
sg31
I01
sbasg114
I40
sS'conditions'
p161
(lp162
g127
ag141
ag96
ag156
asg75
S'random'
p163
sg73
F0.019952623149688795
sbasS'saveWideText'
p164
I01
sS'thisEntry'
p165
(dp166
sS'version'
p167
S''
sS'_paramNamesSoFar'
p168
(lp169
sS'entries'
p170
(lp171
(dp172
g42
g43
sg15
S'up'
p173
sg41
g12
sg44
V2
sg34
g35
sg36
g40
sg16
F18.494055616549304
sa(dp174
g42
g43
sg17
I1
sg44
V2
sg30
I1
sg22
I2
sg24
I1
sg36
g40
sg25
I0
sg20
g143
sg41
g12
sg27
I4
sg28
g92
sg19
g142
sg34
g35
sg26
S'start'
p175
sg18
I0
sg29
F0.10000000000000001
sg21
F0.10000000000000001
sg23
I1
sa(dp176
g42
g43
sVtrials.maxVal
p177
I1
sg44
V2
sS'trials.response'
p178
I1
sVtrials.sf
p179
I8
sS'trials.thisRepN'
p180
I1
sg36
g40
sS'trials.thisN'
p181
I1
sVtrials.stepSizes
p182
g158
sg41
g12
sS'trials.stepSize'
p183
I4
sS'trials.stepType'
p184
g92
sVtrials.label
p185
g157
sg34
g35
sS'trials.direction'
p186
g175
sVtrials.minVal
p187
I0
sS'trials.intensity'
p188
F0.10000000000000001
sVtrials.startVal
p189
F0.10000000000000001
sS'trials.thisIndex'
p190
I3
sa(dp191
g42
g43
sVtrials.maxVal
p192
I1
sg44
V2
sS'trials.response'
p193
I1
sVtrials.sf
p194
I8
sS'trials.thisRepN'
p195
I1
sg36
g40
sS'trials.thisN'
p196
I2
sVtrials.stepSizes
p197
g102
sg41
g12
sS'trials.stepSize'
p198
I4
sS'trials.stepType'
p199
g92
sVtrials.label
p200
g100
sg34
g35
sS'trials.direction'
p201
g175
sVtrials.minVal
p202
I0
sS'trials.intensity'
p203
F0.001
sVtrials.startVal
p204
F0.001
sS'trials.thisIndex'
p205
I2
sa(dp206
g42
g43
sVtrials.maxVal
p207
I1
sg44
V2
sS'trials.response'
p208
I0
sVtrials.sf
p209
I2
sS'trials.thisRepN'
p210
I1
sg36
g40
sS'trials.thisN'
p211
I3
sVtrials.stepSizes
p212
g129
sg41
g12
sS'trials.stepSize'
p213
I4
sS'trials.stepType'
p214
g92
sVtrials.label
p215
g128
sg34
g35
sS'trials.direction'
p216
g175
sVtrials.minVal
p217
I0
sS'trials.intensity'
p218
F0.001
sVtrials.startVal
p219
F0.001
sS'trials.thisIndex'
p220
I0
sa(dp221
g42
g43
sVtrials.maxVal
p222
I1
sg44
V2
sS'trials.response'
p223
I0
sVtrials.sf
p224
I8
sS'trials.thisRepN'
p225
I2
sg36
g40
sS'trials.thisN'
p226
I4
sVtrials.stepSizes
p227
g102
sg41
g12
sS'trials.stepSize'
p228
I4
sS'trials.stepType'
p229
g92
sVtrials.label
p230
g100
sg34
g35
sS'trials.direction'
p231
g109
sVtrials.minVal
p232
I0
sS'trials.intensity'
p233
F0.0006309573444801932
sVtrials.startVal
p234
F0.001
sS'trials.thisIndex'
p235
I2
sa(dp236
g42
g43
sVtrials.maxVal
p237
I1
sg44
V2
sS'trials.response'
p238
I1
sVtrials.sf
p239
I2
sS'trials.thisRepN'
p240
I2
sg36
g40
sS'trials.thisN'
p241
I5
sVtrials.stepSizes
p242
g143
sg41
g12
sS'trials.stepSize'
p243
I4
sS'trials.stepType'
p244
g92
sVtrials.label
p245
g142
sg34
g35
sS'trials.direction'
p246
g109
sVtrials.minVal
p247
I0
sS'trials.intensity'
p248
F0.063095734448019331
sVtrials.startVal
p249
F0.10000000000000001
sS'trials.thisIndex'
p250
I1
sa(dp251
g42
g43
sVtrials.maxVal
p252
I1
sg44
V2
sS'trials.response'
p253
I0
sVtrials.sf
p254
I2
sS'trials.thisRepN'
p255
I2
sg36
g40
sS'trials.thisN'
p256
I6
sVtrials.stepSizes
p257
g129
sg41
g12
sS'trials.stepSize'
p258
I4
sS'trials.stepType'
p259
g92
sVtrials.label
p260
g128
sg34
g35
sS'trials.direction'
p261
g145
sVtrials.minVal
p262
I0
sS'trials.intensity'
p263
F0.0015848931924611136
sVtrials.startVal
p264
F0.001
sS'trials.thisIndex'
p265
I0
sa(dp266
g42
g43
sVtrials.maxVal
p267
I1
sg44
V2
sS'trials.response'
p268
I1
sVtrials.sf
p269
I8
sS'trials.thisRepN'
p270
I2
sg36
g40
sS'trials.thisN'
p271
I7
sVtrials.stepSizes
p272
g158
sg41
g12
sS'trials.stepSize'
p273
I4
sS'trials.stepType'
p274
g92
sVtrials.label
p275
g157
sg34
g35
sS'trials.direction'
p276
g109
sVtrials.minVal
p277
I0
sS'trials.intensity'
p278
F0.063095734448019331
sVtrials.startVal
p279
F0.10000000000000001
sS'trials.thisIndex'
p280
I3
sa(dp281
g42
g43
sVtrials.maxVal
p282
I1
sg44
V2
sS'trials.response'
p283
I0
sVtrials.sf
p284
I2
sS'trials.thisRepN'
p285
I3
sg36
g40
sS'trials.thisN'
p286
I8
sVtrials.stepSizes
p287
g129
sg41
g12
sS'trials.stepSize'
p288
I4
sS'trials.stepType'
p289
g92
sVtrials.label
p290
g128
sg34
g35
sS'trials.direction'
p291
g145
sVtrials.minVal
p292
I0
sS'trials.intensity'
p293
F0.0025118864315095807
sVtrials.startVal
p294
F0.001
sS'trials.thisIndex'
p295
I0
sa(dp296
g42
g43
sVtrials.maxVal
p297
I1
sg44
V2
sS'trials.response'
p298
I1
sVtrials.sf
p299
I2
sS'trials.thisRepN'
p300
I3
sg36
g40
sS'trials.thisN'
p301
I9
sVtrials.stepSizes
p302
g143
sg41
g12
sS'trials.stepSize'
p303
I4
sS'trials.stepType'
p304
g92
sVtrials.label
p305
g142
sg34
g35
sS'trials.direction'
p306
g109
sVtrials.minVal
p307
I0
sS'trials.intensity'
p308
F0.039810717055349727
sVtrials.startVal
p309
F0.10000000000000001
sS'trials.thisIndex'
p310
I1
sa(dp311
g42
g43
sVtrials.maxVal
p312
I1
sg44
V2
sS'trials.response'
p313
I1
sVtrials.sf
p314
I8
sS'trials.thisRepN'
p315
I3
sg36
g40
sS'trials.thisN'
p316
I10
sVtrials.stepSizes
p317
g102
sg41
g12
sS'trials.stepSize'
p318
I2
sS'trials.stepType'
p319
g92
sVtrials.label
p320
g100
sg34
g35
sS'trials.direction'
p321
g145
sVtrials.minVal
p322
I0
sS'trials.intensity'
p323
F0.00079432823472428153
sVtrials.startVal
p324
F0.001
sS'trials.thisIndex'
p325
I2
sa(dp326
g42
g43
sVtrials.maxVal
p327
I1
sg44
V2
sS'trials.response'
p328
I1
sVtrials.sf
p329
I8
sS'trials.thisRepN'
p330
I3
sg36
g40
sS'trials.thisN'
p331
I11
sVtrials.stepSizes
p332
g158
sg41
g12
sS'trials.stepSize'
p333
I4
sS'trials.stepType'
p334
g92
sVtrials.label
p335
g157
sg34
g35
sS'trials.direction'
p336
g109
sVtrials.minVal
p337
I0
sS'trials.intensity'
p338
F0.039810717055349727
sVtrials.startVal
p339
F0.10000000000000001
sS'trials.thisIndex'
p340
I3
sa(dp341
g42
g43
sVtrials.maxVal
p342
I1
sg44
V2
sS'trials.response'
p343
I1
sVtrials.sf
p344
I2
sS'trials.thisRepN'
p345
I4
sg36
g40
sS'trials.thisN'
p346
I12
sVtrials.stepSizes
p347
g129
sg41
g12
sS'trials.stepSize'
p348
I4
sS'trials.stepType'
p349
g92
sVtrials.label
p350
g128
sg34
g35
sS'trials.direction'
p351
g145
sVtrials.minVal
p352
I0
sS'trials.intensity'
p353
F0.0039810717055349734
sVtrials.startVal
p354
F0.001
sS'trials.thisIndex'
p355
I0
sa(dp356
g42
g43
sVtrials.maxVal
p357
I1
sg44
V2
sS'trials.response'
p358
I1
sVtrials.sf
p359
I8
sS'trials.thisRepN'
p360
I4
sg36
g40
sS'trials.thisN'
p361
I13
sVtrials.stepSizes
p362
g102
sg41
g12
sS'trials.stepSize'
p363
I2
sS'trials.stepType'
p364
g92
sVtrials.label
p365
g100
sg34
g35
sS'trials.direction'
p366
g145
sVtrials.minVal
p367
I0
sS'trials.intensity'
p368
F0.00079432823472428153
sVtrials.startVal
p369
F0.001
sS'trials.thisIndex'
p370
I2
sa(dp371
g42
g43
sVtrials.maxVal
p372
I1
sg44
V2
sS'trials.response'
p373
I1
sVtrials.sf
p374
I2
sS'trials.thisRepN'
p375
I4
sg36
g40
sS'trials.thisN'
p376
I14
sVtrials.stepSizes
p377
g143
sg41
g12
sS'trials.stepSize'
p378
I4
sS'trials.stepType'
p379
g92
sVtrials.label
p380
g142
sg34
g35
sS'trials.direction'
p381
g109
sVtrials.minVal
p382
I0
sS'trials.intensity'
p383
F0.025118864315095801
sVtrials.startVal
p384
F0.10000000000000001
sS'trials.thisIndex'
p385
I1
sa(dp386
g42
g43
sVtrials.maxVal
p387
I1
sg44
V2
sS'trials.response'
p388
I1
sVtrials.sf
p389
I8
sS'trials.thisRepN'
p390
I4
sg36
g40
sS'trials.thisN'
p391
I15
sVtrials.stepSizes
p392
g158
sg41
g12
sS'trials.stepSize'
p393
I4
sS'trials.stepType'
p394
g92
sVtrials.label
p395
g157
sg34
g35
sS'trials.direction'
p396
g109
sVtrials.minVal
p397
I0
sS'trials.intensity'
p398
F0.025118864315095801
sVtrials.startVal
p399
F0.10000000000000001
sS'trials.thisIndex'
p400
I3
sa(dp401
g42
g43
sVtrials.maxVal
p402
I1
sg44
V2
sS'trials.response'
p403
I0
sVtrials.sf
p404
I8
sS'trials.thisRepN'
p405
I5
sg36
g40
sS'trials.thisN'
p406
I16
sVtrials.stepSizes
p407
g158
sg41
g12
sS'trials.stepSize'
p408
I4
sS'trials.stepType'
p409
g92
sVtrials.label
p410
g157
sg34
g35
sS'trials.direction'
p411
g109
sVtrials.minVal
p412
I0
sS'trials.intensity'
p413
F0.015848931924611134
sVtrials.startVal
p414
F0.10000000000000001
sS'trials.thisIndex'
p415
I3
sa(dp416
g42
g43
sVtrials.maxVal
p417
I1
sg44
V2
sS'trials.response'
p418
I1
sVtrials.sf
p419
I2
sS'trials.thisRepN'
p420
I5
sg36
g40
sS'trials.thisN'
p421
I17
sVtrials.stepSizes
p422
g143
sg41
g12
sS'trials.stepSize'
p423
I4
sS'trials.stepType'
p424
g92
sVtrials.label
p425
g142
sg34
g35
sS'trials.direction'
p426
g109
sVtrials.minVal
p427
I0
sS'trials.intensity'
p428
F0.015848931924611134
sVtrials.startVal
p429
F0.10000000000000001
sS'trials.thisIndex'
p430
I1
sa(dp431
g42
g43
sVtrials.maxVal
p432
I1
sg44
V2
sS'trials.response'
p433
I0
sVtrials.sf
p434
I8
sS'trials.thisRepN'
p435
I5
sg36
g40
sS'trials.thisN'
p436
I18
sVtrials.stepSizes
p437
g102
sg41
g12
sS'trials.stepSize'
p438
I2
sS'trials.stepType'
p439
g92
sVtrials.label
p440
g100
sg34
g35
sS'trials.direction'
p441
g145
sVtrials.minVal
p442
I0
sS'trials.intensity'
p443
F0.00079432823472428153
sVtrials.startVal
p444
F0.001
sS'trials.thisIndex'
p445
I2
sa(dp446
g42
g43
sVtrials.maxVal
p447
I1
sg44
V2
sS'trials.response'
p448
I1
sVtrials.sf
p449
I2
sS'trials.thisRepN'
p450
I5
sg36
g40
sS'trials.thisN'
p451
I19
sVtrials.stepSizes
p452
g129
sg41
g12
sS'trials.stepSize'
p453
I2
sS'trials.stepType'
p454
g92
sVtrials.label
p455
g128
sg34
g35
sS'trials.direction'
p456
g109
sVtrials.minVal
p457
I0
sS'trials.intensity'
p458
F0.0031622776601683798
sVtrials.startVal
p459
F0.001
sS'trials.thisIndex'
p460
I0
sa(dp461
g42
g43
sVtrials.maxVal
p462
I1
sg44
V2
sS'trials.response'
p463
I0
sVtrials.sf
p464
I8
sS'trials.thisRepN'
p465
I6
sg36
g40
sS'trials.thisN'
p466
I20
sVtrials.stepSizes
p467
g102
sg41
g12
sS'trials.stepSize'
p468
I2
sS'trials.stepType'
p469
g92
sVtrials.label
p470
g100
sg34
g35
sS'trials.direction'
p471
g145
sVtrials.minVal
p472
I0
sS'trials.intensity'
p473
F0.001
sVtrials.startVal
p474
F0.001
sS'trials.thisIndex'
p475
I2
sa(dp476
g42
g43
sVtrials.maxVal
p477
I1
sg44
V2
sS'trials.response'
p478
I1
sVtrials.sf
p479
I8
sS'trials.thisRepN'
p480
I6
sg36
g40
sS'trials.thisN'
p481
I21
sVtrials.stepSizes
p482
g158
sg41
g12
sS'trials.stepSize'
p483
I2
sS'trials.stepType'
p484
g92
sVtrials.label
p485
g157
sg34
g35
sS'trials.direction'
p486
g145
sVtrials.minVal
p487
I0
sS'trials.intensity'
p488
F0.019952623149688795
sVtrials.startVal
p489
F0.10000000000000001
sS'trials.thisIndex'
p490
I3
sa(dp491
g42
g43
sVtrials.maxVal
p492
I1
sg44
V2
sS'trials.response'
p493
I1
sVtrials.sf
p494
I2
sS'trials.thisRepN'
p495
I6
sg36
g40
sS'trials.thisN'
p496
I22
sVtrials.stepSizes
p497
g143
sg41
g12
sS'trials.stepSize'
p498
I4
sS'trials.stepType'
p499
g92
sVtrials.label
p500
g142
sg34
g35
sS'trials.direction'
p501
g109
sVtrials.minVal
p502
I0
sS'trials.intensity'
p503
F0.0099999999999999985
sVtrials.startVal
p504
F0.10000000000000001
sS'trials.thisIndex'
p505
I1
sa(dp506
g42
g43
sVtrials.maxVal
p507
I1
sg44
V2
sS'trials.response'
p508
I0
sVtrials.sf
p509
I2
sS'trials.thisRepN'
p510
I6
sg36
g40
sS'trials.thisN'
p511
I23
sVtrials.stepSizes
p512
g129
sg41
g12
sS'trials.stepSize'
p513
I2
sS'trials.stepType'
p514
g92
sVtrials.label
p515
g128
sg34
g35
sS'trials.direction'
p516
g109
sVtrials.minVal
p517
I0
sS'trials.intensity'
p518
F0.0031622776601683798
sVtrials.startVal
p519
F0.001
sS'trials.thisIndex'
p520
I0
sa(dp521
g42
g43
sVtrials.maxVal
p522
I1
sg44
V2
sS'trials.response'
p523
I0
sVtrials.sf
p524
I8
sS'trials.thisRepN'
p525
I7
sg36
g40
sS'trials.thisN'
p526
I24
sVtrials.stepSizes
p527
g102
sg41
g12
sS'trials.stepSize'
p528
I2
sS'trials.stepType'
p529
g92
sVtrials.label
p530
g100
sg34
g35
sS'trials.direction'
p531
g145
sVtrials.minVal
p532
I0
sS'trials.intensity'
p533
F0.0012589254117941673
sVtrials.startVal
p534
F0.001
sS'trials.thisIndex'
p535
I2
sa(dp536
g42
g43
sVtrials.maxVal
p537
I1
sg44
V2
sS'trials.response'
p538
I1
sVtrials.sf
p539
I2
sS'trials.thisRepN'
p540
I7
sg36
g40
sS'trials.thisN'
p541
I25
sVtrials.stepSizes
p542
g129
sg41
g12
sS'trials.stepSize'
p543
I2
sS'trials.stepType'
p544
g92
sVtrials.label
p545
g128
sg34
g35
sS'trials.direction'
p546
g145
sVtrials.minVal
p547
I0
sS'trials.intensity'
p548
F0.0039810717055349734
sVtrials.startVal
p549
F0.001
sS'trials.thisIndex'
p550
I0
sa(dp551
g42
g43
sVtrials.maxVal
p552
I1
sg44
V2
sS'trials.response'
p553
I1
sVtrials.sf
p554
I8
sS'trials.thisRepN'
p555
I7
sg36
g40
sS'trials.thisN'
p556
I26
sVtrials.stepSizes
p557
g158
sg41
g12
sS'trials.stepSize'
p558
I2
sS'trials.stepType'
p559
g92
sVtrials.label
p560
g157
sg34
g35
sS'trials.direction'
p561
g145
sVtrials.minVal
p562
I0
sS'trials.intensity'
p563
F0.019952623149688795
sVtrials.startVal
p564
F0.10000000000000001
sS'trials.thisIndex'
p565
I3
sa(dp566
g42
g43
sVtrials.maxVal
p567
I1
sg44
V2
sS'trials.response'
p568
I0
sVtrials.sf
p569
I2
sS'trials.thisRepN'
p570
I7
sg36
g40
sS'trials.thisN'
p571
I27
sVtrials.stepSizes
p572
g143
sg41
g12
sS'trials.stepSize'
p573
I4
sS'trials.stepType'
p574
g92
sVtrials.label
p575
g142
sg34
g35
sS'trials.direction'
p576
g109
sVtrials.minVal
p577
I0
sS'trials.intensity'
p578
F0.0063095734448019311
sVtrials.startVal
p579
F0.10000000000000001
sS'trials.thisIndex'
p580
I1
sa(dp581
g42
g43
sVtrials.maxVal
p582
I1
sg44
V2
sS'trials.response'
p583
I1
sVtrials.sf
p584
I2
sS'trials.thisRepN'
p585
I8
sg36
g40
sS'trials.thisN'
p586
I28
sVtrials.stepSizes
p587
g129
sg41
g12
sS'trials.stepSize'
p588
I2
sS'trials.stepType'
p589
g92
sVtrials.label
p590
g128
sg34
g35
sS'trials.direction'
p591
g145
sVtrials.minVal
p592
I0
sS'trials.intensity'
p593
F0.0039810717055349734
sVtrials.startVal
p594
F0.001
sS'trials.thisIndex'
p595
I0
sa(dp596
g42
g43
sVtrials.maxVal
p597
I1
sg44
V2
sS'trials.response'
p598
I0
sVtrials.sf
p599
I8
sS'trials.thisRepN'
p600
I8
sg36
g40
sS'trials.thisN'
p601
I29
sVtrials.stepSizes
p602
g158
sg41
g12
sS'trials.stepSize'
p603
I2
sS'trials.stepType'
p604
g92
sVtrials.label
p605
g157
sg34
g35
sS'trials.direction'
p606
g145
sVtrials.minVal
p607
I0
sS'trials.intensity'
p608
F0.019952623149688795
sVtrials.startVal
p609
F0.10000000000000001
sS'trials.thisIndex'
p610
I3
sa(dp611
g42
g43
sVtrials.maxVal
p612
I1
sg44
V2
sS'trials.response'
p613
I0
sVtrials.sf
p614
I2
sS'trials.thisRepN'
p615
I8
sg36
g40
sS'trials.thisN'
p616
I30
sVtrials.stepSizes
p617
g143
sg41
g12
sS'trials.stepSize'
p618
I2
sS'trials.stepType'
p619
g92
sVtrials.label
p620
g142
sg34
g35
sS'trials.direction'
p621
g145
sVtrials.minVal
p622
I0
sS'trials.intensity'
p623
F0.0079432823472428138
sVtrials.startVal
p624
F0.10000000000000001
sS'trials.thisIndex'
p625
I1
sa(dp626
g42
g43
sVtrials.maxVal
p627
I1
sg44
V2
sS'trials.response'
p628
I1
sVtrials.sf
p629
I8
sS'trials.thisRepN'
p630
I8
sg36
g40
sS'trials.thisN'
p631
I31
sVtrials.stepSizes
p632
g102
sg41
g12
sS'trials.stepSize'
p633
I2
sS'trials.stepType'
p634
g92
sVtrials.label
p635
g100
sg34
g35
sS'trials.direction'
p636
g145
sVtrials.minVal
p637
I0
sS'trials.intensity'
p638
F0.0015848931924611136
sVtrials.startVal
p639
F0.001
sS'trials.thisIndex'
p640
I2
sa(dp641
g42
g43
sVtrials.maxVal
p642
I1
sg44
V2
sS'trials.response'
p643
I1
sVtrials.sf
p644
I2
sS'trials.thisRepN'
p645
I9
sg36
g40
sS'trials.thisN'
p646
I32
sVtrials.stepSizes
p647
g143
sg41
g12
sS'trials.stepSize'
p648
I2
sS'trials.stepType'
p649
g92
sVtrials.label
p650
g142
sg34
g35
sS'trials.direction'
p651
g145
sVtrials.minVal
p652
I0
sS'trials.intensity'
p653
F0.0099999999999999985
sVtrials.startVal
p654
F0.10000000000000001
sS'trials.thisIndex'
p655
I1
sa(dp656
g42
g43
sVtrials.maxVal
p657
I1
sg44
V2
sS'trials.response'
p658
I1
sVtrials.sf
p659
I8
sS'trials.thisRepN'
p660
I9
sg36
g40
sS'trials.thisN'
p661
I33
sVtrials.stepSizes
p662
g158
sg41
g12
sS'trials.stepSize'
p663
I2
sS'trials.stepType'
p664
g92
sVtrials.label
p665
g157
sg34
g35
sS'trials.direction'
p666
g145
sVtrials.minVal
p667
I0
sS'trials.intensity'
p668
F0.025118864315095801
sVtrials.startVal
p669
F0.10000000000000001
sS'trials.thisIndex'
p670
I3
sa(dp671
g42
g43
sVtrials.maxVal
p672
I1
sg44
V2
sS'trials.response'
p673
I0
sVtrials.sf
p674
I2
sS'trials.thisRepN'
p675
I9
sg36
g40
sS'trials.thisN'
p676
I34
sVtrials.stepSizes
p677
g129
sg41
g12
sS'trials.stepSize'
p678
I2
sS'trials.stepType'
p679
g92
sVtrials.label
p680
g128
sg34
g35
sS'trials.direction'
p681
g145
sVtrials.minVal
p682
I0
sS'trials.intensity'
p683
F0.0039810717055349734
sVtrials.startVal
p684
F0.001
sS'trials.thisIndex'
p685
I0
sa(dp686
g42
g43
sVtrials.maxVal
p687
I1
sg44
V2
sS'trials.response'
p688
I1
sVtrials.sf
p689
I8
sS'trials.thisRepN'
p690
I9
sg36
g40
sS'trials.thisN'
p691
I35
sVtrials.stepSizes
p692
g102
sg41
g12
sS'trials.stepSize'
p693
I2
sS'trials.stepType'
p694
g92
sVtrials.label
p695
g100
sg34
g35
sS'trials.direction'
p696
g145
sVtrials.minVal
p697
I0
sS'trials.intensity'
p698
F0.0015848931924611136
sVtrials.startVal
p699
F0.001
sS'trials.thisIndex'
p700
I2
sa(dp701
g42
g43
sVtrials.maxVal
p702
I1
sg44
V2
sS'trials.response'
p703
I0
sVtrials.sf
p704
I8
sS'trials.thisRepN'
p705
I10
sg36
g40
sS'trials.thisN'
p706
I36
sVtrials.stepSizes
p707
g158
sg41
g12
sS'trials.stepSize'
p708
I2
sS'trials.stepType'
p709
g92
sVtrials.label
p710
g157
sg34
g35
sS'trials.direction'
p711
g145
sVtrials.minVal
p712
I0
sS'trials.intensity'
p713
F0.025118864315095801
sVtrials.startVal
p714
F0.10000000000000001
sS'trials.thisIndex'
p715
I3
sa(dp716
g42
g43
sVtrials.maxVal
p717
I1
sg44
V2
sS'trials.response'
p718
I0
sVtrials.sf
p719
I2
sS'trials.thisRepN'
p720
I10
sg36
g40
sS'trials.thisN'
p721
I37
sVtrials.stepSizes
p722
g143
sg41
g12
sS'trials.stepSize'
p723
I2
sS'trials.stepType'
p724
g92
sVtrials.label
p725
g142
sg34
g35
sS'trials.direction'
p726
g145
sVtrials.minVal
p727
I0
sS'trials.intensity'
p728
F0.0099999999999999985
sVtrials.startVal
p729
F0.10000000000000001
sS'trials.thisIndex'
p730
I1
sa(dp731
g42
g43
sVtrials.maxVal
p732
I1
sg44
V2
sS'trials.response'
p733
I0
sVtrials.sf
p734
I8
sS'trials.thisRepN'
p735
I10
sg36
g40
sS'trials.thisN'
p736
I38
sVtrials.stepSizes
p737
g102
sg41
g12
sS'trials.stepSize'
p738
I2
sS'trials.stepType'
p739
g92
sVtrials.label
p740
g100
sg34
g35
sS'trials.direction'
p741
g145
sVtrials.minVal
p742
I0
sS'trials.intensity'
p743
F0.0015848931924611136
sVtrials.startVal
p744
F0.001
sS'trials.thisIndex'
p745
I2
sa(dp746
g42
g43
sVtrials.maxVal
p747
I1
sg44
V2
sS'trials.response'
p748
I0
sVtrials.sf
p749
I2
sS'trials.thisRepN'
p750
I10
sg36
g40
sS'trials.thisN'
p751
I39
sVtrials.stepSizes
p752
g129
sg41
g12
sS'trials.stepSize'
p753
I2
sS'trials.stepType'
p754
g92
sVtrials.label
p755
g128
sg34
g35
sS'trials.direction'
p756
g145
sVtrials.minVal
p757
I0
sS'trials.intensity'
p758
F0.0050118723362727246
sVtrials.startVal
p759
F0.001
sS'trials.thisIndex'
p760
I0
sa(dp761
g42
g43
sVtrials.maxVal
p762
I1
sg44
V2
sS'trials.response'
p763
I1
sVtrials.sf
p764
I2
sS'trials.thisRepN'
p765
I11
sg36
g40
sS'trials.thisN'
p766
I40
sVtrials.stepSizes
p767
g143
sg41
g12
sS'trials.stepSize'
p768
I2
sS'trials.stepType'
p769
g92
sVtrials.label
p770
g142
sg34
g35
sS'trials.direction'
p771
g145
sVtrials.minVal
p772
I0
sS'trials.intensity'
p773
F0.012589254117941671
sVtrials.startVal
p774
F0.10000000000000001
sS'trials.thisIndex'
p775
I1
sa(dp776
g42
g43
sVtrials.maxVal
p777
I1
sg44
V2
sS'trials.response'
p778
I1
sVtrials.sf
p779
I2
sS'trials.thisRepN'
p780
I11
sg36
g40
sS'trials.thisN'
p781
I41
sVtrials.stepSizes
p782
g129
sg41
g12
sS'trials.stepSize'
p783
I2
sS'trials.stepType'
p784
g92
sVtrials.label
p785
g128
sg34
g35
sS'trials.direction'
p786
g145
sVtrials.minVal
p787
I0
sS'trials.intensity'
p788
F0.0063095734448019355
sVtrials.startVal
p789
F0.001
sS'trials.thisIndex'
p790
I0
sa(dp791
g42
g43
sVtrials.maxVal
p792
I1
sg44
V2
sS'trials.response'
p793
I1
sVtrials.sf
p794
I8
sS'trials.thisRepN'
p795
I11
sg36
g40
sS'trials.thisN'
p796
I42
sVtrials.stepSizes
p797
g102
sg41
g12
sS'trials.stepSize'
p798
I2
sS'trials.stepType'
p799
g92
sVtrials.label
p800
g100
sg34
g35
sS'trials.direction'
p801
g145
sVtrials.minVal
p802
I0
sS'trials.intensity'
p803
F0.0019952623149688798
sVtrials.startVal
p804
F0.001
sS'trials.thisIndex'
p805
I2
sa(dp806
g42
g43
sVtrials.maxVal
p807
I1
sg44
V2
sS'trials.response'
p808
I1
sVtrials.sf
p809
I8
sS'trials.thisRepN'
p810
I11
sg36
g40
sS'trials.thisN'
p811
I43
sVtrials.stepSizes
p812
g158
sg41
g12
sS'trials.stepSize'
p813
I2
sS'trials.stepType'
p814
g92
sVtrials.label
p815
g157
sg34
g35
sS'trials.direction'
p816
g145
sVtrials.minVal
p817
I0
sS'trials.intensity'
p818
F0.031622776601683798
sVtrials.startVal
p819
F0.10000000000000001
sS'trials.thisIndex'
p820
I3
sa(dp821
g42
g43
sVtrials.maxVal
p822
I1
sg44
V2
sS'trials.response'
p823
I1
sVtrials.sf
p824
I2
sS'trials.thisRepN'
p825
I12
sg36
g40
sS'trials.thisN'
p826
I44
sVtrials.stepSizes
p827
g129
sg41
g12
sS'trials.stepSize'
p828
I2
sS'trials.stepType'
p829
g92
sVtrials.label
p830
g128
sg34
g35
sS'trials.direction'
p831
g145
sVtrials.minVal
p832
I0
sS'trials.intensity'
p833
F0.0063095734448019355
sVtrials.startVal
p834
F0.001
sS'trials.thisIndex'
p835
I0
sa(dp836
g42
g43
sVtrials.maxVal
p837
I1
sg44
V2
sS'trials.response'
p838
I1
sVtrials.sf
p839
I2
sS'trials.thisRepN'
p840
I12
sg36
g40
sS'trials.thisN'
p841
I45
sVtrials.stepSizes
p842
g143
sg41
g12
sS'trials.stepSize'
p843
I2
sS'trials.stepType'
p844
g92
sVtrials.label
p845
g142
sg34
g35
sS'trials.direction'
p846
g145
sVtrials.minVal
p847
I0
sS'trials.intensity'
p848
F0.012589254117941671
sVtrials.startVal
p849
F0.10000000000000001
sS'trials.thisIndex'
p850
I1
sa(dp851
g42
g43
sVtrials.maxVal
p852
I1
sg44
V2
sS'trials.response'
p853
I0
sVtrials.sf
p854
I8
sS'trials.thisRepN'
p855
I12
sg36
g40
sS'trials.thisN'
p856
I46
sVtrials.stepSizes
p857
g158
sg41
g12
sS'trials.stepSize'
p858
I2
sS'trials.stepType'
p859
g92
sVtrials.label
p860
g157
sg34
g35
sS'trials.direction'
p861
g145
sVtrials.minVal
p862
I0
sS'trials.intensity'
p863
F0.031622776601683798
sVtrials.startVal
p864
F0.10000000000000001
sS'trials.thisIndex'
p865
I3
sa(dp866
g42
g43
sVtrials.maxVal
p867
I1
sg44
V2
sS'trials.response'
p868
I1
sVtrials.sf
p869
I8
sS'trials.thisRepN'
p870
I12
sg36
g40
sS'trials.thisN'
p871
I47
sVtrials.stepSizes
p872
g102
sg41
g12
sS'trials.stepSize'
p873
I2
sS'trials.stepType'
p874
g92
sVtrials.label
p875
g100
sg34
g35
sS'trials.direction'
p876
g145
sVtrials.minVal
p877
I0
sS'trials.intensity'
p878
F0.0019952623149688798
sVtrials.startVal
p879
F0.001
sS'trials.thisIndex'
p880
I2
sa(dp881
g42
g43
sVtrials.maxVal
p882
I1
sg44
V2
sS'trials.response'
p883
I0
sVtrials.sf
p884
I8
sS'trials.thisRepN'
p885
I13
sg36
g40
sS'trials.thisN'
p886
I48
sVtrials.stepSizes
p887
g102
sg41
g12
sS'trials.stepSize'
p888
I2
sS'trials.stepType'
p889
g92
sVtrials.label
p890
g100
sg34
g35
sS'trials.direction'
p891
g145
sVtrials.minVal
p892
I0
sS'trials.intensity'
p893
F0.0019952623149688798
sVtrials.startVal
p894
F0.001
sS'trials.thisIndex'
p895
I2
sa(dp896
g42
g43
sVtrials.maxVal
p897
I1
sg44
V2
sS'trials.response'
p898
I1
sVtrials.sf
p899
I8
sS'trials.thisRepN'
p900
I13
sg36
g40
sS'trials.thisN'
p901
I49
sVtrials.stepSizes
p902
g158
sg41
g12
sS'trials.stepSize'
p903
I2
sS'trials.stepType'
p904
g92
sVtrials.label
p905
g157
sg34
g35
sS'trials.direction'
p906
g145
sVtrials.minVal
p907
I0
sS'trials.intensity'
p908
F0.039810717055349734
sVtrials.startVal
p909
F0.10000000000000001
sS'trials.thisIndex'
p910
I3
sa(dp911
g42
g43
sVtrials.maxVal
p912
I1
sg44
V2
sS'trials.response'
p913
I0
sVtrials.sf
p914
I2
sS'trials.thisRepN'
p915
I13
sg36
g40
sS'trials.thisN'
p916
I50
sVtrials.stepSizes
p917
g143
sg41
g12
sS'trials.stepSize'
p918
I2
sS'trials.stepType'
p919
g92
sVtrials.label
p920
g142
sg34
g35
sS'trials.direction'
p921
g145
sVtrials.minVal
p922
I0
sS'trials.intensity'
p923
F0.012589254117941671
sVtrials.startVal
p924
F0.10000000000000001
sS'trials.thisIndex'
p925
I1
sa(dp926
g42
g43
sVtrials.maxVal
p927
I1
sg44
V2
sS'trials.response'
p928
I1
sVtrials.sf
p929
I2
sS'trials.thisRepN'
p930
I13
sg36
g40
sS'trials.thisN'
p931
I51
sVtrials.stepSizes
p932
g129
sg41
g12
sS'trials.stepSize'
p933
I2
sS'trials.stepType'
p934
g92
sVtrials.label
p935
g128
sg34
g35
sS'trials.direction'
p936
g145
sVtrials.minVal
p937
I0
sS'trials.intensity'
p938
F0.0063095734448019355
sVtrials.startVal
p939
F0.001
sS'trials.thisIndex'
p940
I0
sa(dp941
g42
g43
sVtrials.maxVal
p942
I1
sg44
V2
sS'trials.response'
p943
I0
sVtrials.sf
p944
I8
sS'trials.thisRepN'
p945
I14
sg36
g40
sS'trials.thisN'
p946
I52
sVtrials.stepSizes
p947
g158
sg41
g12
sS'trials.stepSize'
p948
I2
sS'trials.stepType'
p949
g92
sVtrials.label
p950
g157
sg34
g35
sS'trials.direction'
p951
g145
sVtrials.minVal
p952
I0
sS'trials.intensity'
p953
F0.039810717055349734
sVtrials.startVal
p954
F0.10000000000000001
sS'trials.thisIndex'
p955
I3
sa(dp956
g42
g43
sVtrials.maxVal
p957
I1
sg44
V2
sS'trials.response'
p958
I1
sVtrials.sf
p959
I2
sS'trials.thisRepN'
p960
I14
sg36
g40
sS'trials.thisN'
p961
I53
sVtrials.stepSizes
p962
g143
sg41
g12
sS'trials.stepSize'
p963
I2
sS'trials.stepType'
p964
g92
sVtrials.label
p965
g142
sg34
g35
sS'trials.direction'
p966
g145
sVtrials.minVal
p967
I0
sS'trials.intensity'
p968
F0.015848931924611134
sVtrials.startVal
p969
F0.10000000000000001
sS'trials.thisIndex'
p970
I1
sa(dp971
g42
g43
sVtrials.maxVal
p972
I1
sg44
V2
sS'trials.response'
p973
I0
sVtrials.sf
p974
I2
sS'trials.thisRepN'
p975
I14
sg36
g40
sS'trials.thisN'
p976
I54
sVtrials.stepSizes
p977
g129
sg41
g12
sS'trials.stepSize'
p978
I1
sS'trials.stepType'
p979
g92
sVtrials.label
p980
g128
sg34
g35
sS'trials.direction'
p981
g109
sVtrials.minVal
p982
I0
sS'trials.intensity'
p983
F0.0056234132519034936
sVtrials.startVal
p984
F0.001
sS'trials.thisIndex'
p985
I0
sa(dp986
g42
g43
sVtrials.maxVal
p987
I1
sg44
V2
sS'trials.response'
p988
I0
sVtrials.sf
p989
I8
sS'trials.thisRepN'
p990
I14
sg36
g40
sS'trials.thisN'
p991
I55
sVtrials.stepSizes
p992
g102
sg41
g12
sS'trials.stepSize'
p993
I2
sS'trials.stepType'
p994
g92
sVtrials.label
p995
g100
sg34
g35
sS'trials.direction'
p996
g145
sVtrials.minVal
p997
I0
sS'trials.intensity'
p998
F0.0025118864315095803
sVtrials.startVal
p999
F0.001
sS'trials.thisIndex'
p1000
I2
sa(dp1001
g42
g43
sVtrials.maxVal
p1002
I1
sg44
V2
sS'trials.response'
p1003
I1
sVtrials.sf
p1004
I2
sS'trials.thisRepN'
p1005
I15
sg36
g40
sS'trials.thisN'
p1006
I56
sVtrials.stepSizes
p1007
g129
sg41
g12
sS'trials.stepSize'
p1008
I1
sS'trials.stepType'
p1009
g92
sVtrials.label
p1010
g128
sg34
g35
sS'trials.direction'
p1011
g145
sVtrials.minVal
p1012
I0
sS'trials.intensity'
p1013
F0.0063095734448019355
sVtrials.startVal
p1014
F0.001
sS'trials.thisIndex'
p1015
I0
sa(dp1016
g42
g43
sVtrials.maxVal
p1017
I1
sg44
V2
sS'trials.response'
p1018
I0
sVtrials.sf
p1019
I8
sS'trials.thisRepN'
p1020
I15
sg36
g40
sS'trials.thisN'
p1021
I57
sVtrials.stepSizes
p1022
g158
sg41
g12
sS'trials.stepSize'
p1023
I2
sS'trials.stepType'
p1024
g92
sVtrials.label
p1025
g157
sg34
g35
sS'trials.direction'
p1026
g145
sVtrials.minVal
p1027
I0
sS'trials.intensity'
p1028
F0.050118723362727241
sVtrials.startVal
p1029
F0.10000000000000001
sS'trials.thisIndex'
p1030
I3
sa(dp1031
g42
g43
sVtrials.maxVal
p1032
I1
sg44
V2
sS'trials.response'
p1033
I1
sVtrials.sf
p1034
I2
sS'trials.thisRepN'
p1035
I15
sg36
g40
sS'trials.thisN'
p1036
I58
sVtrials.stepSizes
p1037
g143
sg41
g12
sS'trials.stepSize'
p1038
I2
sS'trials.stepType'
p1039
g92
sVtrials.label
p1040
g142
sg34
g35
sS'trials.direction'
p1041
g145
sVtrials.minVal
p1042
I0
sS'trials.intensity'
p1043
F0.015848931924611134
sVtrials.startVal
p1044
F0.10000000000000001
sS'trials.thisIndex'
p1045
I1
sa(dp1046
g42
g43
sVtrials.maxVal
p1047
I1
sg44
V2
sS'trials.response'
p1048
I1
sVtrials.sf
p1049
I8
sS'trials.thisRepN'
p1050
I15
sg36
g40
sS'trials.thisN'
p1051
I59
sVtrials.stepSizes
p1052
g102
sg41
g12
sS'trials.stepSize'
p1053
I2
sS'trials.stepType'
p1054
g92
sVtrials.label
p1055
g100
sg34
g35
sS'trials.direction'
p1056
g145
sVtrials.minVal
p1057
I0
sS'trials.intensity'
p1058
F0.0031622776601683798
sVtrials.startVal
p1059
F0.001
sS'trials.thisIndex'
p1060
I2
sa(dp1061
g42
g43
sVtrials.maxVal
p1062
I1
sg44
V2
sS'trials.response'
p1063
I1
sVtrials.sf
p1064
I2
sS'trials.thisRepN'
p1065
I16
sg36
g40
sS'trials.thisN'
p1066
I60
sVtrials.stepSizes
p1067
g143
sg41
g12
sS'trials.stepSize'
p1068
I2
sS'trials.stepType'
p1069
g92
sVtrials.label
p1070
g142
sg34
g35
sS'trials.direction'
p1071
g145
sVtrials.minVal
p1072
I0
sS'trials.intensity'
p1073
F0.015848931924611134
sVtrials.startVal
p1074
F0.10000000000000001
sS'trials.thisIndex'
p1075
I1
sa(dp1076
g42
g43
sVtrials.maxVal
p1077
I1
sg44
V2
sS'trials.response'
p1078
I1
sVtrials.sf
p1079
I8
sS'trials.thisRepN'
p1080
I16
sg36
g40
sS'trials.thisN'
p1081
I61
sVtrials.stepSizes
p1082
g158
sg41
g12
sS'trials.stepSize'
p1083
I2
sS'trials.stepType'
p1084
g92
sVtrials.label
p1085
g157
sg34
g35
sS'trials.direction'
p1086
g145
sVtrials.minVal
p1087
I0
sS'trials.intensity'
p1088
F0.063095734448019344
sVtrials.startVal
p1089
F0.10000000000000001
sS'trials.thisIndex'
p1090
I3
sa(dp1091
g42
g43
sVtrials.maxVal
p1092
I1
sg44
V2
sS'trials.response'
p1093
I1
sVtrials.sf
p1094
I2
sS'trials.thisRepN'
p1095
I16
sg36
g40
sS'trials.thisN'
p1096
I62
sVtrials.stepSizes
p1097
g129
sg41
g12
sS'trials.stepSize'
p1098
I1
sS'trials.stepType'
p1099
g92
sVtrials.label
p1100
g128
sg34
g35
sS'trials.direction'
p1101
g145
sVtrials.minVal
p1102
I0
sS'trials.intensity'
p1103
F0.0063095734448019355
sVtrials.startVal
p1104
F0.001
sS'trials.thisIndex'
p1105
I0
sa(dp1106
g42
g43
sVtrials.maxVal
p1107
I1
sg44
V2
sS'trials.response'
p1108
I1
sVtrials.sf
p1109
I8
sS'trials.thisRepN'
p1110
I16
sg36
g40
sS'trials.thisN'
p1111
I63
sVtrials.stepSizes
p1112
g102
sg41
g12
sS'trials.stepSize'
p1113
I2
sS'trials.stepType'
p1114
g92
sVtrials.label
p1115
g100
sg34
g35
sS'trials.direction'
p1116
g145
sVtrials.minVal
p1117
I0
sS'trials.intensity'
p1118
F0.0031622776601683798
sVtrials.startVal
p1119
F0.001
sS'trials.thisIndex'
p1120
I2
sa(dp1121
g42
g43
sVtrials.maxVal
p1122
I1
sg44
V2
sS'trials.response'
p1123
I1
sVtrials.sf
p1124
I2
sS'trials.thisRepN'
p1125
I17
sg36
g40
sS'trials.thisN'
p1126
I64
sVtrials.stepSizes
p1127
g129
sg41
g12
sS'trials.stepSize'
p1128
I1
sS'trials.stepType'
p1129
g92
sVtrials.label
p1130
g128
sg34
g35
sS'trials.direction'
p1131
g145
sVtrials.minVal
p1132
I0
sS'trials.intensity'
p1133
F0.0063095734448019355
sVtrials.startVal
p1134
F0.001
sS'trials.thisIndex'
p1135
I0
sa(dp1136
g42
g43
sVtrials.maxVal
p1137
I1
sg44
V2
sS'trials.response'
p1138
I0
sVtrials.sf
p1139
I8
sS'trials.thisRepN'
p1140
I17
sg36
g40
sS'trials.thisN'
p1141
I65
sVtrials.stepSizes
p1142
g158
sg41
g12
sS'trials.stepSize'
p1143
I2
sS'trials.stepType'
p1144
g92
sVtrials.label
p1145
g157
sg34
g35
sS'trials.direction'
p1146
g145
sVtrials.minVal
p1147
I0
sS'trials.intensity'
p1148
F0.063095734448019344
sVtrials.startVal
p1149
F0.10000000000000001
sS'trials.thisIndex'
p1150
I3
sa(dp1151
g42
g43
sVtrials.maxVal
p1152
I1
sg44
V2
sS'trials.response'
p1153
I0
sVtrials.sf
p1154
I8
sS'trials.thisRepN'
p1155
I17
sg36
g40
sS'trials.thisN'
p1156
I66
sVtrials.stepSizes
p1157
g102
sg41
g12
sS'trials.stepSize'
p1158
I2
sS'trials.stepType'
p1159
g92
sVtrials.label
p1160
g100
sg34
g35
sS'trials.direction'
p1161
g145
sVtrials.minVal
p1162
I0
sS'trials.intensity'
p1163
F0.0031622776601683798
sVtrials.startVal
p1164
F0.001
sS'trials.thisIndex'
p1165
I2
sa(dp1166
g42
g43
sVtrials.maxVal
p1167
I1
sg44
V2
sS'trials.response'
p1168
I0
sVtrials.sf
p1169
I2
sS'trials.thisRepN'
p1170
I17
sg36
g40
sS'trials.thisN'
p1171
I67
sVtrials.stepSizes
p1172
g143
sg41
g12
sS'trials.stepSize'
p1173
I2
sS'trials.stepType'
p1174
g92
sVtrials.label
p1175
g142
sg34
g35
sS'trials.direction'
p1176
g109
sVtrials.minVal
p1177
I0
sS'trials.intensity'
p1178
F0.012589254117941671
sVtrials.startVal
p1179
F0.10000000000000001
sS'trials.thisIndex'
p1180
I1
sa(dp1181
g42
g43
sVtrials.maxVal
p1182
I1
sg44
V2
sS'trials.response'
p1183
I1
sVtrials.sf
p1184
I8
sS'trials.thisRepN'
p1185
I18
sg36
g40
sS'trials.thisN'
p1186
I68
sVtrials.stepSizes
p1187
g102
sg41
g12
sS'trials.stepSize'
p1188
I2
sS'trials.stepType'
p1189
g92
sVtrials.label
p1190
g100
sg34
g35
sS'trials.direction'
p1191
g145
sVtrials.minVal
p1192
I0
sS'trials.intensity'
p1193
F0.0039810717055349734
sVtrials.startVal
p1194
F0.001
sS'trials.thisIndex'
p1195
I2
sa(dp1196
g42
g43
sVtrials.maxVal
p1197
I1
sg44
V2
sS'trials.response'
p1198
I0
sVtrials.sf
p1199
I8
sS'trials.thisRepN'
p1200
I18
sg36
g40
sS'trials.thisN'
p1201
I69
sVtrials.stepSizes
p1202
g158
sg41
g12
sS'trials.stepSize'
p1203
I2
sS'trials.stepType'
p1204
g92
sVtrials.label
p1205
g157
sg34
g35
sS'trials.direction'
p1206
g145
sVtrials.minVal
p1207
I0
sS'trials.intensity'
p1208
F0.07943282347242818
sVtrials.startVal
p1209
F0.10000000000000001
sS'trials.thisIndex'
p1210
I3
sa(dp1211
g42
g43
sVtrials.maxVal
p1212
I1
sg44
V2
sS'trials.response'
p1213
I0
sVtrials.sf
p1214
I2
sS'trials.thisRepN'
p1215
I18
sg36
g40
sS'trials.thisN'
p1216
I70
sVtrials.stepSizes
p1217
g129
sg41
g12
sS'trials.stepSize'
p1218
I1
sS'trials.stepType'
p1219
g92
sVtrials.label
p1220
g128
sg34
g35
sS'trials.direction'
p1221
g109
sVtrials.minVal
p1222
I0
sS'trials.intensity'
p1223
F0.0056234132519034936
sVtrials.startVal
p1224
F0.001
sS'trials.thisIndex'
p1225
I0
sa(dp1226
g42
g43
sVtrials.maxVal
p1227
I1
sg44
V2
sS'trials.response'
p1228
I1
sVtrials.sf
p1229
I2
sS'trials.thisRepN'
p1230
I18
sg36
g40
sS'trials.thisN'
p1231
I71
sVtrials.stepSizes
p1232
g143
sg41
g12
sS'trials.stepSize'
p1233
I1
sS'trials.stepType'
p1234
g92
sVtrials.label
p1235
g142
sg34
g35
sS'trials.direction'
p1236
g145
sVtrials.minVal
p1237
I0
sS'trials.intensity'
p1238
F0.014125375446227542
sVtrials.startVal
p1239
F0.10000000000000001
sS'trials.thisIndex'
p1240
I1
sa(dp1241
g42
g43
sVtrials.maxVal
p1242
I1
sg44
V2
sS'trials.response'
p1243
I1
sVtrials.sf
p1244
I8
sS'trials.thisRepN'
p1245
I19
sg36
g40
sS'trials.thisN'
p1246
I72
sVtrials.stepSizes
p1247
g102
sg41
g12
sS'trials.stepSize'
p1248
I2
sS'trials.stepType'
p1249
g92
sVtrials.label
p1250
g100
sg34
g35
sS'trials.direction'
p1251
g145
sVtrials.minVal
p1252
I0
sS'trials.intensity'
p1253
F0.0039810717055349734
sVtrials.startVal
p1254
F0.001
sS'trials.thisIndex'
p1255
I2
sa(dp1256
g42
g43
sVtrials.maxVal
p1257
I1
sg44
V2
sS'trials.response'
p1258
I1
sVtrials.sf
p1259
I2
sS'trials.thisRepN'
p1260
I19
sg36
g40
sS'trials.thisN'
p1261
I73
sVtrials.stepSizes
p1262
g129
sg41
g12
sS'trials.stepSize'
p1263
I1
sS'trials.stepType'
p1264
g92
sVtrials.label
p1265
g128
sg34
g35
sS'trials.direction'
p1266
g145
sVtrials.minVal
p1267
I0
sS'trials.intensity'
p1268
F0.0063095734448019355
sVtrials.startVal
p1269
F0.001
sS'trials.thisIndex'
p1270
I0
sa(dp1271
g42
g43
sVtrials.maxVal
p1272
I1
sg44
V2
sS'trials.response'
p1273
I1
sVtrials.sf
p1274
I2
sS'trials.thisRepN'
p1275
I19
sg36
g40
sS'trials.thisN'
p1276
I74
sVtrials.stepSizes
p1277
g143
sg41
g12
sS'trials.stepSize'
p1278
I1
sS'trials.stepType'
p1279
g92
sVtrials.label
p1280
g142
sg34
g35
sS'trials.direction'
p1281
g145
sVtrials.minVal
p1282
I0
sS'trials.intensity'
p1283
F0.014125375446227542
sVtrials.startVal
p1284
F0.10000000000000001
sS'trials.thisIndex'
p1285
I1
sa(dp1286
g42
g43
sVtrials.maxVal
p1287
I1
sg44
V2
sS'trials.response'
p1288
I0
sVtrials.sf
p1289
I8
sS'trials.thisRepN'
p1290
I19
sg36
g40
sS'trials.thisN'
p1291
I75
sVtrials.stepSizes
p1292
g158
sg41
g12
sS'trials.stepSize'
p1293
I2
sS'trials.stepType'
p1294
g92
sVtrials.label
p1295
g157
sg34
g35
sS'trials.direction'
p1296
g145
sVtrials.minVal
p1297
I0
sS'trials.intensity'
p1298
F0.10000000000000005
sVtrials.startVal
p1299
F0.10000000000000001
sS'trials.thisIndex'
p1300
I3
sa(dp1301
g42
g43
sVtrials.maxVal
p1302
I1
sg44
V2
sS'trials.response'
p1303
I0
sVtrials.sf
p1304
I8
sS'trials.thisRepN'
p1305
I20
sg36
g40
sS'trials.thisN'
p1306
I76
sVtrials.stepSizes
p1307
g102
sg41
g12
sS'trials.stepSize'
p1308
I2
sS'trials.stepType'
p1309
g92
sVtrials.label
p1310
g100
sg34
g35
sS'trials.direction'
p1311
g145
sVtrials.minVal
p1312
I0
sS'trials.intensity'
p1313
F0.0039810717055349734
sVtrials.startVal
p1314
F0.001
sS'trials.thisIndex'
p1315
I2
sa(dp1316
g42
g43
sVtrials.maxVal
p1317
I1
sg44
V2
sS'trials.response'
p1318
I1
sVtrials.sf
p1319
I2
sS'trials.thisRepN'
p1320
I20
sg36
g40
sS'trials.thisN'
p1321
I77
sVtrials.stepSizes
p1322
g129
sg41
g12
sS'trials.stepSize'
p1323
I1
sS'trials.stepType'
p1324
g92
sVtrials.label
p1325
g128
sg34
g35
sS'trials.direction'
p1326
g145
sVtrials.minVal
p1327
I0
sS'trials.intensity'
p1328
F0.0063095734448019355
sVtrials.startVal
p1329
F0.001
sS'trials.thisIndex'
p1330
I0
sa(dp1331
g42
g43
sVtrials.maxVal
p1332
I1
sg44
V2
sS'trials.response'
p1333
I1
sVtrials.sf
p1334
I8
sS'trials.thisRepN'
p1335
I20
sg36
g40
sS'trials.thisN'
p1336
I78
sVtrials.stepSizes
p1337
g158
sg41
g12
sS'trials.stepSize'
p1338
I2
sS'trials.stepType'
p1339
g92
sVtrials.label
p1340
g157
sg34
g35
sS'trials.direction'
p1341
g145
sVtrials.minVal
p1342
I0
sS'trials.intensity'
p1343
F0.12589254117941678
sVtrials.startVal
p1344
F0.10000000000000001
sS'trials.thisIndex'
p1345
I3
sa(dp1346
g42
g43
sVtrials.maxVal
p1347
I1
sg44
V2
sS'trials.response'
p1348
I1
sVtrials.sf
p1349
I2
sS'trials.thisRepN'
p1350
I20
sg36
g40
sS'trials.thisN'
p1351
I79
sVtrials.stepSizes
p1352
g143
sg41
g12
sS'trials.stepSize'
p1353
I1
sS'trials.stepType'
p1354
g92
sVtrials.label
p1355
g142
sg34
g35
sS'trials.direction'
p1356
g145
sVtrials.minVal
p1357
I0
sS'trials.intensity'
p1358
F0.014125375446227542
sVtrials.startVal
p1359
F0.10000000000000001
sS'trials.thisIndex'
p1360
I1
sa(dp1361
g42
g43
sVtrials.maxVal
p1362
I1
sg44
V2
sS'trials.response'
p1363
I0
sVtrials.sf
p1364
I2
sS'trials.thisRepN'
p1365
I21
sg36
g40
sS'trials.thisN'
p1366
I80
sVtrials.stepSizes
p1367
g129
sg41
g12
sS'trials.stepSize'
p1368
I1
sS'trials.stepType'
p1369
g92
sVtrials.label
p1370
g128
sg34
g35
sS'trials.direction'
p1371
g145
sVtrials.minVal
p1372
I0
sS'trials.intensity'
p1373
F0.0063095734448019355
sVtrials.startVal
p1374
F0.001
sS'trials.thisIndex'
p1375
I0
sa(dp1376
g42
g43
sVtrials.maxVal
p1377
I1
sg44
V2
sS'trials.response'
p1378
I1
sVtrials.sf
p1379
I8
sS'trials.thisRepN'
p1380
I21
sg36
g40
sS'trials.thisN'
p1381
I81
sVtrials.stepSizes
p1382
g158
sg41
g12
sS'trials.stepSize'
p1383
I2
sS'trials.stepType'
p1384
g92
sVtrials.label
p1385
g157
sg34
g35
sS'trials.direction'
p1386
g145
sVtrials.minVal
p1387
I0
sS'trials.intensity'
p1388
F0.12589254117941678
sVtrials.startVal
p1389
F0.10000000000000001
sS'trials.thisIndex'
p1390
I3
sa(dp1391
g42
g43
sVtrials.maxVal
p1392
I1
sg44
V2
sS'trials.response'
p1393
I1
sVtrials.sf
p1394
I8
sS'trials.thisRepN'
p1395
I21
sg36
g40
sS'trials.thisN'
p1396
I82
sVtrials.stepSizes
p1397
g102
sg41
g12
sS'trials.stepSize'
p1398
I2
sS'trials.stepType'
p1399
g92
sVtrials.label
p1400
g100
sg34
g35
sS'trials.direction'
p1401
g145
sVtrials.minVal
p1402
I0
sS'trials.intensity'
p1403
F0.0050118723362727246
sVtrials.startVal
p1404
F0.001
sS'trials.thisIndex'
p1405
I2
sa(dp1406
g42
g43
sVtrials.maxVal
p1407
I1
sg44
V2
sS'trials.response'
p1408
I1
sVtrials.sf
p1409
I2
sS'trials.thisRepN'
p1410
I21
sg36
g40
sS'trials.thisN'
p1411
I83
sVtrials.stepSizes
p1412
g143
sg41
g12
sS'trials.stepSize'
p1413
I1
sS'trials.stepType'
p1414
g92
sVtrials.label
p1415
g142
sg34
g35
sS'trials.direction'
p1416
g109
sVtrials.minVal
p1417
I0
sS'trials.intensity'
p1418
F0.012589254117941671
sVtrials.startVal
p1419
F0.10000000000000001
sS'trials.thisIndex'
p1420
I1
sa(dp1421
g42
g43
sVtrials.maxVal
p1422
I1
sg44
V2
sS'trials.response'
p1423
I0
sVtrials.sf
p1424
I2
sS'trials.thisRepN'
p1425
I22
sg36
g40
sS'trials.thisN'
p1426
I84
sVtrials.stepSizes
p1427
g129
sg41
g12
sS'trials.stepSize'
p1428
I1
sS'trials.stepType'
p1429
g92
sVtrials.label
p1430
g128
sg34
g35
sS'trials.direction'
p1431
g145
sVtrials.minVal
p1432
I0
sS'trials.intensity'
p1433
F0.0070794578438413821
sVtrials.startVal
p1434
F0.001
sS'trials.thisIndex'
p1435
I0
sa(dp1436
g42
g43
sVtrials.maxVal
p1437
I1
sg44
V2
sS'trials.response'
p1438
I1
sVtrials.sf
p1439
I8
sS'trials.thisRepN'
p1440
I22
sg36
g40
sS'trials.thisN'
p1441
I85
sVtrials.stepSizes
p1442
g158
sg41
g12
sS'trials.stepSize'
p1443
I2
sS'trials.stepType'
p1444
g92
sVtrials.label
p1445
g157
sg34
g35
sS'trials.direction'
p1446
g145
sVtrials.minVal
p1447
I0
sS'trials.intensity'
p1448
F0.12589254117941678
sVtrials.startVal
p1449
F0.10000000000000001
sS'trials.thisIndex'
p1450
I3
sa(dp1451
g42
g43
sVtrials.maxVal
p1452
I1
sg44
V2
sS'trials.response'
p1453
I0
sVtrials.sf
p1454
I2
sS'trials.thisRepN'
p1455
I22
sg36
g40
sS'trials.thisN'
p1456
I86
sVtrials.stepSizes
p1457
g143
sg41
g12
sS'trials.stepSize'
p1458
I1
sS'trials.stepType'
p1459
g92
sVtrials.label
p1460
g142
sg34
g35
sS'trials.direction'
p1461
g109
sVtrials.minVal
p1462
I0
sS'trials.intensity'
p1463
F0.012589254117941671
sVtrials.startVal
p1464
F0.10000000000000001
sS'trials.thisIndex'
p1465
I1
sa(dp1466
g42
g43
sVtrials.maxVal
p1467
I1
sg44
V2
sS'trials.response'
p1468
I0
sVtrials.sf
p1469
I8
sS'trials.thisRepN'
p1470
I22
sg36
g40
sS'trials.thisN'
p1471
I87
sVtrials.stepSizes
p1472
g102
sg41
g12
sS'trials.stepSize'
p1473
I2
sS'trials.stepType'
p1474
g92
sVtrials.label
p1475
g100
sg34
g35
sS'trials.direction'
p1476
g145
sVtrials.minVal
p1477
I0
sS'trials.intensity'
p1478
F0.0050118723362727246
sVtrials.startVal
p1479
F0.001
sS'trials.thisIndex'
p1480
I2
sa(dp1481
g42
g43
sVtrials.maxVal
p1482
I1
sg44
V2
sS'trials.response'
p1483
I1
sVtrials.sf
p1484
I8
sS'trials.thisRepN'
p1485
I23
sg36
g40
sS'trials.thisN'
p1486
I88
sVtrials.stepSizes
p1487
g102
sg41
g12
sS'trials.stepSize'
p1488
I2
sS'trials.stepType'
p1489
g92
sVtrials.label
p1490
g100
sg34
g35
sS'trials.direction'
p1491
g145
sVtrials.minVal
p1492
I0
sS'trials.intensity'
p1493
F0.0063095734448019355
sVtrials.startVal
p1494
F0.001
sS'trials.thisIndex'
p1495
I2
sa(dp1496
g42
g43
sVtrials.maxVal
p1497
I1
sg44
V2
sS'trials.response'
p1498
I1
sVtrials.sf
p1499
I8
sS'trials.thisRepN'
p1500
I23
sg36
g40
sS'trials.thisN'
p1501
I89
sVtrials.stepSizes
p1502
g158
sg41
g12
sS'trials.stepSize'
p1503
I2
sS'trials.stepType'
p1504
g92
sVtrials.label
p1505
g157
sg34
g35
sS'trials.direction'
p1506
g109
sVtrials.minVal
p1507
I0
sS'trials.intensity'
p1508
F0.10000000000000005
sVtrials.startVal
p1509
F0.10000000000000001
sS'trials.thisIndex'
p1510
I3
sa(dp1511
g42
g43
sVtrials.maxVal
p1512
I1
sg44
V2
sS'trials.response'
p1513
I1
sVtrials.sf
p1514
I2
sS'trials.thisRepN'
p1515
I23
sg36
g40
sS'trials.thisN'
p1516
I90
sVtrials.stepSizes
p1517
g143
sg41
g12
sS'trials.stepSize'
p1518
I1
sS'trials.stepType'
p1519
g92
sVtrials.label
p1520
g142
sg34
g35
sS'trials.direction'
p1521
g145
sVtrials.minVal
p1522
I0
sS'trials.intensity'
p1523
F0.014125375446227542
sVtrials.startVal
p1524
F0.10000000000000001
sS'trials.thisIndex'
p1525
I1
sa(dp1526
g42
g43
sVtrials.maxVal
p1527
I1
sg44
V2
sS'trials.response'
p1528
I1
sVtrials.sf
p1529
I2
sS'trials.thisRepN'
p1530
I23
sg36
g40
sS'trials.thisN'
p1531
I91
sVtrials.stepSizes
p1532
g129
sg41
g12
sS'trials.stepSize'
p1533
I1
sS'trials.stepType'
p1534
g92
sVtrials.label
p1535
g128
sg34
g35
sS'trials.direction'
p1536
g145
sVtrials.minVal
p1537
I0
sS'trials.intensity'
p1538
F0.0079432823472428173
sVtrials.startVal
p1539
F0.001
sS'trials.thisIndex'
p1540
I0
sa(dp1541
g42
g43
sVtrials.maxVal
p1542
I1
sg44
V2
sS'trials.response'
p1543
I1
sVtrials.sf
p1544
I8
sS'trials.thisRepN'
p1545
I24
sg36
g40
sS'trials.thisN'
p1546
I92
sVtrials.stepSizes
p1547
g102
sg41
g12
sS'trials.stepSize'
p1548
I2
sS'trials.stepType'
p1549
g92
sVtrials.label
p1550
g100
sg34
g35
sS'trials.direction'
p1551
g145
sVtrials.minVal
p1552
I0
sS'trials.intensity'
p1553
F0.0063095734448019355
sVtrials.startVal
p1554
F0.001
sS'trials.thisIndex'
p1555
I2
sa(dp1556
g42
g43
sVtrials.maxVal
p1557
I1
sg44
V2
sS'trials.response'
p1558
I1
sVtrials.sf
p1559
I2
sS'trials.thisRepN'
p1560
I24
sg36
g40
sS'trials.thisN'
p1561
I93
sVtrials.stepSizes
p1562
g143
sg41
g12
sS'trials.stepSize'
p1563
I1
sS'trials.stepType'
p1564
g92
sVtrials.label
p1565
g142
sg34
g35
sS'trials.direction'
p1566
g145
sVtrials.minVal
p1567
I0
sS'trials.intensity'
p1568
F0.014125375446227542
sVtrials.startVal
p1569
F0.10000000000000001
sS'trials.thisIndex'
p1570
I1
sa(dp1571
g42
g43
sVtrials.maxVal
p1572
I1
sg44
V2
sS'trials.response'
p1573
I1
sVtrials.sf
p1574
I2
sS'trials.thisRepN'
p1575
I24
sg36
g40
sS'trials.thisN'
p1576
I94
sVtrials.stepSizes
p1577
g129
sg41
g12
sS'trials.stepSize'
p1578
I1
sS'trials.stepType'
p1579
g92
sVtrials.label
p1580
g128
sg34
g35
sS'trials.direction'
p1581
g145
sVtrials.minVal
p1582
I0
sS'trials.intensity'
p1583
F0.0079432823472428173
sVtrials.startVal
p1584
F0.001
sS'trials.thisIndex'
p1585
I0
sa(dp1586
g42
g43
sVtrials.maxVal
p1587
I1
sg44
V2
sS'trials.response'
p1588
I0
sVtrials.sf
p1589
I8
sS'trials.thisRepN'
p1590
I24
sg36
g40
sS'trials.thisN'
p1591
I95
sVtrials.stepSizes
p1592
g158
sg41
g12
sS'trials.stepSize'
p1593
I2
sS'trials.stepType'
p1594
g92
sVtrials.label
p1595
g157
sg34
g35
sS'trials.direction'
p1596
g109
sVtrials.minVal
p1597
I0
sS'trials.intensity'
p1598
F0.10000000000000005
sVtrials.startVal
p1599
F0.10000000000000001
sS'trials.thisIndex'
p1600
I3
sa(dp1601
g42
g43
sVtrials.maxVal
p1602
I1
sg44
V2
sS'trials.response'
p1603
I0
sVtrials.sf
p1604
I8
sS'trials.thisRepN'
p1605
I25
sg36
g40
sS'trials.thisN'
p1606
I96
sVtrials.stepSizes
p1607
g102
sg41
g12
sS'trials.stepSize'
p1608
I2
sS'trials.stepType'
p1609
g92
sVtrials.label
p1610
g100
sg34
g35
sS'trials.direction'
p1611
g145
sVtrials.minVal
p1612
I0
sS'trials.intensity'
p1613
F0.0063095734448019355
sVtrials.startVal
p1614
F0.001
sS'trials.thisIndex'
p1615
I2
sa(dp1616
g42
g43
sVtrials.maxVal
p1617
I1
sg44
V2
sS'trials.response'
p1618
I0
sVtrials.sf
p1619
I2
sS'trials.thisRepN'
p1620
I25
sg36
g40
sS'trials.thisN'
p1621
I97
sVtrials.stepSizes
p1622
g129
sg41
g12
sS'trials.stepSize'
p1623
I1
sS'trials.stepType'
p1624
g92
sVtrials.label
p1625
g128
sg34
g35
sS'trials.direction'
p1626
g145
sVtrials.minVal
p1627
I0
sS'trials.intensity'
p1628
F0.0079432823472428173
sVtrials.startVal
p1629
F0.001
sS'trials.thisIndex'
p1630
I0
sa(dp1631
g42
g43
sVtrials.maxVal
p1632
I1
sg44
V2
sS'trials.response'
p1633
I0
sVtrials.sf
p1634
I8
sS'trials.thisRepN'
p1635
I25
sg36
g40
sS'trials.thisN'
p1636
I98
sVtrials.stepSizes
p1637
g158
sg41
g12
sS'trials.stepSize'
p1638
I1
sS'trials.stepType'
p1639
g92
sVtrials.label
p1640
g157
sg34
g35
sS'trials.direction'
p1641
g145
sVtrials.minVal
p1642
I0
sS'trials.intensity'
p1643
F0.11220184543019639
sVtrials.startVal
p1644
F0.10000000000000001
sS'trials.thisIndex'
p1645
I3
sa(dp1646
g42
g43
sVtrials.maxVal
p1647
I1
sg44
V2
sS'trials.response'
p1648
I1
sVtrials.sf
p1649
I2
sS'trials.thisRepN'
p1650
I25
sg36
g40
sS'trials.thisN'
p1651
I99
sVtrials.stepSizes
p1652
g143
sg41
g12
sS'trials.stepSize'
p1653
I1
sS'trials.stepType'
p1654
g92
sVtrials.label
p1655
g142
sg34
g35
sS'trials.direction'
p1656
g145
sVtrials.minVal
p1657
I0
sS'trials.intensity'
p1658
F0.014125375446227542
sVtrials.startVal
p1659
F0.10000000000000001
sS'trials.thisIndex'
p1660
I1
sa(dp1661
g42
g43
sVtrials.maxVal
p1662
I1
sg44
V2
sS'trials.response'
p1663
I0
sVtrials.sf
p1664
I8
sS'trials.thisRepN'
p1665
I26
sg36
g40
sS'trials.thisN'
p1666
I100
sVtrials.stepSizes
p1667
g102
sg41
g12
sS'trials.stepSize'
p1668
I2
sS'trials.stepType'
p1669
g92
sVtrials.label
p1670
g100
sg34
g35
sS'trials.direction'
p1671
g145
sVtrials.minVal
p1672
I0
sS'trials.intensity'
p1673
F0.007943282347242819
sVtrials.startVal
p1674
F0.001
sS'trials.thisIndex'
p1675
I2
sa(dp1676
g42
g43
sVtrials.maxVal
p1677
I1
sg44
V2
sS'trials.response'
p1678
I1
sVtrials.sf
p1679
I8
sS'trials.thisRepN'
p1680
I26
sg36
g40
sS'trials.thisN'
p1681
I101
sVtrials.stepSizes
p1682
g158
sg41
g12
sS'trials.stepSize'
p1683
I1
sS'trials.stepType'
p1684
g92
sVtrials.label
p1685
g157
sg34
g35
sS'trials.direction'
p1686
g145
sVtrials.minVal
p1687
I0
sS'trials.intensity'
p1688
F0.12589254117941676
sVtrials.startVal
p1689
F0.10000000000000001
sS'trials.thisIndex'
p1690
I3
sa(dp1691
g42
g43
sVtrials.maxVal
p1692
I1
sg44
V2
sS'trials.response'
p1693
I1
sVtrials.sf
p1694
I2
sS'trials.thisRepN'
p1695
I26
sg36
g40
sS'trials.thisN'
p1696
I102
sVtrials.stepSizes
p1697
g143
sg41
g12
sS'trials.stepSize'
p1698
I1
sS'trials.stepType'
p1699
g92
sVtrials.label
p1700
g142
sg34
g35
sS'trials.direction'
p1701
g109
sVtrials.minVal
p1702
I0
sS'trials.intensity'
p1703
F0.012589254117941671
sVtrials.startVal
p1704
F0.10000000000000001
sS'trials.thisIndex'
p1705
I1
sa(dp1706
g42
g43
sVtrials.maxVal
p1707
I1
sg44
V2
sS'trials.response'
p1708
I0
sVtrials.sf
p1709
I2
sS'trials.thisRepN'
p1710
I26
sg36
g40
sS'trials.thisN'
p1711
I103
sVtrials.stepSizes
p1712
g129
sg41
g12
sS'trials.stepSize'
p1713
I1
sS'trials.stepType'
p1714
g92
sVtrials.label
p1715
g128
sg34
g35
sS'trials.direction'
p1716
g145
sVtrials.minVal
p1717
I0
sS'trials.intensity'
p1718
F0.0089125093813374572
sVtrials.startVal
p1719
F0.001
sS'trials.thisIndex'
p1720
I0
sa(dp1721
g42
g43
sVtrials.maxVal
p1722
I1
sg44
V2
sS'trials.response'
p1723
I1
sVtrials.sf
p1724
I2
sS'trials.thisRepN'
p1725
I27
sg36
g40
sS'trials.thisN'
p1726
I104
sVtrials.stepSizes
p1727
g129
sg41
g12
sS'trials.stepSize'
p1728
I1
sS'trials.stepType'
p1729
g92
sVtrials.label
p1730
g128
sg34
g35
sS'trials.direction'
p1731
g145
sVtrials.minVal
p1732
I0
sS'trials.intensity'
p1733
F0.010000000000000002
sVtrials.startVal
p1734
F0.001
sS'trials.thisIndex'
p1735
I0
sa(dp1736
g42
g43
sVtrials.maxVal
p1737
I1
sg44
V2
sS'trials.response'
p1738
I0
sVtrials.sf
p1739
I8
sS'trials.thisRepN'
p1740
I27
sg36
g40
sS'trials.thisN'
p1741
I105
sVtrials.stepSizes
p1742
g102
sg41
g12
sS'trials.stepSize'
p1743
I2
sS'trials.stepType'
p1744
g92
sVtrials.label
p1745
g100
sg34
g35
sS'trials.direction'
p1746
g145
sVtrials.minVal
p1747
I0
sS'trials.intensity'
p1748
F0.010000000000000005
sVtrials.startVal
p1749
F0.001
sS'trials.thisIndex'
p1750
I2
sa(dp1751
g42
g43
sVtrials.maxVal
p1752
I1
sg44
V2
sS'trials.response'
p1753
I1
sVtrials.sf
p1754
I8
sS'trials.thisRepN'
p1755
I27
sg36
g40
sS'trials.thisN'
p1756
I106
sVtrials.stepSizes
p1757
g158
sg41
g12
sS'trials.stepSize'
p1758
I1
sS'trials.stepType'
p1759
g92
sVtrials.label
p1760
g157
sg34
g35
sS'trials.direction'
p1761
g145
sVtrials.minVal
p1762
I0
sS'trials.intensity'
p1763
F0.12589254117941676
sVtrials.startVal
p1764
F0.10000000000000001
sS'trials.thisIndex'
p1765
I3
sa(dp1766
g42
g43
sVtrials.maxVal
p1767
I1
sg44
V2
sS'trials.response'
p1768
I1
sVtrials.sf
p1769
I2
sS'trials.thisRepN'
p1770
I27
sg36
g40
sS'trials.thisN'
p1771
I107
sVtrials.stepSizes
p1772
g143
sg41
g12
sS'trials.stepSize'
p1773
I1
sS'trials.stepType'
p1774
g92
sVtrials.label
p1775
g142
sg34
g35
sS'trials.direction'
p1776
g109
sVtrials.minVal
p1777
I0
sS'trials.intensity'
p1778
F0.012589254117941671
sVtrials.startVal
p1779
F0.10000000000000001
sS'trials.thisIndex'
p1780
I1
sa(dp1781
g42
g43
sVtrials.maxVal
p1782
I1
sg44
V2
sS'trials.response'
p1783
I1
sVtrials.sf
p1784
I8
sS'trials.thisRepN'
p1785
I28
sg36
g40
sS'trials.thisN'
p1786
I108
sVtrials.stepSizes
p1787
g102
sg41
g12
sS'trials.stepSize'
p1788
I2
sS'trials.stepType'
p1789
g92
sVtrials.label
p1790
g100
sg34
g35
sS'trials.direction'
p1791
g145
sVtrials.minVal
p1792
I0
sS'trials.intensity'
p1793
F0.01258925411794168
sVtrials.startVal
p1794
F0.001
sS'trials.thisIndex'
p1795
I2
sa(dp1796
g42
g43
sVtrials.maxVal
p1797
I1
sg44
V2
sS'trials.response'
p1798
I0
sVtrials.sf
p1799
I2
sS'trials.thisRepN'
p1800
I28
sg36
g40
sS'trials.thisN'
p1801
I109
sVtrials.stepSizes
p1802
g143
sg41
g12
sS'trials.stepSize'
p1803
I1
sS'trials.stepType'
p1804
g92
sVtrials.label
p1805
g142
sg34
g35
sS'trials.direction'
p1806
g109
sVtrials.minVal
p1807
I0
sS'trials.intensity'
p1808
F0.012589254117941671
sVtrials.startVal
p1809
F0.10000000000000001
sS'trials.thisIndex'
p1810
I1
sa(dp1811
g42
g43
sVtrials.maxVal
p1812
I1
sg44
V2
sS'trials.response'
p1813
I1
sVtrials.sf
p1814
I8
sS'trials.thisRepN'
p1815
I28
sg36
g40
sS'trials.thisN'
p1816
I110
sVtrials.stepSizes
p1817
g158
sg41
g12
sS'trials.stepSize'
p1818
I1
sS'trials.stepType'
p1819
g92
sVtrials.label
p1820
g157
sg34
g35
sS'trials.direction'
p1821
g145
sVtrials.minVal
p1822
I0
sS'trials.intensity'
p1823
F0.12589254117941676
sVtrials.startVal
p1824
F0.10000000000000001
sS'trials.thisIndex'
p1825
I3
sa(dp1826
g42
g43
sVtrials.maxVal
p1827
I1
sg44
V2
sS'trials.response'
p1828
I0
sVtrials.sf
p1829
I2
sS'trials.thisRepN'
p1830
I28
sg36
g40
sS'trials.thisN'
p1831
I111
sVtrials.stepSizes
p1832
g129
sg41
g12
sS'trials.stepSize'
p1833
I1
sS'trials.stepType'
p1834
g92
sVtrials.label
p1835
g128
sg34
g35
sS'trials.direction'
p1836
g145
sVtrials.minVal
p1837
I0
sS'trials.intensity'
p1838
F0.010000000000000002
sVtrials.startVal
p1839
F0.001
sS'trials.thisIndex'
p1840
I0
sa(dp1841
g42
g43
sVtrials.maxVal
p1842
I1
sg44
V2
sS'trials.response'
p1843
I1
sVtrials.sf
p1844
I2
sS'trials.thisRepN'
p1845
I29
sg36
g40
sS'trials.thisN'
p1846
I112
sVtrials.stepSizes
p1847
g143
sg41
g12
sS'trials.stepSize'
p1848
I1
sS'trials.stepType'
p1849
g92
sVtrials.label
p1850
g142
sg34
g35
sS'trials.direction'
p1851
g145
sVtrials.minVal
p1852
I0
sS'trials.intensity'
p1853
F0.014125375446227542
sVtrials.startVal
p1854
F0.10000000000000001
sS'trials.thisIndex'
p1855
I1
sa(dp1856
g42
g43
sVtrials.maxVal
p1857
I1
sg44
V2
sS'trials.response'
p1858
I1
sVtrials.sf
p1859
I8
sS'trials.thisRepN'
p1860
I29
sg36
g40
sS'trials.thisN'
p1861
I113
sVtrials.stepSizes
p1862
g102
sg41
g12
sS'trials.stepSize'
p1863
I2
sS'trials.stepType'
p1864
g92
sVtrials.label
p1865
g100
sg34
g35
sS'trials.direction'
p1866
g145
sVtrials.minVal
p1867
I0
sS'trials.intensity'
p1868
F0.01258925411794168
sVtrials.startVal
p1869
F0.001
sS'trials.thisIndex'
p1870
I2
sa(dp1871
g42
g43
sVtrials.maxVal
p1872
I1
sg44
V2
sS'trials.response'
p1873
I0
sVtrials.sf
p1874
I8
sS'trials.thisRepN'
p1875
I29
sg36
g40
sS'trials.thisN'
p1876
I114
sVtrials.stepSizes
p1877
g158
sg41
g12
sS'trials.stepSize'
p1878
I1
sS'trials.stepType'
p1879
g92
sVtrials.label
p1880
g157
sg34
g35
sS'trials.direction'
p1881
g109
sVtrials.minVal
p1882
I0
sS'trials.intensity'
p1883
F0.11220184543019639
sVtrials.startVal
p1884
F0.10000000000000001
sS'trials.thisIndex'
p1885
I3
sa(dp1886
g42
g43
sVtrials.maxVal
p1887
I1
sg44
V2
sS'trials.response'
p1888
I1
sVtrials.sf
p1889
I2
sS'trials.thisRepN'
p1890
I29
sg36
g40
sS'trials.thisN'
p1891
I115
sVtrials.stepSizes
p1892
g129
sg41
g12
sS'trials.stepSize'
p1893
I1
sS'trials.stepType'
p1894
g92
sVtrials.label
p1895
g128
sg34
g35
sS'trials.direction'
p1896
g145
sVtrials.minVal
p1897
I0
sS'trials.intensity'
p1898
F0.011220184543019636
sVtrials.startVal
p1899
F0.001
sS'trials.thisIndex'
p1900
I0
sa(dp1901
g42
g43
sVtrials.maxVal
p1902
I1
sg44
V2
sS'trials.response'
p1903
I1
sVtrials.sf
p1904
I8
sS'trials.thisRepN'
p1905
I30
sg36
g40
sS'trials.thisN'
p1906
I116
sVtrials.stepSizes
p1907
g158
sg41
g12
sS'trials.stepSize'
p1908
I1
sS'trials.stepType'
p1909
g92
sVtrials.label
p1910
g157
sg34
g35
sS'trials.direction'
p1911
g145
sVtrials.minVal
p1912
I0
sS'trials.intensity'
p1913
F0.12589254117941676
sVtrials.startVal
p1914
F0.10000000000000001
sS'trials.thisIndex'
p1915
I3
sa(dp1916
g42
g43
sVtrials.maxVal
p1917
I1
sg44
V2
sS'trials.response'
p1918
I1
sVtrials.sf
p1919
I2
sS'trials.thisRepN'
p1920
I30
sg36
g40
sS'trials.thisN'
p1921
I117
sVtrials.stepSizes
p1922
g129
sg41
g12
sS'trials.stepSize'
p1923
I1
sS'trials.stepType'
p1924
g92
sVtrials.label
p1925
g128
sg34
g35
sS'trials.direction'
p1926
g145
sVtrials.minVal
p1927
I0
sS'trials.intensity'
p1928
F0.011220184543019636
sVtrials.startVal
p1929
F0.001
sS'trials.thisIndex'
p1930
I0
sa(dp1931
g42
g43
sVtrials.maxVal
p1932
I1
sg44
V2
sS'trials.response'
p1933
I1
sVtrials.sf
p1934
I8
sS'trials.thisRepN'
p1935
I30
sg36
g40
sS'trials.thisN'
p1936
I118
sVtrials.stepSizes
p1937
g102
sg41
g12
sS'trials.stepSize'
p1938
I2
sS'trials.stepType'
p1939
g92
sVtrials.label
p1940
g100
sg34
g35
sS'trials.direction'
p1941
g145
sVtrials.minVal
p1942
I0
sS'trials.intensity'
p1943
F0.01258925411794168
sVtrials.startVal
p1944
F0.001
sS'trials.thisIndex'
p1945
I2
sa(dp1946
g42
g43
sVtrials.maxVal
p1947
I1
sg44
V2
sS'trials.response'
p1948
I1
sVtrials.sf
p1949
I2
sS'trials.thisRepN'
p1950
I30
sg36
g40
sS'trials.thisN'
p1951
I119
sVtrials.stepSizes
p1952
g143
sg41
g12
sS'trials.stepSize'
p1953
I1
sS'trials.stepType'
p1954
g92
sVtrials.label
p1955
g142
sg34
g35
sS'trials.direction'
p1956
g145
sVtrials.minVal
p1957
I0
sS'trials.intensity'
p1958
F0.014125375446227542
sVtrials.startVal
p1959
F0.10000000000000001
sS'trials.thisIndex'
p1960
I1
sa(dp1961
g42
g43
sVtrials.maxVal
p1962
I1
sg44
V2
sS'trials.response'
p1963
I1
sVtrials.sf
p1964
I2
sS'trials.thisRepN'
p1965
I31
sg36
g40
sS'trials.thisN'
p1966
I120
sVtrials.stepSizes
p1967
g143
sg41
g12
sS'trials.stepSize'
p1968
I1
sS'trials.stepType'
p1969
g92
sVtrials.label
p1970
g142
sg34
g35
sS'trials.direction'
p1971
g145
sVtrials.minVal
p1972
I0
sS'trials.intensity'
p1973
F0.014125375446227542
sVtrials.startVal
p1974
F0.10000000000000001
sS'trials.thisIndex'
p1975
I1
sa(dp1976
g42
g43
sVtrials.maxVal
p1977
I1
sg44
V2
sS'trials.response'
p1978
I1
sVtrials.sf
p1979
I8
sS'trials.thisRepN'
p1980
I31
sg36
g40
sS'trials.thisN'
p1981
I121
sVtrials.stepSizes
p1982
g102
sg41
g12
sS'trials.stepSize'
p1983
I2
sS'trials.stepType'
p1984
g92
sVtrials.label
p1985
g100
sg34
g35
sS'trials.direction'
p1986
g109
sVtrials.minVal
p1987
I0
sS'trials.intensity'
p1988
F0.010000000000000005
sVtrials.startVal
p1989
F0.001
sS'trials.thisIndex'
p1990
I2
sa(dp1991
g42
g43
sVtrials.maxVal
p1992
I1
sg44
V2
sS'trials.response'
p1993
I1
sVtrials.sf
p1994
I8
sS'trials.thisRepN'
p1995
I31
sg36
g40
sS'trials.thisN'
p1996
I122
sVtrials.stepSizes
p1997
g158
sg41
g12
sS'trials.stepSize'
p1998
I1
sS'trials.stepType'
p1999
g92
sVtrials.label
p2000
g157
sg34
g35
sS'trials.direction'
p2001
g145
sVtrials.minVal
p2002
I0
sS'trials.intensity'
p2003
F0.12589254117941676
sVtrials.startVal
p2004
F0.10000000000000001
sS'trials.thisIndex'
p2005
I3
sa(dp2006
g42
g43
sVtrials.maxVal
p2007
I1
sg44
V2
sS'trials.response'
p2008
I0
sVtrials.sf
p2009
I2
sS'trials.thisRepN'
p2010
I31
sg36
g40
sS'trials.thisN'
p2011
I123
sVtrials.stepSizes
p2012
g129
sg41
g12
sS'trials.stepSize'
p2013
I1
sS'trials.stepType'
p2014
g92
sVtrials.label
p2015
g128
sg34
g35
sS'trials.direction'
p2016
g145
sVtrials.minVal
p2017
I0
sS'trials.intensity'
p2018
F0.011220184543019636
sVtrials.startVal
p2019
F0.001
sS'trials.thisIndex'
p2020
I0
sa(dp2021
g42
g43
sVtrials.maxVal
p2022
I1
sg44
V2
sS'trials.response'
p2023
I1
sVtrials.sf
p2024
I8
sS'trials.thisRepN'
p2025
I32
sg36
g40
sS'trials.thisN'
p2026
I124
sVtrials.stepSizes
p2027
g158
sg41
g12
sS'trials.stepSize'
p2028
I1
sS'trials.stepType'
p2029
g92
sVtrials.label
p2030
g157
sg34
g35
sS'trials.direction'
p2031
g145
sVtrials.minVal
p2032
I0
sS'trials.intensity'
p2033
F0.12589254117941676
sVtrials.startVal
p2034
F0.10000000000000001
sS'trials.thisIndex'
p2035
I3
sa(dp2036
g42
g43
sVtrials.maxVal
p2037
I1
sg44
V2
sS'trials.response'
p2038
I1
sVtrials.sf
p2039
I8
sS'trials.thisRepN'
p2040
I32
sg36
g40
sS'trials.thisN'
p2041
I125
sVtrials.stepSizes
p2042
g102
sg41
g12
sS'trials.stepSize'
p2043
I2
sS'trials.stepType'
p2044
g92
sVtrials.label
p2045
g100
sg34
g35
sS'trials.direction'
p2046
g109
sVtrials.minVal
p2047
I0
sS'trials.intensity'
p2048
F0.010000000000000005
sVtrials.startVal
p2049
F0.001
sS'trials.thisIndex'
p2050
I2
sa(dp2051
g42
g43
sVtrials.maxVal
p2052
I1
sg44
V2
sS'trials.response'
p2053
I0
sVtrials.sf
p2054
I2
sS'trials.thisRepN'
p2055
I32
sg36
g40
sS'trials.thisN'
p2056
I126
sVtrials.stepSizes
p2057
g143
sg41
g12
sS'trials.stepSize'
p2058
I1
sS'trials.stepType'
p2059
g92
sVtrials.label
p2060
g142
sg34
g35
sS'trials.direction'
p2061
g109
sVtrials.minVal
p2062
I0
sS'trials.intensity'
p2063
F0.012589254117941671
sVtrials.startVal
p2064
F0.10000000000000001
sS'trials.thisIndex'
p2065
I1
sa(dp2066
g42
g43
sVtrials.maxVal
p2067
I1
sg44
V2
sS'trials.response'
p2068
I0
sVtrials.sf
p2069
I2
sS'trials.thisRepN'
p2070
I32
sg36
g40
sS'trials.thisN'
p2071
I127
sVtrials.stepSizes
p2072
g129
sg41
g12
sS'trials.stepSize'
p2073
I1
sS'trials.stepType'
p2074
g92
sVtrials.label
p2075
g128
sg34
g35
sS'trials.direction'
p2076
g145
sVtrials.minVal
p2077
I0
sS'trials.intensity'
p2078
F0.012589254117941673
sVtrials.startVal
p2079
F0.001
sS'trials.thisIndex'
p2080
I0
sa(dp2081
g42
g43
sVtrials.maxVal
p2082
I1
sg44
V2
sS'trials.response'
p2083
I1
sVtrials.sf
p2084
I8
sS'trials.thisRepN'
p2085
I33
sg36
g40
sS'trials.thisN'
p2086
I128
sVtrials.stepSizes
p2087
g158
sg41
g12
sS'trials.stepSize'
p2088
I1
sS'trials.stepType'
p2089
g92
sVtrials.label
p2090
g157
sg34
g35
sS'trials.direction'
p2091
g109
sVtrials.minVal
p2092
I0
sS'trials.intensity'
p2093
F0.11220184543019639
sVtrials.startVal
p2094
F0.10000000000000001
sS'trials.thisIndex'
p2095
I3
sa(dp2096
g42
g43
sVtrials.maxVal
p2097
I1
sg44
V2
sS'trials.response'
p2098
I0
sVtrials.sf
p2099
I8
sS'trials.thisRepN'
p2100
I33
sg36
g40
sS'trials.thisN'
p2101
I129
sVtrials.stepSizes
p2102
g102
sg41
g12
sS'trials.stepSize'
p2103
I2
sS'trials.stepType'
p2104
g92
sVtrials.label
p2105
g100
sg34
g35
sS'trials.direction'
p2106
g109
sVtrials.minVal
p2107
I0
sS'trials.intensity'
p2108
F0.010000000000000005
sVtrials.startVal
p2109
F0.001
sS'trials.thisIndex'
p2110
I2
sa(dp2111
g42
g43
sVtrials.maxVal
p2112
I1
sg44
V2
sS'trials.response'
p2113
I1
sVtrials.sf
p2114
I2
sS'trials.thisRepN'
p2115
I33
sg36
g40
sS'trials.thisN'
p2116
I130
sVtrials.stepSizes
p2117
g129
sg41
g12
sS'trials.stepSize'
p2118
I1
sS'trials.stepType'
p2119
g92
sVtrials.label
p2120
g128
sg34
g35
sS'trials.direction'
p2121
g145
sVtrials.minVal
p2122
I0
sS'trials.intensity'
p2123
F0.014125375446227544
sVtrials.startVal
p2124
F0.001
sS'trials.thisIndex'
p2125
I0
sa(dp2126
g42
g43
sVtrials.maxVal
p2127
I1
sg44
V2
sS'trials.response'
p2128
I1
sVtrials.sf
p2129
I2
sS'trials.thisRepN'
p2130
I33
sg36
g40
sS'trials.thisN'
p2131
I131
sVtrials.stepSizes
p2132
g143
sg41
g12
sS'trials.stepSize'
p2133
I1
sS'trials.stepType'
p2134
g92
sVtrials.label
p2135
g142
sg34
g35
sS'trials.direction'
p2136
g145
sVtrials.minVal
p2137
I0
sS'trials.intensity'
p2138
F0.014125375446227542
sVtrials.startVal
p2139
F0.10000000000000001
sS'trials.thisIndex'
p2140
I1
sa(dp2141
g42
g43
sVtrials.maxVal
p2142
I1
sg44
V2
sS'trials.response'
p2143
I1
sVtrials.sf
p2144
I2
sS'trials.thisRepN'
p2145
I34
sg36
g40
sS'trials.thisN'
p2146
I132
sVtrials.stepSizes
p2147
g129
sg41
g12
sS'trials.stepSize'
p2148
I1
sS'trials.stepType'
p2149
g92
sVtrials.label
p2150
g128
sg34
g35
sS'trials.direction'
p2151
g145
sVtrials.minVal
p2152
I0
sS'trials.intensity'
p2153
F0.014125375446227544
sVtrials.startVal
p2154
F0.001
sS'trials.thisIndex'
p2155
I0
sa(dp2156
g42
g43
sVtrials.maxVal
p2157
I1
sg44
V2
sS'trials.response'
p2158
I1
sVtrials.sf
p2159
I8
sS'trials.thisRepN'
p2160
I34
sg36
g40
sS'trials.thisN'
p2161
I133
sVtrials.stepSizes
p2162
g158
sg41
g12
sS'trials.stepSize'
p2163
I1
sS'trials.stepType'
p2164
g92
sVtrials.label
p2165
g157
sg34
g35
sS'trials.direction'
p2166
g109
sVtrials.minVal
p2167
I0
sS'trials.intensity'
p2168
F0.11220184543019639
sVtrials.startVal
p2169
F0.10000000000000001
sS'trials.thisIndex'
p2170
I3
sa(dp2171
g42
g43
sVtrials.maxVal
p2172
I1
sg44
V2
sS'trials.response'
p2173
I1
sVtrials.sf
p2174
I2
sS'trials.thisRepN'
p2175
I34
sg36
g40
sS'trials.thisN'
p2176
I134
sVtrials.stepSizes
p2177
g143
sg41
g12
sS'trials.stepSize'
p2178
I1
sS'trials.stepType'
p2179
g92
sVtrials.label
p2180
g142
sg34
g35
sS'trials.direction'
p2181
g145
sVtrials.minVal
p2182
I0
sS'trials.intensity'
p2183
F0.014125375446227542
sVtrials.startVal
p2184
F0.10000000000000001
sS'trials.thisIndex'
p2185
I1
sa(dp2186
g42
g43
sVtrials.maxVal
p2187
I1
sg44
V2
sS'trials.response'
p2188
I0
sVtrials.sf
p2189
I8
sS'trials.thisRepN'
p2190
I34
sg36
g40
sS'trials.thisN'
p2191
I135
sVtrials.stepSizes
p2192
g102
sg41
g12
sS'trials.stepSize'
p2193
I1
sS'trials.stepType'
p2194
g92
sVtrials.label
p2195
g100
sg34
g35
sS'trials.direction'
p2196
g145
sVtrials.minVal
p2197
I0
sS'trials.intensity'
p2198
F0.011220184543019639
sVtrials.startVal
p2199
F0.001
sS'trials.thisIndex'
p2200
I2
sa(dp2201
g42
g43
sVtrials.maxVal
p2202
I1
sg44
V2
sS'trials.response'
p2203
I1
sVtrials.sf
p2204
I8
sS'trials.thisRepN'
p2205
I35
sg36
g40
sS'trials.thisN'
p2206
I136
sVtrials.stepSizes
p2207
g158
sg41
g12
sS'trials.stepSize'
p2208
I1
sS'trials.stepType'
p2209
g92
sVtrials.label
p2210
g157
sg34
g35
sS'trials.direction'
p2211
g109
sVtrials.minVal
p2212
I0
sS'trials.intensity'
p2213
F0.11220184543019639
sVtrials.startVal
p2214
F0.10000000000000001
sS'trials.thisIndex'
p2215
I3
sa(dp2216
g42
g43
sVtrials.maxVal
p2217
I1
sg44
V2
sS'trials.response'
p2218
I0
sVtrials.sf
p2219
I2
sS'trials.thisRepN'
p2220
I35
sg36
g40
sS'trials.thisN'
p2221
I137
sVtrials.stepSizes
p2222
g143
sg41
g12
sS'trials.stepSize'
p2223
I1
sS'trials.stepType'
p2224
g92
sVtrials.label
p2225
g142
sg34
g35
sS'trials.direction'
p2226
g145
sVtrials.minVal
p2227
I0
sS'trials.intensity'
p2228
F0.014125375446227542
sVtrials.startVal
p2229
F0.10000000000000001
sS'trials.thisIndex'
p2230
I1
sa(dp2231
g42
g43
sVtrials.maxVal
p2232
I1
sg44
V2
sS'trials.response'
p2233
I1
sVtrials.sf
p2234
I8
sS'trials.thisRepN'
p2235
I35
sg36
g40
sS'trials.thisN'
p2236
I138
sVtrials.stepSizes
p2237
g102
sg41
g12
sS'trials.stepSize'
p2238
I1
sS'trials.stepType'
p2239
g92
sVtrials.label
p2240
g100
sg34
g35
sS'trials.direction'
p2241
g145
sVtrials.minVal
p2242
I0
sS'trials.intensity'
p2243
F0.012589254117941677
sVtrials.startVal
p2244
F0.001
sS'trials.thisIndex'
p2245
I2
sa(dp2246
g42
g43
sVtrials.maxVal
p2247
I1
sg44
V2
sS'trials.response'
p2248
I0
sVtrials.sf
p2249
I2
sS'trials.thisRepN'
p2250
I35
sg36
g40
sS'trials.thisN'
p2251
I139
sVtrials.stepSizes
p2252
g129
sg41
g12
sS'trials.stepSize'
p2253
I1
sS'trials.stepType'
p2254
g92
sVtrials.label
p2255
g128
sg34
g35
sS'trials.direction'
p2256
g145
sVtrials.minVal
p2257
I0
sS'trials.intensity'
p2258
F0.014125375446227544
sVtrials.startVal
p2259
F0.001
sS'trials.thisIndex'
p2260
I0
sa(dp2261
g42
g43
sVtrials.maxVal
p2262
I1
sg44
V2
sS'trials.response'
p2263
I1
sVtrials.sf
p2264
I2
sS'trials.thisRepN'
p2265
I36
sg36
g40
sS'trials.thisN'
p2266
I140
sVtrials.stepSizes
p2267
g143
sg41
g12
sS'trials.stepSize'
p2268
I1
sS'trials.stepType'
p2269
g92
sVtrials.label
p2270
g142
sg34
g35
sS'trials.direction'
p2271
g145
sVtrials.minVal
p2272
I0
sS'trials.intensity'
p2273
F0.015848931924611131
sVtrials.startVal
p2274
F0.10000000000000001
sS'trials.thisIndex'
p2275
I1
sa(dp2276
g42
g43
sVtrials.maxVal
p2277
I1
sg44
V2
sS'trials.response'
p2278
I0
sVtrials.sf
p2279
I2
sS'trials.thisRepN'
p2280
I36
sg36
g40
sS'trials.thisN'
p2281
I141
sVtrials.stepSizes
p2282
g129
sg41
g12
sS'trials.stepSize'
p2283
I1
sS'trials.stepType'
p2284
g92
sVtrials.label
p2285
g128
sg34
g35
sS'trials.direction'
p2286
g145
sVtrials.minVal
p2287
I0
sS'trials.intensity'
p2288
F0.015848931924611134
sVtrials.startVal
p2289
F0.001
sS'trials.thisIndex'
p2290
I0
sa(dp2291
g42
g43
sVtrials.maxVal
p2292
I1
sg44
V2
sS'trials.response'
p2293
I0
sVtrials.sf
p2294
I8
sS'trials.thisRepN'
p2295
I36
sg36
g40
sS'trials.thisN'
p2296
I142
sVtrials.stepSizes
p2297
g158
sg41
g12
sS'trials.stepSize'
p2298
I1
sS'trials.stepType'
p2299
g92
sVtrials.label
p2300
g157
sg34
g35
sS'trials.direction'
p2301
g109
sVtrials.minVal
p2302
I0
sS'trials.intensity'
p2303
F0.10000000000000005
sVtrials.startVal
p2304
F0.10000000000000001
sS'trials.thisIndex'
p2305
I3
sa(dp2306
g42
g43
sVtrials.maxVal
p2307
I1
sg44
V2
sS'trials.response'
p2308
I0
sVtrials.sf
p2309
I8
sS'trials.thisRepN'
p2310
I36
sg36
g40
sS'trials.thisN'
p2311
I143
sVtrials.stepSizes
p2312
g102
sg41
g12
sS'trials.stepSize'
p2313
I1
sS'trials.stepType'
p2314
g92
sVtrials.label
p2315
g100
sg34
g35
sS'trials.direction'
p2316
g145
sVtrials.minVal
p2317
I0
sS'trials.intensity'
p2318
F0.012589254117941677
sVtrials.startVal
p2319
F0.001
sS'trials.thisIndex'
p2320
I2
sa(dp2321
g42
g43
sVtrials.maxVal
p2322
I1
sg44
V2
sS'trials.response'
p2323
I1
sVtrials.sf
p2324
I8
sS'trials.thisRepN'
p2325
I37
sg36
g40
sS'trials.thisN'
p2326
I144
sVtrials.stepSizes
p2327
g158
sg41
g12
sS'trials.stepSize'
p2328
I1
sS'trials.stepType'
p2329
g92
sVtrials.label
p2330
g157
sg34
g35
sS'trials.direction'
p2331
g145
sVtrials.minVal
p2332
I0
sS'trials.intensity'
p2333
F0.11220184543019639
sVtrials.startVal
p2334
F0.10000000000000001
sS'trials.thisIndex'
p2335
I3
sa(dp2336
g42
g43
sVtrials.maxVal
p2337
I1
sg44
V2
sS'trials.response'
p2338
I1
sVtrials.sf
p2339
I2
sS'trials.thisRepN'
p2340
I37
sg36
g40
sS'trials.thisN'
p2341
I145
sVtrials.stepSizes
p2342
g143
sg41
g12
sS'trials.stepSize'
p2343
I1
sS'trials.stepType'
p2344
g92
sVtrials.label
p2345
g142
sg34
g35
sS'trials.direction'
p2346
g145
sVtrials.minVal
p2347
I0
sS'trials.intensity'
p2348
F0.015848931924611131
sVtrials.startVal
p2349
F0.10000000000000001
sS'trials.thisIndex'
p2350
I1
sa(dp2351
g42
g43
sVtrials.maxVal
p2352
I1
sg44
V2
sS'trials.response'
p2353
I1
sVtrials.sf
p2354
I2
sS'trials.thisRepN'
p2355
I37
sg36
g40
sS'trials.thisN'
p2356
I146
sVtrials.stepSizes
p2357
g129
sg41
g12
sS'trials.stepSize'
p2358
I1
sS'trials.stepType'
p2359
g92
sVtrials.label
p2360
g128
sg34
g35
sS'trials.direction'
p2361
g145
sVtrials.minVal
p2362
I0
sS'trials.intensity'
p2363
F0.017782794100389226
sVtrials.startVal
p2364
F0.001
sS'trials.thisIndex'
p2365
I0
sa(dp2366
g42
g43
sVtrials.maxVal
p2367
I1
sg44
V2
sS'trials.response'
p2368
I1
sVtrials.sf
p2369
I8
sS'trials.thisRepN'
p2370
I37
sg36
g40
sS'trials.thisN'
p2371
I147
sVtrials.stepSizes
p2372
g102
sg41
g12
sS'trials.stepSize'
p2373
I1
sS'trials.stepType'
p2374
g92
sVtrials.label
p2375
g100
sg34
g35
sS'trials.direction'
p2376
g145
sVtrials.minVal
p2377
I0
sS'trials.intensity'
p2378
F0.014125375446227547
sVtrials.startVal
p2379
F0.001
sS'trials.thisIndex'
p2380
I2
sa(dp2381
g42
g43
sVtrials.maxVal
p2382
I1
sg44
V2
sS'trials.response'
p2383
I1
sVtrials.sf
p2384
I2
sS'trials.thisRepN'
p2385
I38
sg36
g40
sS'trials.thisN'
p2386
I148
sVtrials.stepSizes
p2387
g129
sg41
g12
sS'trials.stepSize'
p2388
I1
sS'trials.stepType'
p2389
g92
sVtrials.label
p2390
g128
sg34
g35
sS'trials.direction'
p2391
g145
sVtrials.minVal
p2392
I0
sS'trials.intensity'
p2393
F0.017782794100389226
sVtrials.startVal
p2394
F0.001
sS'trials.thisIndex'
p2395
I0
sa(dp2396
g42
g43
sVtrials.maxVal
p2397
I1
sg44
V2
sS'trials.response'
p2398
I1
sVtrials.sf
p2399
I8
sS'trials.thisRepN'
p2400
I38
sg36
g40
sS'trials.thisN'
p2401
I149
sVtrials.stepSizes
p2402
g158
sg41
g12
sS'trials.stepSize'
p2403
I1
sS'trials.stepType'
p2404
g92
sVtrials.label
p2405
g157
sg34
g35
sS'trials.direction'
p2406
g145
sVtrials.minVal
p2407
I0
sS'trials.intensity'
p2408
F0.11220184543019639
sVtrials.startVal
p2409
F0.10000000000000001
sS'trials.thisIndex'
p2410
I3
sa(dp2411
g42
g43
sVtrials.maxVal
p2412
I1
sg44
V2
sS'trials.response'
p2413
I1
sVtrials.sf
p2414
I2
sS'trials.thisRepN'
p2415
I38
sg36
g40
sS'trials.thisN'
p2416
I150
sVtrials.stepSizes
p2417
g143
sg41
g12
sS'trials.stepSize'
p2418
I1
sS'trials.stepType'
p2419
g92
sVtrials.label
p2420
g142
sg34
g35
sS'trials.direction'
p2421
g145
sVtrials.minVal
p2422
I0
sS'trials.intensity'
p2423
F0.015848931924611131
sVtrials.startVal
p2424
F0.10000000000000001
sS'trials.thisIndex'
p2425
I1
sa(dp2426
g42
g43
sVtrials.maxVal
p2427
I1
sg44
V2
sS'trials.response'
p2428
I0
sVtrials.sf
p2429
I8
sS'trials.thisRepN'
p2430
I38
sg36
g40
sS'trials.thisN'
p2431
I151
sVtrials.stepSizes
p2432
g102
sg41
g12
sS'trials.stepSize'
p2433
I1
sS'trials.stepType'
p2434
g92
sVtrials.label
p2435
g100
sg34
g35
sS'trials.direction'
p2436
g145
sVtrials.minVal
p2437
I0
sS'trials.intensity'
p2438
F0.014125375446227547
sVtrials.startVal
p2439
F0.001
sS'trials.thisIndex'
p2440
I2
sa(dp2441
g42
g43
sVtrials.maxVal
p2442
I1
sg44
V2
sS'trials.response'
p2443
I1
sVtrials.sf
p2444
I2
sS'trials.thisRepN'
p2445
I39
sg36
g40
sS'trials.thisN'
p2446
I152
sVtrials.stepSizes
p2447
g129
sg41
g12
sS'trials.stepSize'
p2448
I1
sS'trials.stepType'
p2449
g92
sVtrials.label
p2450
g128
sg34
g35
sS'trials.direction'
p2451
g145
sVtrials.minVal
p2452
I0
sS'trials.intensity'
p2453
F0.017782794100389226
sVtrials.startVal
p2454
F0.001
sS'trials.thisIndex'
p2455
I0
sa(dp2456
g42
g43
sVtrials.maxVal
p2457
I1
sg44
V2
sS'trials.response'
p2458
I1
sVtrials.sf
p2459
I8
sS'trials.thisRepN'
p2460
I39
sg36
g40
sS'trials.thisN'
p2461
I153
sVtrials.stepSizes
p2462
g102
sg41
g12
sS'trials.stepSize'
p2463
I1
sS'trials.stepType'
p2464
g92
sVtrials.label
p2465
g100
sg34
g35
sS'trials.direction'
p2466
g145
sVtrials.minVal
p2467
I0
sS'trials.intensity'
p2468
F0.015848931924611138
sVtrials.startVal
p2469
F0.001
sS'trials.thisIndex'
p2470
I2
sa(dp2471
g42
g43
sVtrials.maxVal
p2472
I1
sg44
V2
sS'trials.response'
p2473
I1
sVtrials.sf
p2474
I8
sS'trials.thisRepN'
p2475
I39
sg36
g40
sS'trials.thisN'
p2476
I154
sVtrials.stepSizes
p2477
g158
sg41
g12
sS'trials.stepSize'
p2478
I1
sS'trials.stepType'
p2479
g92
sVtrials.label
p2480
g157
sg34
g35
sS'trials.direction'
p2481
g145
sVtrials.minVal
p2482
I0
sS'trials.intensity'
p2483
F0.11220184543019639
sVtrials.startVal
p2484
F0.10000000000000001
sS'trials.thisIndex'
p2485
I3
sa(dp2486
g42
g43
sVtrials.maxVal
p2487
I1
sg44
V2
sS'trials.response'
p2488
I0
sVtrials.sf
p2489
I2
sS'trials.thisRepN'
p2490
I39
sg36
g40
sS'trials.thisN'
p2491
I155
sVtrials.stepSizes
p2492
g143
sg41
g12
sS'trials.stepSize'
p2493
I1
sS'trials.stepType'
p2494
g92
sVtrials.label
p2495
g142
sg34
g35
sS'trials.direction'
p2496
g109
sVtrials.minVal
p2497
I0
sS'trials.intensity'
p2498
F0.01412537544622754
sVtrials.startVal
p2499
F0.10000000000000001
sS'trials.thisIndex'
p2500
I1
sa(dp2501
g42
g43
sVtrials.maxVal
p2502
I1
sg44
V2
sS'trials.response'
p2503
I1
sVtrials.sf
p2504
I2
sS'trials.thisRepN'
p2505
I40
sg36
g40
sS'trials.thisN'
p2506
I156
sVtrials.stepSizes
p2507
g143
sg41
g12
sS'trials.stepSize'
p2508
I1
sS'trials.stepType'
p2509
g92
sVtrials.label
p2510
g142
sg34
g35
sS'trials.direction'
p2511
g145
sVtrials.minVal
p2512
I0
sS'trials.intensity'
p2513
F0.015848931924611131
sVtrials.startVal
p2514
F0.10000000000000001
sS'trials.thisIndex'
p2515
I1
sa(dp2516
g42
g43
sVtrials.maxVal
p2517
I1
sg44
V2
sS'trials.response'
p2518
I0
sVtrials.sf
p2519
I8
sS'trials.thisRepN'
p2520
I40
sg36
g40
sS'trials.thisN'
p2521
I157
sVtrials.stepSizes
p2522
g102
sg41
g12
sS'trials.stepSize'
p2523
I1
sS'trials.stepType'
p2524
g92
sVtrials.label
p2525
g100
sg34
g35
sS'trials.direction'
p2526
g145
sVtrials.minVal
p2527
I0
sS'trials.intensity'
p2528
F0.015848931924611138
sVtrials.startVal
p2529
F0.001
sS'trials.thisIndex'
p2530
I2
sa(dp2531
g42
g43
sVtrials.maxVal
p2532
I1
sg44
V2
sS'trials.response'
p2533
I1
sVtrials.sf
p2534
I2
sS'trials.thisRepN'
p2535
I40
sg36
g40
sS'trials.thisN'
p2536
I158
sVtrials.stepSizes
p2537
g129
sg41
g12
sS'trials.stepSize'
p2538
I1
sS'trials.stepType'
p2539
g92
sVtrials.label
p2540
g128
sg34
g35
sS'trials.direction'
p2541
g109
sVtrials.minVal
p2542
I0
sS'trials.intensity'
p2543
F0.015848931924611134
sVtrials.startVal
p2544
F0.001
sS'trials.thisIndex'
p2545
I0
sa(dp2546
g42
g43
sVtrials.maxVal
p2547
I1
sg44
V2
sS'trials.response'
p2548
I1
sVtrials.sf
p2549
I8
sS'trials.thisRepN'
p2550
I40
sg36
g40
sS'trials.thisN'
p2551
I159
sVtrials.stepSizes
p2552
g158
sg41
g12
sS'trials.stepSize'
p2553
I1
sS'trials.stepType'
p2554
g92
sVtrials.label
p2555
g157
sg34
g35
sS'trials.direction'
p2556
g109
sVtrials.minVal
p2557
I0
sS'trials.intensity'
p2558
F0.10000000000000005
sVtrials.startVal
p2559
F0.10000000000000001
sS'trials.thisIndex'
p2560
I3
sa(dp2561
g42
g43
sVtrials.maxVal
p2562
I1
sg44
V2
sS'trials.response'
p2563
I0
sVtrials.sf
p2564
I8
sS'trials.thisRepN'
p2565
I41
sg36
g40
sS'trials.thisN'
p2566
I160
sVtrials.stepSizes
p2567
g102
sg41
g12
sS'trials.stepSize'
p2568
I1
sS'trials.stepType'
p2569
g92
sVtrials.label
p2570
g100
sg34
g35
sS'trials.direction'
p2571
g145
sVtrials.minVal
p2572
I0
sS'trials.intensity'
p2573
F0.017782794100389229
sVtrials.startVal
p2574
F0.001
sS'trials.thisIndex'
p2575
I2
sa(dp2576
g42
g43
sVtrials.maxVal
p2577
I1
sg44
V2
sS'trials.response'
p2578
I1
sVtrials.sf
p2579
I8
sS'trials.thisRepN'
p2580
I42
sg36
g40
sS'trials.thisN'
p2581
I161
sVtrials.stepSizes
p2582
g102
sg41
g12
sS'trials.stepSize'
p2583
I1
sS'trials.stepType'
p2584
g92
sVtrials.label
p2585
g100
sg34
g35
sS'trials.direction'
p2586
g145
sVtrials.minVal
p2587
I0
sS'trials.intensity'
p2588
F0.019952623149688795
sVtrials.startVal
p2589
F0.001
sS'trials.thisIndex'
p2590
I2
sa(dp2591
g42
g43
sVtrials.maxVal
p2592
I1
sg44
V2
sS'trials.response'
p2593
I1
sVtrials.sf
p2594
I8
sS'trials.thisRepN'
p2595
I43
sg36
g40
sS'trials.thisN'
p2596
I162
sVtrials.stepSizes
p2597
g102
sg41
g12
sS'trials.stepSize'
p2598
I1
sS'trials.stepType'
p2599
g92
sVtrials.label
p2600
g100
sg34
g35
sS'trials.direction'
p2601
g145
sVtrials.minVal
p2602
I0
sS'trials.intensity'
p2603
F0.019952623149688795
sVtrials.startVal
p2604
F0.001
sS'trials.thisIndex'
p2605
I2
sa(dp2606
g42
g43
sVtrials.maxVal
p2607
I1
sg44
V2
sS'trials.response'
p2608
I1
sVtrials.sf
p2609
I8
sS'trials.thisRepN'
p2610
I44
sg36
g40
sS'trials.thisN'
p2611
I163
sVtrials.stepSizes
p2612
g102
sg41
g12
sS'trials.stepSize'
p2613
I1
sS'trials.stepType'
p2614
g92
sVtrials.label
p2615
g100
sg34
g35
sS'trials.direction'
p2616
g145
sVtrials.minVal
p2617
I0
sS'trials.intensity'
p2618
F0.019952623149688795
sVtrials.startVal
p2619
F0.001
sS'trials.thisIndex'
p2620
I2
sasS'loops'
p2621
(lp2622
g48
asS'savePickle'
p2623
I00
sb.